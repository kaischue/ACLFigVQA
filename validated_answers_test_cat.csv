img_file_name;question_german;question_english;corrected_answer_german;corrected_answer_english;short_answer_german;short_answer_english;category;context
2015.jeptalnrecital-court.1.pdf-Figure1.png;Welche Farbe stellt die Basislinie im ersten Subplot dar?;What color represents the baseline in the first subplot?;Blau;Blue;Blau;Blue;Simple Retrieval;''
2015.jeptalnrecital-court.1.pdf-Figure1.png;Liegt der Wert von PL(1) Test im zweiten Subplot beim x-Wert 100 über oder unter 0,310?;In the second subplot, is the value of PL(1) test at x-value 100 above or below 0.310?;Über 0,310;Above 0.310;Über;Above;Simple Retrieval;''
2015.jeptalnrecital-court.1.pdf-Figure1.png;In wie vielen der unteren vier Subplots (Test Set) überschreitet die grüne Linie die blaue Basislinie?;In how many of the bottom four subplots (test set) does the green line exceed the blue baseline?;In allen der unteren vier Subplots überschreitet die grüne Linie die blaue Basislinie.;In all of the lower four subplots, the green line exceeds the blue baseline.;Alle;All;Simple Calculation;''
2015.jeptalnrecital-court.1.pdf-Figure1.png;Welcher PL(k)-Test im unteren Graphensatz hat die geringste Abweichung von der blauen Basislinie, gemessen an der visuellen Höhe der grünen Linien?;Which PL(k) test in the bottom set of graphs has the least deviation from the blue baseline, judging by the visual height of the green lines?;PL(9);PL(9);PL(9);PL(9);Simple Retrieval;''
2015.jeptalnrecital-court.1.pdf-Figure1.png;Im Text wird erwähnt, dass PL(1) einem Algorithmus basierend auf maximaler Entropie entspricht. Wie verhält sich PL(1) im Vergleich zu MIRA in den Reranking-Experimenten (Abbildung 1) in Bezug auf Overfitting und Stabilität?;The text mentions PL(1) being equivalent to a max-entropy based algorithm. How does PL(1) compare to MIRA in the reranking experiments (Figure 1) regarding overfitting and stability?;PL(1) zeigt stärkeres Overfitting als MIRA. Während PL(1) anfänglich stark verbessert wird und MIRA übertrifft, fällt die Leistung schließlich unter die MIRA-Basislinie, was auf eine geringere Stabilität hindeutet.;PL(1) shows more overfitting than MIRA. While PL(1) initially improves greatly and surpasses MIRA, its performance eventually drops below the MIRA baseline, indicating lower stability.;Mehr Overfitting;More Overfitting;Caption Question/Complex Calculation and Logical Reasoning;''
2015.jeptalnrecital-long.1.pdf-Figure5.png;'Welche Farbe repräsentiert die Datenreihe ''Gauche-droite''?';'Which color represents the data series ''Gauche-droite''?';'Blau repräsentiert die Datenreihe ''Gauche-droite''.';'Blue represents the ''Gauche-droite'' data series.';'Blau';Blue;Simple Retrieval;''
2015.jeptalnrecital-long.1.pdf-Figure5.png;'Was ist der Unterschied zwischen den Werten von ''Gauche-droite'' und ''Ordre libre'' bei #décisions = 2?';'Was ist der Unterschied zwischen den Werten von ''Gauche-droite'' und ''Ordre libre'' bei #décisions = 2?';'Der Unterschied zwischen den Werten von ''Gauche-droite'' und ''Ordre libre'' bei #décisions = 2 beträgt ungefähr 11,5.';'The difference between the values of ''Gauche-droite'' and ''Ordre libre'' at #décisions = 2 is approximately 11.5.';'11,5';'11.5';Simple Calculation;''
2015.jeptalnrecital-long.1.pdf-Figure5.png;'Ist die Summe der Werte von ''Ordre libre'' bei #décisions = 4 und #décisions = 6 größer als der Wert von ''Gauche-droite'' bei #décisions = 8?';'Is the sum of the values of ''Ordre libre'' at #décisions = 4 and #décisions = 6 greater than the value of ''Gauche-droite'' at #décisions = 8?';'Ja, die Summe der Werte von ''Ordre libre'' bei #décisions = 4 und #décisions = 6 (ungefähr 16) ist größer als der Wert von ''Gauche-droite'' bei #décisions = 8 (ungefähr 6).';'Yes, the sum of the values of ''Ordre libre'' at #décisions = 4 and #décisions = 6 (approximately 16) is greater than the value of ''Gauche-droite'' at #décisions = 8 (approximately 6).';'Ja';Yes;Complex Calculation and Logical Reasoning;''
2015.jeptalnrecital-long.1.pdf-Figure5.png;'Bei welchem Wert von ''#décisions'' ist der Unterschied zwischen den Werten von ''Gauche-droite'' und ''Ordre libre'' am größten?';'At which value of ''#décisions'' is the difference between the values of ''Gauche-droite'' and ''Ordre libre'' the greatest?';'Der größte Unterschied zwischen den Werten von ''Gauche-droite'' und ''Ordre libre'' scheint bei #décisions = 10 zu liegen.';'The largest difference between the values of ''Gauche-droite'' and ''Ordre libre'' appears to be at #décisions = 10.';'10';10;Complex Calculation and Logical Reasoning;''
2015.jeptalnrecital-long.6.pdf-Figure3.png;'Welche Farbe repräsentiert die Datenreihe ''ZSSP''?';'Which color represents the data series ''ZSSP''?';Blau;Blue;Blau;Blue;Simple Retrieval;''
2015.jeptalnrecital-long.6.pdf-Figure3.png;Was ist der Unterschied im F-Score-Wert zwischen ZSSP und ZSSP-wordspot bei 20 % entfernter Werte?;What is the difference in F-score between ZSSP and ZSSP-wordspot at 20% of removed values?;0.05;0.05;0.05;0.05;Simple Calculation;''
2015.jeptalnrecital-long.6.pdf-Figure3.png;Wie hoch ist der durchschnittliche F-Score-Wert für ZSSP über alle Prozentsätze der entfernten Werte (gerundet auf zwei Dezimalstellen)?;What is the average F-score for ZSSP across all percentages of removed values (rounded to two decimal places)?;0.89;0.89;0.89;0.89;Complex Calculation and Logical Reasoning;''
2015.jeptalnrecital-long.6.pdf-Figure3.png;Bei welchem Prozentsatz an entfernten Werten ist der Unterschied zwischen ZSSP und ZSSP-wordspot am größten?;At what percentage of removed values is the difference between ZSSP and ZSSP-wordspot the greatest?;80%;80%;80%;80%;Simple Calculation;''
2015.jeptalnrecital-long.6.pdf-Figure3.png;'Inwiefern beeinflusst die in der Arbeit beschriebene Evaluierung von ''acttype(champ)'' anstelle von ''acttype(champ=value)'' die Interpretation der in Abbildung 3 dargestellten F-Score-Trends im Hinblick auf die Generalisierungsfähigkeit des Modells?';'How does evaluating ''acttype(champ)'' instead of ''acttype(champ=value)'', as explained in the paper, affect the interpretation of the F-score trends shown in Figure 3, specifically regarding the model's ability to generalize?';'Die Evaluierung von ''acttype(champ)'' konzentriert sich auf die Erkennung von High-Level-Konzepten, nicht auf bestimmte Werte, und zeigt die Generalisierungsfähigkeit, wenn Werte fehlen. Die abnehmenden F-Scores in Abbildung 3 mit entfernten Werten demonstrieren dies, wobei ZSSP besser generalisiert als ZSSP-wordspot.';'Evaluating ''acttype(champ)'' focuses on high-level concept detection, not specific values, revealing generalization ability when values are missing. Figure 3's decreasing F-scores with removed values demonstrate this, with ZSSP generalizing better than ZSSP-wordspot.';ZSSP generalisiert besser;ZSSP generalizes better;Requires Paper Context;'Afin d’évaluer la capacité de généralisation de notre système, nous avons volontairement supprimé de la base de connaissances de DSTC2 des formes de surface correspondant aux différents pourcentages des valeurs possibles de certains champs spécifiques. Dans cette étude préliminaire, nous avons choisi d’étudier l’impact sur les champs food, area et pricerange. Les performances du modèle sur les transcriptions manuelles ont été évaluées en termes de F-score pour acttype(champ) uniquement au lieu de acttype(champ=valeur) afin d’évaluer la détection des concepts de haut niveau.'
2015.jeptalnrecital-recital.2.pdf-Figure3.png;Welche Farbe hat die Linie für K=3 im linken Diagramm?;What color is the line for K=3 in the left graph?;Blau;Blue;Blau;Blue;Simple Retrieval;''
2015.jeptalnrecital-recital.2.pdf-Figure3.png;Was ist die Differenz zwischen dem Wert von K=3 und K=5 für LeskBase im linken Diagramm?;Was ist die Differenz zwischen dem Wert von K=3 und K=5 für LeskBase im linken Diagramm?;Ungefähr 10;Approximately 10;10;10;Simple Calculation;''
2015.jeptalnrecital-recital.2.pdf-Figure3.png;Was ist der Durchschnittswert aller K-Werte für LeskÉtendu im rechten Diagramm?;What is the average value across all K values for LeskÉtendu in the right graph?;Ungefähr 51,3;Approximately 51.3;51,3;51.3;Complex Calculation and Logical Reasoning;''
2015.jeptalnrecital-recital.2.pdf-Figure3.png;'Warum schneidet LeskÉtendu im linken Diagramm bei ''pêcheur'' schlecht ab, obwohl es im Text erwähnt wird, dass es viele semantische Verbindungen hat?';'Why does LeskÉtendu perform poorly on ''pêcheur'' in the left graph, even though the paper mentions it has a high number of semantic connections?';'Das Wort ''pêcheur'' hat zwei Bedeutungen. Die korrekte Bedeutung im gegebenen Kontext hat weniger semantische Verbindungen als die falsche Bedeutung, die sich auf das Fischen bezieht (355 vs. 1576), was zu einer falschen Disambiguierung führt.';'The word ''pêcheur'' has two meanings. The correct meaning in the given context has fewer semantic connections than the incorrect meaning related to fishing (355 vs. 1576), leading to the wrong disambiguation.';Falsche Bedeutung mehr Verbindungen;Incorrect meaning more connections;Requires Paper Context;"Pour les noms ambigus, Lesk étendu retourne le bon sens sur toutes les occurrences de plante par contre il se trompe sur toutes les occurrences de pêcheur. Cela en raison qu’il existe deux sens pour lesquels le score retourné par nos méthodes est le même : (sens 1) « la pêche est l’activité consistant à capturer des animaux aquatiques dans leur milieu naturel » ; (sens 2) « personne dont la profession est d'attraper des poissons ». Sur un extrait de texte : « … il fut recueilli par un _vieux pécheur de saumons … », le bon sens de pêcheur est le deuxième mais le premier est retourné par nos méthodes vu_ qu’il possède plus de connexions sémantiques (1 576 contre 355)."
2015.lilt-12.2.pdf-Figure4.png;'Welche Farbe hat die Linie für ''literarisch''?';'What color is the line for ''literary''?';Blau;Blue;Blau;Blue;Simple Retrieval;''
2015.lilt-12.2.pdf-Figure4.png;'Wie hoch ist der Wert für ''abstrakt'' an Punkt 2?';'What is the value for ''abstract'' at point 2?';Ungefähr -0.1;Approximately -0.1;-0.1;-0.1;Simple Retrieval;''
2015.lilt-12.2.pdf-Figure4.png;Welcher Stil hat bei Punkt 4 den höchsten Wert und welcher den niedrigsten?;Which style has the highest value at point 4, and which has the lowest?;„Abstrakt“ hat den höchsten Wert und „umgangssprachlich“ den niedrigsten Wert an Punkt 4.;'''abstract'' has the highest value and ''colloquial'' has the lowest value at point 4.';'Abstrakt' und 'umgangssprachlich';'Abstract' and 'Colloquial';Simple Retrieval;''
2015.lilt-12.2.pdf-Figure4.png;Welcher Stil zeigt die größte Wertänderung zwischen Punkt 2 und 5, und wie groß ist diese Änderung?;Which style shows the greatest change in value between point 2 and point 5, and what is the magnitude of this change?;'Der Stil ''abstrakt'' ändert sich am meisten, mit einer Abnahme von etwa 0.15 (von ungefähr -0.1 auf -0.25).';'The ''abstract'' style changes the most, with a decrease of roughly 0.15 (from approximately -0.1 to -0.25).';Abstrakt, 0.15;Abstract, 0.15;Simple Calculation;''
2015.lilt-12.2.pdf-Figure4.png;Der Text erwähnt, dass Tiresias im dritten Abschnitt (215-256) deutlich umgangssprachlicher ist als im zweiten (77-110). Stimmt diese Aussage mit der Grafik überein?;The text mentions that Tiresias is significantly more colloquial in his third passage (215-256) than in his second (77-110). Does this statement align with the graph?;Die Grafik stellt den dritten Abschnitt (215-256) nicht direkt dar. Punkt 3 entspricht dem zweiten Abschnitt (77-110) und zeigt einen niedrigeren Wert für Umgangssprache. Daher können wir die Aussage aus dem Text anhand dieser Grafik allein nicht visuell bestätigen.;The graph does not directly represent the third passage (215-256). Point 3 corresponds to the second passage (77-110), showing a lower colloquial value.  Therefore, we cannot visually confirm the statement from the text using this graph alone.;Nein;No;Caption Question/Simple Calculation;''
2016.jeptalnrecital-poster.27.pdf-Figure1.png;Wie viele vertikale Linien sind im Diagramm dargestellt?;How many vertical lines are shown in the diagram?;Drei vertikale Linien.;Three vertical lines.;3;3;Simple Retrieval;''
2016.jeptalnrecital-poster.27.pdf-Figure1.png;Schätzen Sie den Unterschied in der Höhe zwischen dem höchsten und dem niedrigsten Punkt der blauen Linie.;Schätzen Sie den Unterschied in der Höhe zwischen dem höchsten und dem niedrigsten Punkt der blauen Linie.;Ungefähr 0.64;Approximately 0.64;0.64;0.64;Simple Calculation;''
2016.jeptalnrecital-poster.27.pdf-Figure1.png;Schätzen Sie, wie viele Datenpunkte auf der blauen Linie über 0,6 liegen.;Estimate how many data points on the blue line are above 0.6?;Ungefähr 17 Datenpunkte.;Approximately 17 data points.;17;17;Complex Calculation and Logical Reasoning;''
2016.jeptalnrecital-poster.27.pdf-Figure1.png;Welcher Wert von k, der durch die vertikalen Linien dargestellt wird, korrespondiert mit dem höchsten Silhouette-Wert?;Which value of k, represented by the vertical lines, corresponds to the highest Silhouette score?;k=40;k=40;40;40;Simple Retrieval;''
2016.jeptalnrecital-poster.27.pdf-Figure1.png;Der Text erwähnt die drei höchsten Silhouette-Werte. Das Diagramm zeigt, dass k=12 gewählt wurde. Warum wurde k=12 gewählt, obwohl es nicht zu den drei höchsten Peaks gehört, die durch vertikale Linien gekennzeichnet sind, welche die besten Silhouette-werte repräsentieren?;The text mentions the three highest silhouette scores. The chart visually indicates that k=12 was chosen. Why was k=12 selected, despite not corresponding to one of the three highest peaks marked by vertical lines, which represent the best silhouette scores?;k=12 wurde aus Gründen der Einfachheit gewählt, obwohl es nicht den höchsten Silhouette-Wert hat.;k=12 was chosen for simplicity despite not having the highest Silhouette score.;Einfachheit;Simplicity;Caption Question/Complex Calculation and Logical Reasoning;''
2018.lilt-16.1.pdf-Figure1.png;Welche Farbe hat die Linie, die ganz links bei 1 beginnt?;What color is the line that starts at 1 on the far left side of the graph?;Blau;Blue;Blau;Blue;Simple Retrieval;''
2018.lilt-16.1.pdf-Figure1.png;Wie hoch ist der Wert der gelben Linie bei x=14?;What is the value of the yellow line at x=14?;Ungefähr 0.95;Approximately 0.95;0.95;0.95;Simple Retrieval;''
2018.lilt-16.1.pdf-Figure1.png;Bei welchem Wert von x schneiden sich die rote und die gelbe Linie? Falls sie sich nicht schneiden, begründen Sie Ihre Antwort.;At what value of x do the red and yellow lines intersect? If they don't intersect, explain why.;Die gelbe und die rote Linie schneiden sich beim Wert x=14.;The yellow and the red line intersect at the value x=14.;x=14;x=14;Simple Retrieval;''
2018.lilt-16.1.pdf-Figure1.png;In Abbildung 1 ist die Leistung der Modelle für die Aufgabe mit Langzeitabhängigkeiten dargestellt. Welches Modell zeigt die beste Fähigkeit, mit zunehmender Stringlänge eine hohe Genauigkeit beizubehalten, und wie hängt dies mit der Diskussion im Artikel über die Eignung dieser Modelle zur Modellierung von Langzeitabhängigkeiten zusammen?;Figure 1 shows the performance of the models for the long-distance dependency task. Which model demonstrates the best ability to maintain high accuracy as the string length increases, and how does this relate to the discussion in the paper regarding the suitability of these models for modeling long-range dependencies?;Die blaue Linie, die das RUSS-Modell darstellt, behält über alle getesteten Stringlängen eine perfekte Genauigkeit (1,0) bei. Der Artikel argumentiert, dass traditionelle RNNs wie LSTMs und GRUs aufgrund verschwindender Gradienten und begrenzter Speicherkapazität mit Langzeitabhängigkeiten zu kämpfen haben. Das RUSS-Modell mit seinem Stapelspeicher adressiert diese Einschränkung explizit und demonstriert seine überlegene Fähigkeit, Langzeitabhängigkeiten zu verarbeiten, wie die konsistente Leistung in Abbildung 1 zeigt.;The blue line, representing the RUSS model, maintains perfect accuracy (1.0) across all string lengths tested. The paper argues that traditional RNNs like LSTMs and GRUs struggle with long-range dependencies due to vanishing gradients and limited memory capacity. The RUSS model, with its stack memory, explicitly addresses this limitation, demonstrating its superior ability to handle long-distance dependencies as shown by its consistent performance in Figure 1.;RUSS;RUSS;Requires Paper Context;"FIGURE 1 Results for long-distance dependency task for LSTM (red), GRU (yellow) and RUSS (blue).

This task is designed to check that the RNN can capture long-term dependencies, by generalizing to longer strings. Indeed, while both s1 and s2 are probably in the training set, the complete string is not: its total length is 1+8+8+1 = 18. Furthermore, correct predictions for the last character require correctly matching it with either the first character of the input or the character at position 9. Performing this matching could be done with counting alone, but only if the model optimizes for guessing the last character. On the contrary, in our experiment, models are trained to predict any character, so one can expect that to predict any closing parenthesis character the model has to remember every unclosed parenthesis seen so far. Unfortunately, one never knows how a model really behaves before measuring it, so we report the accuracy for every character (and perform further experiments described in the next section).

**Results**

We report only the results for one run, because there is no qualitative difference from run to run. The results are shown in figure 1. The RUSS performs expected given its design, with no error whatsoever. The LSTM shows near perfect accuracy for all known strings (up to length 10). For longer strings its accuracy dips slightly, but remains excellent, never going below 88%. The GRU performs better than the LSTM up to position 14, but then suffers a sharp drop in performance. It ends up completely failing the test at the position which really matters for this task (the last one), with an accuracy hardly"
2020.acl-demos.42.pdf-Figure6.png;Welche Farbe repräsentiert die Ergebnisse des vorgeschlagenen Modells in Diagramm (a)?;What color represents the results of the proposed model in plot (a)?;Blau;Blue;Blau;Blue;Caption Question/Simple Retrieval;''
2020.acl-demos.42.pdf-Figure6.png;Wie hoch ist der F1-Score des vorgeschlagenen Modells für die Sentimentanalyse mit 20 Erklärungen und 50 gelabelten Daten (Diagramm b)?;What is the F1 score of the proposed model for sentiment analysis with 20 explanations and 50 labeled data (plot b)?;Ungefähr 72;Approximately 72;72;72;Caption Question/Simple Retrieval;''
2020.acl-demos.42.pdf-Figure6.png;In Diagramm (a), wie groß ist der Unterschied zwischen dem höchsten und dem niedrigsten F1-Score des vorgeschlagenen Modells?;In plot (a), what is the difference between the highest and lowest F1 score of the proposed model?;Ungefähr 6;Approximately 6;6;6;Caption Question/Simple Calculation;''
2020.acl-demos.42.pdf-Figure6.png;Berechnen Sie den durchschnittlichen F1-Score des vorgeschlagenen Modells für die Named Entity Recognition über alle Datenpunkte in Diagramm (c).;Calculate the average F1 score of the proposed model for Named Entity Recognition across all data points in plot (c).;Ungefähr 64;Approximately 64;64;64;Caption Question/Complex Calculation and Logical Reasoning;''
2020.acl-demos.42.pdf-Figure6.png;Die Studie erwähnt, dass die Beschriftung einer Instanz mit einer Erklärung doppelt so lange dauert wie die Beschriftung ohne Erklärung. Betrachtet man den Leistungsgewinn bei der größten Datengröße für die Named Entity Recognition in Diagramm (c), argumentiert die Studie, dass sich die Zeitinvestition für Erklärungen lohnt? Warum oder warum nicht?;The paper mentions that labeling one instance with an explanation takes twice as long as labeling without. Considering the performance gain at the largest data size for Named Entity Recognition shown in plot (c), does the paper argue that the time investment for explanations is worthwhile? Why or why not?;Ja, die Studie argumentiert, dass sich die Zeitinvestition lohnt. Die verbesserte Leistung, insbesondere bei weniger Datenpunkten, rechtfertigt den zusätzlichen Zeitaufwand für Erklärungen. Bei der größten Datengröße erzielt das Modell mit Erklärungen einen etwa 6 Punkte höheren F1-Score, was trotz des erhöhten Beschriftungsaufwands einen erheblichen Vorteil darstellt.;Yes, the paper argues the time investment is worthwhile.  The increased performance, particularly with fewer data points, justifies the additional time spent obtaining explanations.  At the largest data size, the model with explanations achieves an F1 score approximately 6 points higher, demonstrating a significant benefit despite the increased labeling time.;Ja;Yes;Requires Paper Context;'We claim that when starting with little to no labeled data, it is more effective to ask annotators to provide a label and an explanation for the label, than to just request a label. To support this claim, we conduct experiments to demonstrate the label efficiency of our explanation-leveraging-model. We found that the time for labeling one instance plus providing an explanation takes 2X times more time than just simply providing a label. ... As shown in Fig. 6, we see that our model not only is more time and label efficient than the label-only training process, but it also outperforms the label-only training process.'
2020.acl-main.35.pdf-Figure1.png;'Welche Farbe ist mit ''Wgrad'' assoziiert?';'What color is associated with ''Wgrad''?';Rot;Red;Rot;Red;Simple Retrieval;''
2020.acl-main.35.pdf-Figure1.png;'Was ist der Wert von ''Attn'' bei Top K = 1?';'What is the value of ''Attn'' at Top K = 1?';Ungefähr 15;Approximately 15;15;15;Simple Retrieval;''
2020.acl-main.35.pdf-Figure1.png;'Was ist die Summe der Werte von ''Pd'' bei Top K = 2 und Top K = 4?';'What is the sum of the values of ''Pd'' at Top K = 2 and Top K = 4?';Ungefähr 8;Approximately 8;8;8;Simple Calculation;''
2020.acl-main.35.pdf-Figure1.png;'Was ist das Verhältnis zwischen dem höchsten und dem niedrigsten Wert von ''Wgrad''?';'What is the ratio between the highest and the lowest value of ''Wgrad''?';5;5;5;5;Simple Calculation;''
2020.acl-main.35.pdf-Figure1.png;Abbildung 1 zeigt die PPL-Werte für verschiedene Erklärungsmethoden auf dem IWSLT De-En-Datensatz. Der Text erwähnt jedoch auch Experimente mit größeren Datensätzen wie WMT. Wie verhält sich der Trend der PPL-Werte in Abbildung 1 im Vergleich zu den Ergebnissen der größeren WMT-Datensätzen, und welche Gründe werden im Text für etwaige Unterschiede genannt? Beziehen Sie Ihre Antwort sowohl auf die Abbildung als auch auf den bereitgestellten Textauszug.;Figure 1 shows the PPL values for different explanation methods on the IWSLT De-En dataset. However, the text excerpt also mentions experiments on larger datasets like WMT. How does the trend of PPL values in Figure 1 compare to the results on the larger WMT datasets, and what reasons are given in the text for any differences? Relate your answer to both the figure and the provided text excerpt.;Der Trend abnehmender PPL mit steigendem k, der in Abbildung 1 für den IWSLT-Datensatz beobachtet wird, wird voraussichtlich auch für größere WMT-Datensätze gelten. Der Text legt nahe, dass dies daran liegt, dass größere Datensätze mehr Trainingsdaten liefern, was zu einer besseren Generalisierung und geringerer Perplexität führt. Der Text vergleicht die Größenordnung der PPL-Unterschiede zwischen IWSLT und WMT nicht explizit, sondern konzentriert sich auf die konsistente Rangfolge der Erklärungsmethoden über Datensätze und k-Werte hinweg.;The trend of decreasing PPL with increasing k observed in Figure 1 for the IWSLT dataset is expected to hold for larger WMT datasets as well. The text suggests this is because larger datasets provide more training data, leading to better generalization and lower perplexity.  The text doesn't explicitly compare the magnitude of PPL differences between IWSLT and WMT but focuses on the consistent ranking of explanation methods across datasets and k values.;Abnehmender Trend;Decreasing trend;Requires Paper Context;"**Datasets** We carry out our experiments on three standard IWSLT translation tasks including IWSLT14 De En (167k sentence pairs), _⇒_ IWSLT17 Zh En (237k sentence pairs) and _⇒_ IWSLT17 Fr En (229k sentence pairs). All these _⇒_ datasets are tokenized and applied BPE (Byte-Pair Encoding) following Ott et al. (2019). The target side vocabulary sizes of the three datasets are 8876, 11632, and 9844 respectively. In addition, we carry out extended experiments on three largescale WMT translation tasks including WMT14 De En (4.5m sentence pairs), WMT17 Zh En _⇒_ _⇒_ (22m sentence pairs) and WMT14 Fr En (40.8m _⇒_ sentence pairs), with vocabulary sizes 22568, 29832, 27168 respectively.

**NMT Systems** To examine the generality of our evaluation method, we conduct experiments on two NMT systems, i.e. RNN-SEARCH (denoted by RNN) and TRANSFORMER (denoted by Trans.), both of which are implemented with fairseq (Ott et al., 2019). [...]

**Effects on different k** In this experiment, we examine the effects of explanation methods on larger k with respect to SA. Figure 1 depicts the effects of k for TRANSFORMER on De En task. _⇒_ One can clearly observe two findings: 1) the ranking order of explanation methods is invariant for different k. 2) as k is larger, the PPL is much better for each explanation method. 3) the PPL improvement for PD, ATTN, and NGRAD is less after _k > 2, which further validates that they are pow-_ erful in explaining NMT using only a few words."
2020.acl-main.39.pdf-Figure4.png;Welche Farbe hat die Linie, die 'x' darstellt?;What color is the line representing 'x'?;Schwarz;Black;Schwarz;Black;Simple Retrieval;''
2020.acl-main.39.pdf-Figure4.png;Welchen Wert hat die Soft-Staircase-Funktion an der Stelle x = 2?;What is the value of the soft-staircase function at x = 2?;Ungefähr 2;Approximately 2;2;2;Simple Retrieval;''
2020.acl-main.39.pdf-Figure4.png;Wie viele Schnittpunkte gibt es zwischen der Soft-Staircase-Funktion und der Geraden y = x im dargestellten Bereich?;How many intersection points are there between the soft-staircase function and the line y = x in the shown range?;13;13;13;13;Simple Calculation;''
2020.acl-main.39.pdf-Figure4.png;Welchen Wert hat die Soft-Staircase-Funktion im gezeigten Bereich maximal und minimal, und wie groß ist die Differenz dazwischen?;What are the maximum and minimum values of the soft-staircase function in the shown range, and what is the difference between them?;Der Maximalwert beträgt ungefähr 3, der Minimalwert ungefähr -3, und die Differenz beträgt ungefähr 6.;The maximum value is approximately 3, the minimum value is approximately -3, and the difference is approximately 6.;6;6;Simple Calculation;''
2020.acl-main.39.pdf-Figure4.png;'Die Arbeit erwähnt die Erzwingung von ''Gewichtungen der Schrittgröße, die ungefähr ganzzahlig sind''. Wie trägt diese Einschränkung zum ''Treppeneffekt'' bei, der im Diagramm der Soft-Staircase-Aktivierungsfunktion beobachtet wird? Beziehen Sie Ihre Antwort auf die angegebene mathematische Definition.';'The paper mentions forcing ''weights of the step size to be approximately integers''. How does this constraint contribute to the ''staircase'' effect observed in the graph of the soft-staircase activation function? Relate your answer to the provided mathematical definition.';'Der Treppeneffekt kommt von der Abrundungsfunktion (⌊⌋) in der Definition: *softstair(x) := x + sigmoid(20(x - 0.5⌊x⌋)) - ⌊x⌋*. Die Abrundungsfunktion erzeugt diskrete Stufen. Der Sigmoid-Term glättet diese Stufen und macht sie zu einer ''weichen'' Treppe. Das Erzwingen von ganzzahligen Gewichtungen bedeutet, dass die Eingabe der Abrundungsfunktion sich in diskreten Schritten ändert, wodurch die diskrete Natur der Abrundungsfunktion hervorgehoben und ein stärker ausgeprägter Treppeneffekt erzeugt wird.';'The staircase effect comes from the floor function (⌊⌋) in the definition: *softstair(x) := x + sigmoid(20(x - 0.5⌊x⌋)) - ⌊x⌋*. The floor function creates discrete steps. The sigmoid term smooths these steps making it a ''soft'' staircase. Forcing integer weights means the input to the floor function will change in discrete steps, emphasizing the discrete nature of the floor function and creating a more pronounced staircase effect.';Ganzzahlige Gewichtungen betonen die Stufen.;Integer weights emphasize steps.;Caption Question/Complex Calculation and Logical Reasoning;'_softstair(x) :=_ _x_ +sigmoid(20(x 0.5 _x_ )) _⌊_ _⌋_ _−_ _−⌊_ _⌋_'
2020.acl-main.57.pdf-Figure2.png;'Welche Farbe stellt die Datenreihe ''MDSmle'' dar?';'What color represents the data series labeled ''MDSmle''?';Lila;Purple;Lila;Purple;Simple Retrieval;''
2020.acl-main.57.pdf-Figure2.png;Wie groß ist der Genauigkeitsunterschied zwischen Mem und Meta-Mem nach 10 Feinabstimmungsiterationen?;What is the accuracy difference between Mem and Meta-Mem after 10 fine-tuning iterations?;Ungefähr 0,06;Approximately 0.06;0,06;0.06;Simple Calculation;''
2020.acl-main.57.pdf-Figure2.png;Welches Modell erreicht nach 4 Iterationen die höchste Genauigkeit und welches die niedrigste?;Which model achieves the highest accuracy after 4 iterations and which the lowest?;MDS erreicht die höchste Genauigkeit und Mem die niedrigste nach 4 Iterationen.;MDS achieves the highest accuracy and Mem the lowest after 4 iterations.;MDS/Mem;MDS/Mem;Simple Calculation;''
2020.acl-main.57.pdf-Figure2.png;Bei welcher Iteration ist der Genauigkeitsunterschied zwischen MDS und Mem am größten?;At which iteration is the accuracy difference between MDS and Mem the largest?;Der größte Unterschied scheint um Iteration 0 zu liegen.;The largest difference appears to be around iteration 0.;Iteration 0;Iteration 0;Simple Calculation;''
2020.acl-main.57.pdf-Figure2.png;Abschnitt 3.3 erwähnt, dass MDS zu Beginn die beste Genauigkeit erreicht und am schnellsten konvergiert. Welche Eigenschaften des Graphen in Abbildung 2 stützen diese Aussage, und welche zusätzliche Information aus dem Paper (Abschnitt 3.3) erklärt die schnellere Konvergenz von MDS?;Section 3.3 mentions that MDS achieves the best accuracy at the beginning and converges fastest. Which characteristics of the graph in Figure 2 support this statement, and what additional information from the paper (Section 3.3) explains the faster convergence of MDS?;Der Graph zeigt die braune MDS-Linie am höchsten Punkt beginnend und schnell ein Plateau erreichend. Der Abschnitt im Paper erklärt, dass diese schnellere Konvergenz darauf zurückzuführen ist, dass MDS eine bessere Parameterinitialisierung für das Transferlernen auf neue Aufgaben findet.;The graph shows the brown MDS line starting at the highest point and quickly reaching a plateau. The paper section explains that this faster convergence is due to MDS finding better parameter initialization for transfer learning on new tasks.;Beginnt am höchsten, schnelles Plateau/bessere Parameterinitialisierung;Starts highest, quick plateau/better parameter initialization;Requires Paper Context;'To further investigate the adaptation process, we present the fine-tuning curves for different methods with 1 dialog adaptation in Figure 2. As it can be seen, MDS achieves the best accuracy at the beginning and converges fastest as well, showing that it can transfer on new tasks quickly by finding better parameter initialization.'
2020.acl-main.62.pdf-Figure3.png;Welche Datenreihe wird durch offene Kreise und gepunktete Linien dargestellt?;Which data series is represented by open circles and dotted lines?;VRNN (stochastic only);VRNN (stochastic only);VRNN (stochastic only);VRNN (stochastic only);Simple Retrieval;''
2020.acl-main.62.pdf-Figure3.png;Wie hoch ist die Erfolgsrate von VRNN (nur deterministisch) bei einem vollständig annotierten Dialogverhältnis von 15 % in Abbildung (a)?;Wie hoch ist die Erfolgsrate von VRNN (nur deterministisch) bei einem vollständig annotierten Dialogverhältnis von 15 % in Abbildung (a)?;Ungefähr 75%;Approximately 75%;75%;75%;Simple Retrieval;''
2020.acl-main.62.pdf-Figure3.png;Was ist die durchschnittliche Erfolgsrate aller Modelle in Abbildung (b) bei einem vollständig annotierten Dialogverhältnis von 20%?;What is the average success rate of all models in Figure (b) at a 20% fully annotated dialogue ratio?;Ungefähr 77%;Approximately 77%;77%;77%;Complex Calculation and Logical Reasoning;''
2020.acl-main.62.pdf-Figure3.png;Bei welchem vollständig annotierten Dialogverhältnis in Abbildung (a) ist der Unterschied zwischen der Erfolgsrate von VRNN und VRNN (nur stochastisch) am größten?;At which fully annotated dialogue ratio in Figure (a) is the difference between the success rate of VRNN and VRNN (stochastic only) the greatest?;Bei 10% und 15%.;At 10% and 15%. ;10% und 15%;10% and 15%;Complex Calculation and Logical Reasoning;''
2020.acl-main.62.pdf-Figure3.png;Abschnitt 4.3 erwähnt, dass sowohl stochastische als auch deterministische Zustände in VRNN wichtig sind. Welche Ergebnisse in Abbildung 3 unterstützen diese Schlussfolgerung, und wie wird die Bedeutung beider Zustandsarten durch die Ergebnisse der verschiedenen VRNN-Varianten im Vergleich zum vollständigen VRNN-Modell verdeutlicht?;Section 4.3 mentions that both stochastic and deterministic states in VRNN are important.  Which findings in Figure 3 support this statement, and how is the importance of both types of states illustrated by the performance of the different VRNN variants compared to the full VRNN model?;Abbildung 3 zeigt, dass das vollständige VRNN-Modell durchweg sowohl die rein stochastische als auch die rein deterministische Variante über verschiedene vollständig annotierte Dialogverhältnisse hinweg übertrifft. Dies deutet darauf hin, dass sowohl stochastische als auch deterministische Zustände zur Gesamtleistung beitragen. Die Bedeutung beider wird durch die Tatsache hervorgehoben, dass keine der Varianten allein die Leistung des kombinierten Modells erreicht.;Figure 3 shows that the full VRNN model consistently outperforms both the stochastic-only and deterministic-only variants across various fully annotated dialogue ratios. This indicates that both stochastic and deterministic states contribute to the overall performance. The importance of both is highlighted by the fact that neither variant on its own matches the performance of the combined model.;Beide Zustandsarten tragen bei;Both state types contribute;Requires Paper Context;"Last, we study the effects of dynamics model based reward function in Act-VRNN. We consider four different models as reward function: (1) our full dynamics model VRNN; (2) a dynamics model having only deterministic states (Eqn. 17); (3) a dynamics model having only stochastic states (Eqn. 15); (4) GDPL. All four models are learned based

Figure 3: Effects of dynamics model

on action embedding learned in the action learning module. The results under DF + DP and DF + DU are shown in Fig. 3(a) and Fig. 3(b), respectively. We can see that both stochastic and deterministic states in VRNN are important, since VRNN outperforms its two variants and GDPL in each configuration."
2020.acl-main.67.pdf-Figure5.png;Welche Farbe hat die Linie, die K=1 darstellt?;What color is the line representing K=1?;Schwarz;Black;Schwarz;Black;Simple Retrieval;''
2020.acl-main.67.pdf-Figure5.png;Was ist die Differenz des BLEU-Wertes zwischen K=1 und K=4 bei einer AMR-Graphgröße von 11-20?;What is the difference in BLEU score between K=1 and K=4 for an AMR graph size of 11-20?;Ungefähr 2;Approximately 2;2;2;Simple Calculation;''
2020.acl-main.67.pdf-Figure5.png;Was ist der durchschnittliche BLEU-Wert für K=4 über alle AMR-Graphgrößen?;What is the average BLEU score for K=4 across all AMR graph sizes?;Ungefähr 32;Approximately 32;32;32;Complex Calculation and Logical Reasoning;''
2020.acl-main.67.pdf-Figure5.png;Ist die Differenz der BLEU-Werte zwischen K=1 und K=4 bei einer AMR-Graphgröße von >30 größer als bei einer Größe von 1~10?;Is the difference in BLEU scores between K=1 and K=4 greater for an AMR graph size of >30 than for a size of 1~10?;Ja;Yes;Ja;Yes;Simple Calculation;''
2020.acl-main.67.pdf-Figure5.png;In Abschnitt 5.1 wird die BLEU-Variation zwischen Modellen mit unterschiedlichen Ordnungen K in Bezug auf die AMR-Graphgröße untersucht.  Betrachtet man Abbildung 5, welche Schlussfolgerung lässt sich über den Einfluss von K auf die Leistung bei größeren AMR-Graphen im Vergleich zu kleineren AMR-Graphen ziehen?;Section 5.1 investigates the BLEU variation between models with different orders K with respect to AMR graph size. Considering Figure 5, what conclusion can be drawn about the impact of K on performance with larger AMR graphs compared to smaller AMR graphs?;Der Leistungsunterschied zwischen K=4 und K=1 nimmt mit zunehmender AMR-Graphgröße zu, was darauf hindeutet, dass ein höherer K-Wert für größere Graphen wichtiger wird.;The performance difference between K=4 and K=1 increases as AMR graph size increases, indicating that a higher K value becomes more important for larger graphs.;Höherer K-Wert wichtiger für größere Graphen;Higher K value more important for larger graphs;Caption Question/Complex Calculation and Logical Reasoning;''
2020.acl-main.67.pdf-Figure6.png;Welche Farbe hat die Linie mit der Beschriftung Ke=0?;What is the color of the line labeled Ke=0?;Blau;Blue;Blau;Blue;Simple Retrieval;''
2020.acl-main.67.pdf-Figure6.png;Wie groß ist der Unterschied im BLEU-Score zwischen Ke=0 und Ke=4 bei einer AMR-Graphgröße von >30 (linkes Diagramm)?;Wie groß ist der Unterschied im BLEU-Score zwischen Ke=0 und Ke=4 bei einer AMR-Graphgröße von >30 (linkes Diagramm)?;Ungefähr 2;Approximately 2;2;2;Simple Calculation;''
2020.acl-main.67.pdf-Figure6.png;Ist im linken Diagramm die Summe der BLEU-Scores für Ke=0 bei AMR-Graphgrößen von 1-10 und 11-20 größer als der BLEU-Score für Ke=0 bei einer AMR-Graphgröße von 21-30?;In the left chart, is the sum of the BLEU scores for Ke=0 at AMR graph sizes 1-10 and 11-20 greater than the BLEU score for Ke=0 at AMR graph size of 21-30?;Ja, ungefähr 38 + 29 = 67, was größer ist als ungefähr 28.;Yes, approximately 38 + 29 = 67, which is greater than approximately 28.;Ja;Yes;Complex Calculation and Logical Reasoning;''
2020.acl-main.67.pdf-Figure6.png;Im rechten Diagramm: Wie hoch ist die Summe der BLEU-Scores für Ke=4 bei 0-1 und 2-3 Wiedereintrittszahlen?;In the right chart: what is the sum of the BLEU scores for Ke=4 at 0-1 and 2-3 reentrancy numbers?;Ungefähr 32,5 + 31,5 = 64;Approximately 32.5 + 31.5 = 64;64;64;Simple Calculation;''
2020.acl-main.67.pdf-Figure6.png;Inwiefern verändert sich gemäß der Analyse in Abschnitt 5.1 und Abbildung 5 die Leistung des Modells mit K=4 im Vergleich zum Modell mit K=1 mit zunehmender AMR-Graphgröße?;According to the analysis in Section 5.1 and Figure 5, how does the performance of the model with K=4 compare to the model with K=1 as the AMR graph size increases?;Mit zunehmender AMR-Graphgröße vergrößert sich der Leistungsunterschied zwischen dem Modell mit K=4 und dem Modell mit K=1. Dies deutet darauf hin, dass Informationen aus der Nachbarschaft höherer Ordnung für größere Graphen immer wichtiger werden.;As the AMR graph size increases, the performance gap between the model with K=4 and the model with K=1 widens. This suggests that higher-order neighborhood information becomes increasingly important for larger graphs.;Vergrößert sich;Widens;Requires Paper Context;'As mentioned above, if only consider the firstorder neighborhood, the dependencies between distant AMR concepts cannot be fully explored when the graph size becomes larger. To verify this hypothesis, we split the test set into different parts according to the AMR graph size (i.e. number of concepts). We evaluate our models with order K = 4 and K = 1 on different partitions. All models are trained on LDC2015E86 set. Figure 5 shows the result. The model with K = 4 significantly outperforms the one with K = 1. Furthermore, we can find that the performance gap between the two models increases when the graph gets bigger. As a result, higher-order neighborhood information does play an important role in graph-to-sequence generation, especially for larger AMR graphs.'
2020.acl-main.70.pdf-Figure2.png;Welches Symbol steht für den Sb-Algorithmus?;Which symbol represents the Sb algorithm?;Ein nach rechts zeigendes braunes Dreieck (▶).;A rightward-pointing brown triangle (▶).;▶;▶;Simple Retrieval;''
2020.acl-main.70.pdf-Figure2.png;Wie hoch ist der NMI-Wert von DMM für den News-Datensatz beim ersten Datenpunkt?;Wie hoch ist der NMI-Wert von DMM für den News-Datensatz beim ersten Datenpunkt?;Ungefähr 0.72.;Approximately 0.72.;0.72;0.72;Simple Retrieval;''
2020.acl-main.70.pdf-Figure2.png;Welcher Algorithmus hat den höchsten NMI-Wert am ersten Datenpunkt und welcher am letzten Datenpunkt im News-Datensatz?;Which algorithm has the highest NMI value at the first data point and which at the last data point in the News dataset?;MFG hat den höchsten NMI-Wert am ersten Datenpunkt und OSDM am letzten.;MFG has the highest NMI value at the first data point and OSDM at the last.;MFG, OSDM;MFG, OSDM;Simple Retrieval;''
2020.acl-main.70.pdf-Figure2.png;Im Tweets-Datensatz, übersteigt der durchschnittliche NMI-Wert von OSDM den durchschnittlichen NMI-Wert von MF-O?;In the Tweets dataset, does the average NMI value of OSDM exceed the average NMI value of MF-O?;Ja, der durchschnittliche NMI-Wert für OSDM scheint im Tweets-Datensatz höher zu sein als der von MF-O.;Yes, the average NMI value for OSDM appears higher than that of MF-O in the Tweets dataset.;Ja;Yes;Complex Calculation and Logical Reasoning;''
2020.acl-main.70.pdf-Figure2.png;Der Text erwähnt die Notwendigkeit, die Anzahl der Cluster für bestimmte Algorithmen festzulegen. Wie wirkt sich diese Notwendigkeit auf die Fähigkeit dieser Algorithmen aus, mit der Entwicklung von Themen in Textströmen umzugehen, und welche Strategie verwendet OSDM, um diese Einschränkung zu überwinden?;The text mentions the need to fix the number of clusters for certain algorithms. How does this requirement impact the ability of these algorithms to handle evolving topics in text streams, and what strategy does OSDM employ to overcome this limitation?;Die Festlegung der Clusteranzahl kann die Fähigkeit der Algorithmen beeinträchtigen, sich an neu entstehende oder verschwundene Themen in sich entwickelnden Textströmen anzupassen. OSDM begegnet dem, indem es Cluster dynamisch erstellt und entfernt, basierend auf einer Zerfallsfunktion, die auf ihre Gewichte (lz) angewendet wird.;Fixing the number of clusters can hinder the algorithms' ability to adapt to emerging or disappearing topics in evolving text streams. OSDM addresses this by dynamically creating and removing clusters based on a decay function applied to their weights (lz).;Dynamische Clustererstellung und -entfernung;Dynamic cluster creation and removal;Requires Paper Context;"To deal with the cluster evolution (i.e., evolving topics) in text streams, many existing approaches often delete the old clusters by using some of the forgetting mechanisms (e.g., decay rate) (Zhong, 2005; Aggarwal and Yu, 2010; Islam et al., 2019). Instead of deleting old clusters, MStreamF (Yin et al., 2018) deletes old batches. In this study, we investigate the importance of each micro-cluster to handle the cluster evolution problem. Specifically, the importance of each micro-cluster is decreased over time if it is not updated. lz in CF stores weight of each cluster. If the weight is approximately equals to zero, then the cluster is removed from the model, i.e., it cannot capture recent topics in the text stream. For this purpose, we applied the exponential decay function, lz = lz 2[−][λ][×][(][△][t][)]. _×_ Here, _t is the elapsed time from the last update,_ _△_ and λ is the decay rate. The decay rate must be adjusted depending upon the applications at hand. The initial value of lz (See Line 16 of Algorithm 1) is set to 1. Afterward, the importance of microcluster is exponentially decreases over time. We can also store the deleted clusters in a permanent disk for offline analysis."
2020.acl-main.81.pdf-Figure2.png;'Welche Farbe hat die Linie, die ''BERT Recall'' darstellt?';'What color is the line representing ''BERT Recall''?';Hellgrün.;Light green.;Hellgrün;Light green;Simple Retrieval;''
2020.acl-main.81.pdf-Figure2.png;Was ist die Differenz zwischen dem BERT F1-Score und dem SpellGCN F1-score nach Epoche 2?;What is the difference between the BERT F1-score and the SpellGCN F1-score after epoch 2?;Ungefähr 0,07.;Approximately 0.07.;0,07;0.07;Simple Calculation;''
2020.acl-main.81.pdf-Figure2.png;Ist der durchschnittliche BERT Recall über alle Epochen hinweg größer als der durchschnittliche BERT F1-Score? Begründen Sie Ihre Antwort anhand einer ungefähren Berechnung der Durchschnittswerte.;Is the average BERT Recall across all epochs greater than the average BERT F1-score? Support your answer with an approximate calculation of the average values.;Ja. Der durchschnittliche BERT Recall liegt bei etwa 0,66, während der durchschnittliche BERT F1-Score bei etwa 0,64 liegt. Daher ist der durchschnittliche BERT F1-Score etwas höher.;Yes. The average BERT Recall is around 0.66, while the average BERT F1-Score is around 0.64. Therefore, the average BERT F1-Score is slightly higher.;Nein;No;Complex Calculation and Logical Reasoning;''
2020.acl-main.81.pdf-Figure2.png;Übersteigt die Summe aus SpellGCN F1-Score und SpellGCN Precision in Epoche 5 den Wert 1,4?  Geben Sie die ungefähren Werte für beide Metriken in Epoche 5 an.;Does the sum of the SpellGCN F1-score and SpellGCN Precision at epoch 5 exceed 1.4? Provide the approximate values for both metrics at epoch 5.;Ja. In Epoche 5 beträgt der SpellGCN F1-Score etwa 0,77 und die SpellGCN Precision etwa 0,72. Ihre Summe ist ungefähr 1,49.;Yes. At epoch 5, the SpellGCN F1-score is approximately 0.77 and the SpellGCN Precision is approximately 0.72. Their sum is approximately 1.49.;Ja;Yes;Simple Calculation;''
2020.acl-main.81.pdf-Figure2.png;Die Bildunterschrift erwähnt Verbesserungen durch SpellGCN.  Vergleicht man die BERT- und SpellGCN-Kurven in Abbildung 2 visuell, in welcher Epoche ist der Leistungsunterschied am deutlichsten, und wie verhält sich dieser visuelle Unterschied zu der in Tabelle 3 angegebenen prozentualen Verbesserung des C-F-Scores auf SIGHAN 2015?;The caption mentions improvements with SpellGCN. Visually comparing the BERT and SpellGCN curves in Figure 2, during which epoch is the performance difference most pronounced, and how does this visual difference compare to the percentage improvement reported in Table 3 for the C-F score on SIGHAN 2015?;Der größte visuelle Leistungsunterschied liegt bei etwa Epoche 1. Tabelle 3 zeigt, dass SpellGCN einen C-F-Score von 75,9 und BERT einen von 73,0 auf SIGHAN 2015 erreicht, ein Unterschied von 2,9 Prozentpunkten (etwa 4% relative Verbesserung).;The largest visual performance difference is around epoch 1. Table 3 shows that SpellGCN's C-F score is 75.9 and BERT's is 73.0 on SIGHAN 2015, a difference of 2.9 percentage points (approximately 4% relative improvement).;Epoche 1;Epoch 1;Caption Question/Complex Calculation and Logical Reasoning;''
2020.acl-main.92.pdf-Figure4.png;Welche Farbe hat die Linie, die die Daten für AI2 darstellt?;What color is the line representing the data for AI2?;Mittelblau.;Medium blue.;Mittelblau;Medium blue;Simple Retrieval;''
2020.acl-main.92.pdf-Figure4.png;Wie hoch ist der Prozentsatz der MWPs für KAZB bei einer syntaktischen Musterdiversität von 0,2?;What is the percentage of MWPs for KAZB at a syntactic pattern diversity of 0.2?;Ungefähr 35%.;Approximately 35%. ;35%;35%;Simple Retrieval;''
2020.acl-main.92.pdf-Figure4.png;Bei welchem Wert für die syntaktische Musterdiversität kreuzen sich die Linien für ALGES und AllArith schneiden sich?;At what syntactic pattern diversity value do the lines for ALGES and AllArith intersect?;Ungefähr 0,225.;Approximately 0.225.;0,225;0.225;Simple Retrieval;''
2020.acl-main.92.pdf-Figure4.png;Wie hoch ist die durchschnittliche prozentuale Häufigkeit von MWPs für ASDiv und MathQA über alle Werte der syntaktischen Musterdiversität?;What is the average percentage of MWPs for ASDiv and MathQA across all syntactic pattern diversity values?;Ungefähr 14% für ASDiv und 2% für MathQA.;Approximately 14% for ASDiv and 2% for MathQA.;14% / 2%;14% / 2%;Complex Calculation and Logical Reasoning;''
2020.acl-main.92.pdf-Figure4.png;In der Arbeit wird die Herausforderung diskutiert, MWP-Löser aufgrund von Datensatzähnlichkeiten zu bewerten. Wie unterstützt Abbildung 4 visuell die Argumentation der Arbeit, dass ASDiv trotz eines hohen CLD-Werts zwischen Trainings- und Testdatensatz im Vergleich zu Datensätzen wie MathQA immer noch ein schwierigerer Datensatz ist? Beziehen Sie sich in Ihrer Antwort sowohl auf Abbildung 4 als auch auf den entsprechenden Abschnitt im Paper, in dem diese Herausforderungen erläutert werden.;The paper discusses the challenge of evaluating MWP solvers due to dataset similarities. How does Figure 4 visually support the paper's argument that ASDiv, despite a high CLD value between training and test sets, is still a more challenging dataset compared to datasets like MathQA? Refer to both Figure 4 and the relevant section in the paper discussing these challenges in your response.;Laut Textbeschreibung zeigt Abbildung 4, dass ASDiv nur 4% identische syntaktische Muster innerhalb seines Datensatzes aufweist, verglichen mit 87% bei MathQA. Dies impliziert, dass der Testsatz von ASDiv an sich vielfältiger ist als der von MathQA, selbst wenn die lexikalische Diversität (CLD) zwischen Trainings- und Testsätzen für ASDiv hoch ist. Diese größere interne Diversität innerhalb des Testsatzes zwingt Solver zu einer stärkeren Verallgemeinerung, was die Schwierigkeit von ASDiv erhöht.;Figure 4, according to the text description, shows ASDiv having only 4% identical syntactic patterns within its dataset, compared to 87% for MathQA. This implies that ASDiv's test set is intrinsically more diverse than MathQA's, even if the cross-dataset lexical diversity (CLD) between training and test sets for ASDiv is high.  This greater internal diversity within the test set forces solvers to generalize more, increasing the difficulty of ASDiv.;4% vs. 87%;4% vs. 87%;Caption Question/Complex Calculation and Logical Reasoning;"We also provide a _syntactic pattern diversity to_ measure the syntactic diversity of an MWP. Let 𝑃��𝑃�, 𝑃�, …, 𝑃�� be a specific set of MWPs in a given corpus with the same problem type, where 𝑃� is the i-th MWP in 𝑃, and 𝑇� is the corresponding POS sequence of 𝑃�. For example, “NNP VBZ CD NNS” is the POS tagging sequence for “Mary has 5 books.”. For a given 𝑃�, we define its syntac_tic pattern diversity (𝑆𝐷�) as_

𝐵𝐿𝐸𝑈�𝑇�, 𝑇���𝐵𝐿𝐸𝑈�𝑇, 𝑇�� 𝑆𝐷� �1 �max, �,��� 2

where 𝐵𝐿𝐸𝑈�𝑇�, 𝑇�� is measured between 𝑇� and 𝑇� ( j �i, 𝑗��1,2, …, 𝑀� ). Figure 4 shows that there are 87%, 54%, 46% and 33% identical syntactic patterns (these numbers are the percentages of MWPs with 𝑆𝐷� =0 w.r.t. each dataset) in the MathQA, IL, AI2, and ALGES corpora, respectively, while ASDiv only has 4%. This shows that our corpus is also more diverse in terms of syntactic patterns."
2020.acl-main.92.pdf-Figure5.png;Welcher Datensatz weist bei einem Lexikonnutzungsvielfaltsindex von 0 den höchsten Wert auf?;Which dataset has the highest value at a Lexicon Usage Diversity index of 0?;MathQA-C hat bei einem Lexikonnutzungsvielfaltsindex von 0 den höchsten Wert, etwa 80%.;MathQA-C has the highest value at a Lexicon Usage Diversity index of 0, approximately 80%. ;MathQA-C;MathQA-C;Simple Retrieval;''
2020.acl-main.92.pdf-Figure5.png;Wie groß ist der ungefähre Unterschied im Lexikonnutzungsvielfaltsindex zwischen ASDiv-A und MathQA bei einem Indexwert von 0,95?;What is the approximate difference in the Lexicon Usage Diversity index between ASDiv-A and MathQA at an index value of 0.95?;Bei einem Lexikonnutzungsvielfaltsindex von 0,95 liegt ASDiv-A bei etwa 0 % und MathQA bei etwa 19 %. Die Differenz beträgt somit etwa 19 %.;With a lexicon usage diversity index of 0.95, ASDiv-A is at about 0% and MathQA is at about 19%. The difference is therefore about 19%. ;19%;19%;Simple Calculation;''
2020.acl-main.92.pdf-Figure5.png;Wie viele Datensätze haben einen minimalen Lexikonnutzungsvielfaltsindex von unter 5 %?;How many datasets have a minimum Lexicon Usage Diversity index below 5%?;9 Datensätze haben ihren niedrigsten Punkt unter 5%;9 data sets have their lowest point below 5%;9;9;Simple Calculation;''
2020.acl-main.92.pdf-Figure5.png;Abbildung 5 zeigt die lexikalische Nutzungsvielfalt zwischen Test- und Trainingsdatensätzen. Hat MathQA die höchste lexikalische Nutzungsvielfalt, und wenn ja, widerspricht dies der im Text genannten Aussage, dass MathQA eine geringe lexikalische Diversität innerhalb des gesamten Korpus aufweist?;Figure 5 shows the lexicon usage diversity between test and training sets. Does MathQA have the highest lexicon usage diversity, and if so, does this contradict the text's statement that MathQA has low lexical diversity within the entire corpus?;Ja, MathQA hat die höchste lexikalische Nutzungsvielfalt zwischen Test- und Trainingsdatensätzen (0.85). Dies scheint der geringen lexikalischen Diversität von MathQA innerhalb des gesamten Korpus (0,05 wie in Abbildung 1 erwähnt) zu widersprechen. Der Text erklärt jedoch, dass dieser hohe Wert zwischen Test- und Trainingsdatensätzen irreführend sein kann. Ein hoher Wert hier bedeutet nicht unbedingt, dass der Datensatz insgesamt vielfältig ist, da die MWPs *innerhalb* der Test- und Trainingsdatensätze einander sehr ähnlich sein können. Dies wird durch Abbildung 7 gestützt, die zeigt, dass die Diversität *innerhalb* des Testdatensatzes von MathQA relativ gering ist (0,27), was auf eine Ähnlichkeit zwischen den Testdatensatzproblemen selbst hindeutet.;Yes, MathQA has the highest lexicon usage diversity between its test and training sets (0.85). This seemingly contradicts the low overall corpus diversity of MathQA (0.05 as mentioned in Figure 1). However, the text explains that this high value between test and training sets can be misleading. A high value here doesn't necessarily mean the dataset is diverse overall, as the MWPs *within* the test and training sets could be very similar to each other. This is supported by Figure 7, which shows that the diversity *within* MathQA's test set is relatively low (0.27), suggesting similarity among the test set problems themselves.;Ja/Irreführend;Yes/Misleading;Caption Question/Complex Calculation and Logical Reasoning;''
2020.acl-main.94.pdf-Figure2.png;Welche Linienart wird für die Datenreihe 'ja' verwendet?;What line style is used for the data series labeled 'ja'?;Die Datenreihe 'ja' wird durch eine gepunktete Linie dargestellt.;The data series labeled 'ja' is represented by a dotted line.;Gepunktet;Dotted;Simple Retrieval;''
2020.acl-main.94.pdf-Figure2.png;Was ist der BLI (mrr) Wert für 'fr' bei Fenstergröße 10 im NOUN-Diagramm?;What is the BLI (mrr) value for 'fr' at window size 10 in the NOUN plot?;Ungefähr 0.53.;Approximately 0.53.;0.53;0.53;Simple Retrieval;''
2020.acl-main.94.pdf-Figure2.png;Im NOUN-Diagramm, wie hoch ist die Differenz zwischen dem BLI (mrr) Wert von 'fr' und dem von 'de' bei Fenstergröße 5?;In the NOUN plot, what is the difference between the BLI (mrr) value of 'fr' and 'de' at window size 5?;Ungefähr 0.45 - 0.30 = 0.15.;Approximately 0.45 - 0.30 = 0.15.;0.15;0.15;Simple Calculation;''
2020.acl-main.94.pdf-Figure2.png;Berechnen Sie die durchschnittliche BLI (mrr) Leistung für 'ru' über alle Fenstergrößen in den Diagrammen für NOUN, VERB, ADJ und ADV. Welcher Pos-Tag hat die höchste durchschnittliche Leistung?;Calculate the average BLI (mrr) performance for 'ru' across all window sizes in the NOUN, VERB, ADJ, and ADV plots.  Which plot has the highest average performance?;Das NOUN-Diagramm hat die höchste durchschnittliche BLI (mrr) Leistung für 'ru'.;The NOUN plot has the highest average BLI (mrr) performance for 'ru'.;NOUN;NOUN;Complex Calculation and Logical Reasoning;''
2020.acl-main.94.pdf-Figure2.png;In Abbildung 2 wird die BLI-Leistung für verschiedene Wortarten und Fenstergrößen dargestellt. Ausgehend von den in der Abbildung dargestellten Trends: Wenn Sie bilinguale Worteinbettungen für eine nachgeschaltete Aufgabe trainieren würden, bei der die genaue Darstellung von Verben priorisiert wird, würden Sie eine größere oder kleinere Fenstergröße wählen und warum? Begründen Sie Ihre Argumentation anhand der Abbildung.;Figure 2 presents BLI performance across different parts of speech and window sizes. Based on the trends shown in the figure: If you were to train bilingual word embeddings for a downstream task prioritizing accurate representation of verbs, would you choose a larger or smaller window size, and why? Explain your reasoning referencing the figure.;Eine kleinere Fenstergröße, etwa 5, wäre vorzuziehen. Im VERB-Diagramm stagniert die Leistung oder nimmt jenseits einer Fenstergröße von 5 leicht ab. Kleinere Fenstergrößen erfassen mehr lokalen Kontext, was für Verben relevanter sein könnte.;A smaller window size, around 5, would be preferable.  In the VERB plot, performance plateaus or slightly decreases beyond a window size of 5. Smaller window sizes capture more local context, which could be more relevant for verbs.;Kleiner;Smaller;Complex Calculation and Logical Reasoning;''
2020.acl-main.94.pdf-Figure3.png;Welche Sprache wird durch die gepunktete Linie dargestellt?;Which language is represented by the dotted line?;Japanisch (ja);Japanese (ja);Japanisch;Japanese;Simple Retrieval;''
2020.acl-main.94.pdf-Figure3.png;Was ist der BLI (mrr)-Wert für Französisch (fr) bei einer Fenstergröße von 2?;What is the BLI (mrr) value for French (fr) at a window size of 2?;0,28;0.28;0,28;0.28;Simple Retrieval;''
2020.acl-main.94.pdf-Figure3.png;Was ist die Differenz zwischen dem höchsten BLI (mrr)-Wert für Deutsch (de) und dem höchsten BLI (mrr)-Wert für Japanisch (ja)?;What is the difference between the highest BLI (mrr) value for German (de) and the highest BLI (mrr) value for Japanese (ja)?;0,12;0.12;0,12;0.12;Simple Calculation;''
2020.acl-main.94.pdf-Figure3.png;Bei welcher Fenstergröße ist der vertikale Abstand zwischen den Linien für Russisch (ru) und Japanisch (ja) am geringsten?;At which window size is the vertical distance between the lines for Russian (ru) and Japanese (ja) the smallest?;2;2;2;2;Simple Calculation;''
2020.acl-main.94.pdf-Figure3.png;Der Text erwähnt, dass größere Kontextfenster dazu neigen, thematische Ähnlichkeiten von Wörtern zu erfassen. Stimmt diese Beobachtung mit den Ergebnissen dargestellten in Abbildung 3 überein, die die BLI-Leistung im vergleichbaren Setting zeigen?  Beziehen Sie sich in Ihrer Antwort auf bestimmte Sprachen und deren BLI-Werte bei verschiedenen Fenstergrößen, um Ihre Argumentation zu untermauern.;The text mentions that larger context windows tend to capture topical similarities of words. Does this observation align with the results presented in Figure 3, which shows BLI performance in the comparable setting?  Refer to specific languages and their BLI values at different window sizes in your answer to support your reasoning.;Ja, die Beobachtung stimmt mit Abbildung 3 überein. Mit zunehmender Größe des Quell-/Zielfensters verbessert sich die BLI-Leistung im Allgemeinen für alle Sprachen. Französisch (fr) steigt beispielsweise von etwa 0,11 bei einer Fenstergröße von 1 auf etwa 0,50 bei einer Fenstergröße von 20. Ähnliche Aufwärtstrends sind bei Deutsch (de), Russisch (ru) und Japanisch (ja) zu beobachten, was die Idee unterstützt, dass größere Kontextfenster, die mehr thematische Informationen erfassen, zu einer besseren BLI-Leistung führen.;Yes, the observation aligns with Figure 3.  As the source/target window size increases, the BLI performance generally improves for all languages. For example, French (fr) goes from roughly 0.11 at a window size of 1 to approximately 0.50 at a window size of 20. Similar upward trends are observed for German (de), Russian (ru), and Japanese (ja), supporting the idea that larger context windows capturing more topical information lead to better BLI performance.;Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;''
2007.sigdial-1.12.pdf-Figure6.png;Wie hoch ist der Balken bei n=0?;What is the height of the bar at n=0?;0,325;0.325;0,325;0.325;Simple Retrieval;''
2007.sigdial-1.12.pdf-Figure6.png;Was ist die Differenz zwischen den Höhen der Balken bei n=1 und n=2?;What is the difference between the heights of the bars at n=1 and n=2?;0,08;0.08;0,08;0.08;Simple Calculation;''
2007.sigdial-1.12.pdf-Figure6.png;Was ist die Summe der Höhen aller Balken, die größer als 0,1 sind?;What is the sum of the heights of all bars greater than 0.1?;1,3;1.3;1,3;1.3;Complex Calculation and Logical Reasoning;''
2007.sigdial-1.12.pdf-Figure6.png;Ist die durchschnittliche Höhe der Balken bei n=2, n=3 und n=4 größer als die Höhe des Balkens bei n=1?;Is the average height of the bars at n=2, n=3, and n=4 greater than the height of the bar at n=1?;Ja;Yes;Ja;Yes;Complex Calculation and Logical Reasoning;''
2007.sigdial-1.12.pdf-Figure6.png;Basierend auf Abbildung 6, wie verhält sich die ROC-Fläche für n=0 im Vergleich zu den ROC-Flächen für n=1 bis n=6?;Based on Figure 6, how does the ROC area for n=0 compare to the ROC areas for n=1 through n=6?;Die ROC-Fläche für n=0 (die n* darstellt) ist im Vergleich zu den ROC-Flächen für n=1 bis n=6 am höchsten.;The ROC area for n=0 (representing n*) is the highest compared to the ROC areas for n=1 through n=6.;Höchste;Highest;Caption Question/Simple Calculation;''
2007.sigdial-1.23.pdf-Figure3.png;'Welche Farbe hat der Balken, der ''real'' darstellt?';'What color is the bar representing ''real''?';Hellgrau.;Light gray.;Hellgrau;Light gray;Simple Retrieval;''
2007.sigdial-1.23.pdf-Figure3.png;'Was ist der Unterschied zwischen den Werten von ''real'' und ''subject'' für ''U_word''?';'What is the difference between the values of ''real'' and ''subject'' for ''U_word''?';Ungefähr 1,7.;Approximately 1.7.;1,7;1.7;Simple Calculation;''
2007.sigdial-1.23.pdf-Figure3.png;'Ist die Summe der Werte für ''real'' bei ''dialogLen'' und ''turn'' größer als der Wert für ''subject'' bei ''U_word''?';'Is the sum of the values for ''real'' at ''dialogLen'' and ''turn'' greater than the value for ''subject'' at ''U_word''?';'Nein. Die Summe der ''real''-Werte für ''dialogLen'' und ''turn'' beträgt ca. 2,0, was weniger ist als der ''subject''-Wert für ''U_word'' von ca. 2,7.';'No. The sum of the ''real'' values for ''dialogLen'' and ''turn'' is approximately 2.0, which is less than the ''subject'' value for ''U_word'', approximately 2.7.';Nein;No;Complex Calculation and Logical Reasoning;''
2007.sigdial-1.23.pdf-Figure3.png;'Welche der Kategorien ''dialogLen'', ''turn'', ''U_word'', ''U_action'', ''S_action'' und ''Ratio_action'' weist den größten Höhenunterschied zwischen dem hellgrauen (''real'') und dunkelgrauen (''subject'') Balken auf?';'Which of the categories ''dialogLen'', ''turn'', ''U_word'', ''U_action'', ''S_action'', and ''Ratio_action'' has the largest difference in height between the light gray (''real'') and dark gray (''subject'') bars?';U_word;U_word;U_word;U_word;Simple Calculation;''
2007.sigdial-1.23.pdf-Figure3.png;Der Text erwähnt, dass Probanden im Vergleich zu realen Nutzern im Durchschnitt mehr Wörter pro Äußerung verwenden.  Welche Schlussfolgerung lässt Abbildung 3 in Bezug auf die durchschnittliche Anzahl von Wörtern pro Äußerung im Vergleich zwischen Probanden und realen Nutzern zu? Erklären Sie den scheinbaren Widerspruch.;The text mentions that subjects use significantly more words per utterance than users, on average. What conclusion does Figure 3 suggest regarding the average number of words per utterance when comparing subjects and users? Explain this apparent contradiction.;Abbildung 3 zeigt die *relativen* Mittelwerte der High-Level-Dialogmerkmale. Während Probanden höhere absolute Werte für Wörter pro Äußerung haben, normiert Abbildung 3 diese Werte relativ zum Nutzerkorpus. Daher zeigt die Abbildung, wie viel *größer* die Probandenwerte im Vergleich zu den Nutzerwerten sind und nicht die absolute Anzahl der Wörter pro Äußerung. Der scheinbare Widerspruch ergibt sich aus dem Normalisierungsprozess, der verwendet wird, um die Daten in einer vergleichbaren Weise innerhalb eines einzigen Diagramms darzustellen.;Figure 3 shows the *relative* means of high-level dialog features. While subjects have higher absolute values for words per utterance, Figure 3 normalizes these values relative to the user corpus. Therefore, the figure displays how much *larger* the subject values are compared to user values, rather than the absolute number of words per utterance. The apparent contradiction arises from the normalization process used to present the data in a comparable way within a single chart.;Relativ, nicht absolut;Relative, not absolute;Caption Question/Complex Calculation and Logical Reasoning;''
2007.sigdial-1.27.pdf-Figure1.png;Wie hoch ist der Balken für Sprecher-ID 1084?;What is the height of the bar for Speaker ID 1084?;Ungefähr 18%;Approximately 18%;18%;18%;Simple Retrieval;''
2007.sigdial-1.27.pdf-Figure1.png;Was ist der Unterschied in der Prozent-Akzentuierung zwischen Sprecher 1014 und Sprecher 1024?;What is the difference in Percent-Accentuation between speaker 1014 and speaker 1024?;Ungefähr 24%;Approximately 24%;24%;24%;Simple Calculation;''
2007.sigdial-1.27.pdf-Figure1.png;Wie hoch ist die durchschnittliche Prozent-Akzentuierung der drei Sprecher mit den höchsten Werten?;What is the average Percent-Accentuation of the three speakers with the highest values?;Ungefähr 38%;Approximately 38%;38%;38%;Complex Calculation and Logical Reasoning;''
2007.sigdial-1.27.pdf-Figure1.png;Wie viele Sprecher haben eine Prozent-Akzentuierung von weniger als 10%?;How many speakers have a Percent-Accentuation of less than 10%?;10;10;10;10;Simple Calculation;''
2007.sigdial-1.27.pdf-Figure1.png;Der Text erwähnt, dass frühere Studien durch inter-speaker Variationen behindert wurden. Betrachtet man Abbildung 1, wie hoch ist die Prozent-Akzentuierung des Sprechers mit der höchsten Akzentuierung im Vergleich zum Durchschnitt aller Sprecher? Bestätigt diese Diskrepanz die Behauptung, dass inter-speaker Variationen die Verallgemeinerung früherer Ergebnisse erschwert haben?;The text mentions that prior studies were hindered by inter-speaker variations. Considering Figure 1, what is the percent-accentuation of the speaker with the highest accentuation compared to the average of all speakers? Does this discrepancy support the claim that inter-speaker variations made it difficult to generalize prior findings?;Der Sprecher mit der höchsten Akzentuierung (1064) hat ungefähr 47% Akzentuierung. Durch visuelle Schätzung liegt der Durchschnitt bei etwa 12%. Dieser signifikante Unterschied unterstützt die Behauptung des Artikels, dass Unterschiede zwischen den Sprechern die Verallgemeinerung früherer Ergebnisse erschwert haben.;The speaker with the highest accentuation (1064) has approximately 47% accentuation. Visually estimating, the average appears around 12%. This significant difference (25%) supports the paper's claim that inter-speaker variations hindered the generalization of prior findings.;Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;''
2014.lilt-11.3.pdf-Figure2.png;Welches Wort steht ganz oben an der y-Achse?;Which word is at the very top of the y-axis?;-ing;-ing;-ing;-ing;Simple Retrieval;''
2014.lilt-11.3.pdf-Figure2.png;Was ist die Summe der Werte der beiden kürzesten Balken?;What is the sum of the values of the two shortest bars?;Ungefähr 0,0051;Approximately 0.0051;0,0051;0.0051;Simple Calculation;''
2014.lilt-11.3.pdf-Figure2.png;'Ist der Durchschnitt der Werte für ''-ing'', ''-ed'' und ''genitive s'' größer oder kleiner als der Wert für ''plural -s''?';'Is the average of the values for ''-ing'', ''-ed'', and ''genitive s'' greater or less than the value for ''plural -s''?';Kleiner. Der Durchschnitt von '-ing', '-ed' und 'genitive s' ist ungefähr 0,0028, während der Wert für 'plural -s' bei etwa 0,004 liegt.;Less. The average of '-ing', '-ed', and 'genitive s' is approximately 0.0028, while the value for 'plural -s' is approximately 0.004.;Kleiner;Less;Complex Calculation and Logical Reasoning;''
2014.lilt-11.3.pdf-Figure2.png;Welcher Balken hat den höchsten Wert und welcher den niedrigsten?;Which bar has the highest value, and which has the lowest?;Der Balken für '3rd ps sg-s' hat den höchsten Wert, und der Balken für '-ing' hat den niedrigsten Wert.;The bar for '3rd ps sg-s' has the highest value, and the bar for '-ing' has the lowest value.;3rd ps sg-s, -ing;3rd ps sg-s, -ing;Simple Retrieval;''
2014.lilt-11.3.pdf-Figure2.png;'In der Arbeit wird die Standardabweichung für morphologische Komplexität in den morph-manipulierten Texten erörtert. Wie verhält sich die in Abbildung 2 dargestellte erhöhte morphologische Komplexität durch das Hinzufügen der dritten Person Singular ''-s'' zur Veränderung der syntaktischen Komplexität im Vergleich zum Originaltext (unter Berücksichtigung von Abbildung 1 und Tabelle 2)?';The paper discusses the standard deviation for morphological complexity in the morph-manipulated texts. Considering the increased morphological complexity from the addition of the third-person singular '-s' shown in Figure 2, how does this relate to the change in syntactic complexity compared to the original text (using Figure 1 and Table 2)?;'Das Hinzufügen des ''-s'' der dritten Person Singular erhöht die morphologische Komplexität (Abbildung 2), verringert aber die syntaktische Komplexität im Vergleich zum Originaltext (Abbildung 1). Tabelle 2 zeigt niedrige Standardabweichungen für die morphologische Komplexität sowohl des Originaltexts als auch des Texts mit hinzugefügtem ''-s'', was darauf hindeutet, dass der beobachtete Anstieg der morphologischen Komplexität statistisch signifikant ist.';Adding the third-person singular '-s' increases morphological complexity (Figure 2), but decreases syntactic complexity compared to the original text (Figure 1). Table 2 shows low standard deviations for the morphological complexity of both the original and the '-s' added text, suggesting that the observed increase in morphological complexity is statistically significant.;Morphologisch erhöht, syntaktisch verringert;Morphologically increases, syntactically decreases;Requires Paper Context;"Morph Standard deviation  Morphological complexity Syntactic complexity  original 0.00123 0.00136 –ing 0.00119 0.00132 –ed 0.00127 0.00132 genitive ’s 0.00125 0.00131 plural –s 0.00119 0.00132 3rd person singular –s 0.0012 0.00132

TABLE 2 Dispersion across individual measuring points of morphological and syntactic complexity scores in the mixed-genre corpus by morph.

FIGURE 1 Morphological by syntactic complexity of morph-manipulated texts and original text. Abscissa indexes increased syntactic complexity, ordinate indexes increased morphological complexity."
2014.lilt-11.3.pdf-Figure6.png;Welche syntaktische Konstruktion hat die geringste durchschnittliche Komplexität?;Which syntactic construction has the lowest average complexity?;'''Going to''';'''Going to''';'Going to';'Going to';Simple Retrieval;
2014.lilt-11.3.pdf-Figure6.png;Welche Konstruktion hat die höchste durchschnittliche syntaktische Komplexität?;Which construction has the highest average syntactic complexity?;Perfekt;Perfect;Perfekt;Perfect;Simple Retrieval;
2014.lilt-11.3.pdf-Figure6.png;'Ist die durchschnittliche syntaktische Komplexität von ''Progressive'' größer oder kleiner als die von ''Will''?';'Is the average syntactic complexity of ''Progressive'' greater or less than that of ''Will''?';Größer als;Greater than;Größer;Greater;Simple Calculation;
2014.lilt-11.3.pdf-Figure6.png;'Ist die kombinierte durchschnittliche syntaktische Komplexität von ''Going to'' und ''Will'' größer oder kleiner als die von ''Passive''?';'Is the combined average syntactic complexity of ''Going to'' and ''Will'' greater or less than that of ''Passive''?';Kleiner als;Less than;Kleiner;Less;Complex Calculation and Logical Reasoning;
2014.lilt-11.3.pdf-Figure6.png;'Der Text erwähnt, dass die Komplexität von ''Going to'' möglicherweise mit seiner Häufigkeit zusammenhängt. Stimmt diese Beobachtung mit der im Diagramm dargestellten syntaktischen Komplexität überein? Begründen Sie Ihre Antwort.';'The text mentions that the complexity of ''Going to'' might be related to its frequency. Does this observation align with the syntactic complexity shown in the chart? Explain your reasoning.';'Ja, die Beobachtung stimmt mit dem Diagramm überein. ''Going to'' hat die niedrigste syntaktische Komplexität, was darauf hindeutet, dass seine geringe Häufigkeit, wie im Text erwähnt (dreizehn Vorkommnisse), mit seiner Einfachheit zusammenhängen könnte.';'Yes, the observation aligns with the chart. ''Going to'' has the lowest syntactic complexity, suggesting that its low frequency, as mentioned in the text (thirteen occurrences), might be related to its simplicity.';Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;'Despite the fact that fre- quency is not a factor influencing construction complexity in general (see below), it seems plausible that the complexity of going to which occurs only thirteen times in total, might be related to its frequency.'
2016.jeptalnrecital-jep.22.pdf-Figure4.png;Welcher Balken ist höher?;Which bar is taller?;'Der Balken für ''Répétitions pathologiques'' ist höher.';'The bar for ''Répétitions pathologiques'' is taller.';'Répétitions pathologiques';'Répétitions pathologiques';Caption Question/Simple Retrieval;''
2016.jeptalnrecital-jep.22.pdf-Figure4.png;Wie groß ist der ungefähre Höhenunterschied zwischen den beiden Balken?;What is the approximate difference in height between the two bars?;Ungefähr 0,7;Approximately 0.7;0,7;0.7;Caption Question/Simple Calculation;''
2016.jeptalnrecital-jep.22.pdf-Figure4.png;Ist die Summe der Höhen beider Balken größer als 3?;Is the sum of the heights of both bars greater than 3?;Ja, die ungefähre Summe ist 1,4 + 2,1 = 3,5, was größer als 3 ist.;Yes, the approximate sum is 1.4 + 2.1 = 3.5, which is greater than 3.;Ja;Yes;Caption Question/Simple Calculation;''
2016.jeptalnrecital-jep.22.pdf-Figure4.png;Ist der Unterschied zwischen den Höhen der beiden Balken größer als die Hälfte der Höhe des kleineren Balkens?;Is the difference between the heights of the two bars greater than half the height of the smaller bar?;'Die Differenz beträgt etwa 0,7. Die Hälfte der Höhe des kleineren Balkens (''Répétitions normales'') beträgt etwa 0,7. Daher ist die Differenz ungefähr gleich der Hälfte der Höhe des kleineren Balkens, nicht größer.';'The difference is approximately 0.7. Half the height of the smaller bar (''Répétitions normales'') is about 0.7. Therefore, the difference is approximately equal to half the height of the smaller bar, not greater.';Nein;No;Caption Question/Simple Calculation;''
2016.jeptalnrecital-jep.22.pdf-Figure4.png;Die Studie erwähnt, dass Phonemwiederholungen charakteristischer für schwere Dysfluenzen sind. Unterstützen die in Abbildung 4 dargestellten Durchschnittswerte diese Beobachtung über Phonemwiederholungen, und warum oder warum nicht?;The study mentions that phoneme repetitions are more characteristic of severe disfluencies. Do the displayed averages in Figure 4 support this observation about phoneme repetitions, and why or why not?;Die Abbildung zeigt eine höhere durchschnittliche Anzahl von Wiederholungen bei pathologischen Dysfluenzen (2,1) im Vergleich zu normalen Dysfluenzen (1,4). Die Abbildung liefert jedoch keine Aufschlüsselung der Arten von Wiederholungen (z. B. Phonem, Silbe, Wort). Daher zeigt die Abbildung zwar mehr Wiederholungen bei schweren Dysfluenzen, bestätigt aber nicht direkt, dass es sich dabei speziell um Phonemwiederholungen handelt.;The figure shows a higher average number of repetitions for pathological disfluencies (2.1) compared to normal disfluencies (1.4). However, the figure does not provide a breakdown of the types of repetitions (e.g., phoneme, syllable, word). Therefore, while the figure demonstrates more repetitions in severe disfluencies, it doesn't directly confirm that these are specifically phoneme repetitions.;Nein;No;Caption Question/Complex Calculation and Logical Reasoning;''
2016.jeptalnrecital-jep.60.pdf-Figure1.png;Welche Beschriftung befindet sich unter der ersten Balken Gruppe von links?;What label is below the leftmost group of bars?;spontané;spontané;spontané;spontané;Simple Retrieval;''
2016.jeptalnrecital-jep.60.pdf-Figure1.png;'Was ist die Differenz zwischen dem höchsten und dem niedrigsten Balken in der ''spontané'' Gruppe?';'What is the difference between the highest and lowest bar in the ''spontané'' group?';Ungefähr 10.;Approximately 10.;10;10;Simple Calculation;''
2016.jeptalnrecital-jep.60.pdf-Figure1.png;Wie hoch ist die Summe der Werte aller weißen Balken?;What is the sum of the values of all white bars?;Ungefähr 75.;Approximately 75.;75;75;Simple Calculation;''
2016.jeptalnrecital-jep.60.pdf-Figure1.png;'Ist der Durchschnittswert der Balken in der ''lecture'' Gruppe höher als der Durchschnittswert der Balken in der ''spontané'' Gruppe?  Berechnen Sie die Durchschnittswerte und geben Sie diese in Ihrer Antwort an.';'Is the average value of the bars in the ''lecture'' group higher than the average value of the bars in the ''spontané'' group? Calculate the averages and state them in your answer.';'Der Durchschnittswert für die ''lecture'' Gruppe ist ungefähr 42,75, und der Durchschnittswert für die ''spontané'' Gruppe ist ungefähr 29. Ja, der Durchschnitt der ''lecture'' Gruppe ist höher.';'The average value for the ''lecture'' group is approximately 42.75, and the average value for the ''spontané'' group is approximately 29. Yes, the average for the ''lecture'' group is higher.';Ja;Yes;Complex Calculation and Logical Reasoning;''
2016.jeptalnrecital-jep.60.pdf-Figure1.png;Abbildung 1 zeigt die durchschnittliche Anzahl produzierter zweisilbiger Wörter für verschiedene Gruppen. Tabelle 1 im Text enthält die Schweregrade der Dysarthrie für spontanes Sprechen. Gibt es einen Zusammenhang zwischen dem Schweregrad der Dysarthrie und der Anzahl der produzierten Wörter in spontaner Sprache laut Abbildung 1 und Tabelle 1?  Begründen Sie Ihre Antwort.;Figure 1 shows the average number of disyllabic words produced for different groups. Table 1 in the text shows the severity ratings of dysarthria for spontaneous speech. Is there a correlation between the severity of dysarthria and the number of words produced in spontaneous speech according to Figure 1 and Table 1? Explain your answer.;Tabelle 1 zeigt, dass die SLA-Gruppe die höchste Schweregradbewertung (2,02) in der Spontansprache aufweist. Abbildung 1 zeigt, dass die SLA-Gruppe weniger zweisilbige Wörter produziert (etwa 25) im Vergleich zur CTRL-Gruppe (etwa 32). Dies deutet auf eine negative Korrelation hin, bei der höhere Schweregrade mit einer geringeren Anzahl produzierter Wörter verbunden sind.  Es sind jedoch weitere Analysen erforderlich, um diesen Zusammenhang und seine Natur zu bestätigen, da mehr Daten benötigt werden, bevor eine definitive Schlussfolgerung gezogen werden kann.;Table 1 shows that the SLA group has the highest severity rating (2.02) in spontaneous speech. Figure 1 indicates that the SLA group produces fewer disyllabic words (around 25) compared to the CTRL group (around 32). This suggests a negative correlation where higher severity ratings are associated with a lower number of words produced. However, further analysis is required to confirm this relationship and its nature, as more data is needed before drawing a definite conclusion.;Negative Korrelation;Negative correlation;Requires Paper Context;"Degrés de Sévérité Populations Age

Lecture Spontanée

CTRL 69 <63-82> x x

PARK 64.5 <48-83> 0.84 <0.37-1.37> 0.99 <0.36-1.64>

SLA 66 <50-81> 2.05 <0.91-2.91> 2.02 <1.18-2.73>

ATAX 55 <32-77> 1.28 <0.82-2.09> 1.23 <0.64-1.9>

TABLE 1 : Ages et degrés de sévérité en lecture et en spontanée pour chaque population

étudiée. CTRL: sujets contrôles, PARK: sujets atteints de Parkinson, SLA: sujets atteints de

SLA, ATAX: sujets atteints d'ataxie cérébelleuse. Moyenne <min-max>"
2016.lilt-13.2.pdf-Figure2.png;Welche Beschriftung auf der x-Achse hat den höchsten Balken für A1 (blau)?;Which label on the x-axis corresponds to the tallest bar for A1 (blue)?;all;all;all;all;Simple Retrieval;''
2016.lilt-13.2.pdf-Figure2.png;Was ist die Summe der Proportionen der Annotationen von A2 (rot) für die Beschriftungen 'kind', 'no' und 'few'?;What is the sum of the proportions of annotations by A2 (red) for the labels 'kind', 'no', and 'few'?;Ungefähr 0,02;Approximately 0.02;0,02;0.02;Simple Calculation;''
2016.lilt-13.2.pdf-Figure2.png;'Ist die Proportion der Annotationen von A3 (grau) bei ''most'' größer oder kleiner als die von A2 (rot) bei ''some''?';'Is the proportion of annotations by A3 (grey) at ''most'' greater or less than that of A2 (red) at ''some''?';Kleiner;Less;Kleiner;Less;Simple Calculation;''
2016.lilt-13.2.pdf-Figure2.png;'Welche zwei Beschriftungen auf der x-Achse haben zusammen eine höhere Proportion an Annotationen für A2 als die Beschriftung ''all'' für A1?';'Which two x-axis labels have a combined proportion of annotations for A2 that is greater than the proportion of annotations for A1 at ''all''?';'Keine zwei Beschriftungen für A2 haben zusammen eine größere Proportion als A1 bei ''all''.';'No two labels combined for A2 have a greater proportion than A1 at ''all''.';Keine;No;Complex Calculation and Logical Reasoning;''
2016.lilt-13.2.pdf-Figure2.png;'Die Arbeit erwähnt die Minimierung pragmatischer Interferenzen bei der Auswahl von Quantoren. Inwiefern könnte die in der Abbildung dargestellte Verteilung, insbesondere die hohe Verwendung von ''all'' durch A1, diese Interferenzen widerspiegeln?  Beziehen Sie sich dabei auf die im Text beschriebene ''normative'' Interpretation der Welt durch A1.';'The paper mentions minimizing pragmatic interferences in quantifier selection. How might the distribution shown in the figure, specifically the frequent use of ''all'' by A1, reflect these interferences? Refer to the ''normative'' interpretation of the world by A1 as described in the text.';'Die häufige Verwendung von ''all'' durch A1 spiegelt eine normative Interpretation wider, die sich auf die beabsichtigte Funktion anstatt auf reale Ausnahmen konzentriert. Dies minimiert pragmatische Interferenzen, führt aber zu einer Überschätzung universeller Quantoren, wie im Beispiel ''Krankenwagen'' gezeigt.';'A1's frequent use of ''all'' reflects a normative interpretation, focusing on intended function over real-world exceptions. This minimizes pragmatic interferences but leads to an overestimation of universal quantifiers, as seen in the 'ambulance' example.';Normative Interpretation;Normative Interpretation;Requires Paper Context;'A1, in particular, uses all extensively, applying the label to over 70% of the McRae instances. A manual analysis of the data reveals that the annotator may have interpreted their model of the world in a much more normative way than the other participants. For instance, they may have labelled the pair ambulance – used-for-rescuing with a universal under the assumption that the intrinsic function of an ambulance is to rescue people, regardless of the fact that some ambulances might finish their days as museum objects or converted vehicles.'
2019.jeptalnrecital-tia.5.pdf-Figure2.png;Was steht auf der horizontalen Achse?;What is the label of the horizontal axis?;Domänen;Domains;Domänen;Domains;Simple Retrieval;''
2019.jeptalnrecital-tia.5.pdf-Figure2.png;'Welcher Wert ist größer: der Entropiewert des dunkelgrauen Balkens (Base) für ''Agr'' oder der Entropiewert des hellgrauen Balkens (Selection) für ''Agr''?';'Which value is greater: the entropy value of the dark gray bar (Base) for ''Agr'' or the entropy value of the light gray bar (Selection) for ''Agr''?';Der dunkelgraue Balken (Base) hat einen größeren Entropiewert.;The dark gray bar (Base) has a greater entropy value.;Base;Base;Simple Calculation;''
2019.jeptalnrecital-tia.5.pdf-Figure2.png;'Wie hoch ist der durchschnittliche Entropiewert über alle Bereiche für die Datenreihe ''Classificatory (det)'' (hellgrauester Balken)?';'What is the average entropy value across all domains for the ''Classificatory (det)'' data series (lightest gray bar)?';Ungefähr 7.3;Approximately 7.3;7.3;7.3;Complex Calculation and Logical Reasoning;''
2019.jeptalnrecital-tia.5.pdf-Figure2.png;'In welchen Bereichen ist die Entropie für ''Base'' größer als 8.5?';'In which domains is the entropy for ''Base'' greater than 8.5?';Agr, Bot, Chm und Psy;Agr, Bot, Chm and Psy;Agr, Bot, Chm, Psy;Agr, Bot, Chm, Psy;Simple Calculation;''
2019.jeptalnrecital-tia.5.pdf-Figure2.png;'Der Text erwähnt, dass die Spezifikations- und Klassifikationsebenen im Allgemeinen ''strukturierter'' sind als die Selektionsebene. Welche visuellen Beobachtungen in Abbildung 2 stützen diese Aussage, und welche widersprechen ihr?';'The text mentions that the specification and classification layers are generally ''more structured'' than the selection layer. Which visual observations in Figure 2 support this statement, and which contradict it?';Im Allgemeinen sind die Balken für 'Specification' und 'Classificatory' niedriger als der 'Selection'-Balken, was auf eine höhere Strukturiertheit hinweist. In 'Cmp' und etwas in 'Agr' sind die Balken für 'Specification (det)' und 'Classificatory (det)' jedoch höher als für 'Selection', was dem allgemeinen Trend widerspricht.;Generally, the 'Specification' and 'Classificatory' bars are lower than the 'Selection' bar, indicating higher structuredness.  However, in 'Cmp' and slightly in 'Agr', the 'Specification (det)' and 'Classificatory (det)' are higher than 'Selection', contradicting the general trend.;niedriger;Lower;Caption Question/Complex Calculation and Logical Reasoning;''
2020.acl-demos.20.pdf-Figure3.png;Welche Datenreihe wird durch die lila Farbe dargestellt?;Which data series is represented by the purple color?;Alle Daten;All data;Alle Daten;All data;Simple Retrieval;''
2020.acl-demos.20.pdf-Figure3.png;'Was ist der BLEU-Wert für ''ROC_AUC'' bei Verwendung von 60 % der Daten?';'What is the BLEU score for ''ROC_AUC'' when using 60% of the data?';11.41;11.41;11,41;11.41;Simple Retrieval;''
2020.acl-demos.20.pdf-Figure3.png;Was ist die Differenz zwischen dem höchsten und dem niedrigsten BLEU-Wert bei Verwendung von 70 % der Daten?;What is the difference between the highest and the lowest BLEU score when using 70% of the data?;0,28 (11,62 - 11,34);0.28 (11.62 - 11.34);0,28;0.28;Simple Calculation;''
2020.acl-demos.20.pdf-Figure3.png;Wie hoch ist der durchschnittliche BLEU-Score über alle Datenreihen bei 50 % Datennutzung und bei 100 % Datennutzung?  Wie groß ist die Differenz zwischen diesen beiden Durchschnittswerten?;What is the average BLEU score across all data series when using 50% of the data and when using 100% of the data? What is the difference between these two averages?;Der durchschnittliche BLEU-Score bei 50% Datennutzung beträgt 11,29. Der BLEU-Score bei 100% Datennutzung beträgt 11,43. Die Differenz beträgt 0,14.;The average BLEU score at 50% data usage is 11.29. The BLEU score at 100% data usage is 11.43. The difference is 0.14.;0,14;0.14;Complex Calculation and Logical Reasoning;''
2020.acl-demos.20.pdf-Figure3.png;In Abschnitt 3.2 wird die Filterung nach Cross-Entropy und der ursprünglichen Reihenfolge (bicleaner) verglichen.  Analysieren Sie Abbildung 2 und beschreiben Sie den Einfluss beider Filtermethoden auf den BLEU-Score bei verschiedenen Datenanteilen. Welche Methode schneidet bei weniger als 100% der Daten konsistent besser ab und warum könnte das laut Abschnitt 3.2 der Fall sein?;Section 3.2 compares filtering by cross-entropy to the original order (bicleaner). Analyze Figure 2 and describe the impact of both filtering methods on the BLEU score at different data percentages. Which method consistently performs better when using less than 100% of the data, and according to Section 3.2, why might this be the case?;Die Filterung nach Cross-Entropy (CE) liefert bei Datenanteilen unter 100% durchweg bessere Ergebnisse als die ursprüngliche Reihenfolge (bicleaner). Laut Abschnitt 3.2 liegt das daran, dass CE effektiv verrauschte Daten entfernt und gleichzeitig relevante Daten für die Modellverbesserung erhält. Die ursprüngliche Reihenfolge entfernt Daten wahllos, was die Leistung beeinträchtigt.;Cross-entropy filtering (CE) consistently outperforms the original order (bicleaner) for data percentages below 100%. Section 3.2 explains this by CE's ability to remove noisy data while preserving data relevant for model improvement. The original order indiscriminately removes data, degrading performance.;Cross-Entropy;Cross-entropy;Requires Paper Context;"In this section, we compare the results of models trained with data in the original (bicleaner) order and in the order of our classifier using the different data splits described above. We also test the ROC AUC model for which we created a small development set of 200 randomly selected segment pairs that have manually been annotated as noisy or clean (100 examples each). A pair was annotated noisy only in the case of serious problems; sentences with single translation errors or relatively poor fluency were still considered clean. Figure 2 provides an overview of the results for Finnish to English. We can see that our filtering method is very effective. Removing noisy data according to the ranking produced by our tool improves the BLEU score compared to the model that applies the whole ParaCrawl data. In contrast, removing data based on the original ParaCrawl order degrades the BLEU score at all cutoff points. When using cross-entropy based sorting of the data, cutting off 40% of the lowest scoring training pairs increased BLEU by 0.67 points when compared to using the full training set. If more than 40% of the data is removed, the BLEU score starts to decrease. Surprisingly, ROC AUC based sorting, which requires a manually annotated development set, produces worse results than cross-entropy. ROC AUC reaches a maximum gain of 0.26 BLEU points over using the whole data set when 20% of the data is truncated from the noisy end."
2020.acl-demos.32.pdf-Figure3.png;Welche Kategorie im ersten Diagramm (a) hat den zweitlängsten Balken?;Which category in the first chart (a) has the second longest bar?;Name_Calling, Labeling;Name-Calling, Labeling;Name_Calling, Labeling;Name-Calling, Labeling;Simple Retrieval;''
2020.acl-demos.32.pdf-Figure3.png;'Wie hoch ist der Prozentsatz für ''Doubt'' im zweiten Diagramm (b)?';'What is the percentage for ''Doubt'' in the second chart (b)?';13;13;13;13;Simple Retrieval;''
2020.acl-demos.32.pdf-Figure3.png;'Im ersten Diagramm (a): Um wie viel Prozentpunkte ist ''Loaded Language'' größer als ''Name Calling, Labeling''?';'In the first chart (a): By how many percentage points is ''Loaded Language'' greater than ''Name Calling, Labeling''?';1016 Instanzen;1016 instances;1016;1016;Simple Calculation;''
2020.acl-demos.32.pdf-Figure3.png;'Addieren Sie die Werte für ''Flag-Waving'' und ''Slogans'' in Diagramm (b). Ist diese Summe größer oder kleiner als der Wert für ''Loaded Language'' in Diagramm (b)?';'Add the values for ''Flag-Waving'' and ''Slogans'' in chart (b). Is this sum greater or less than the value for ''Loaded Language'' in chart (b)?';Die Summe von Flag-Waving und Slogans (88) ist kleiner als der Wert von Loaded Language (112).;The sum of Flag-Waving and Slogans (88) is less than the value of Loaded Language (112).;Kleiner;Smaller;Simple Calculation;''
2020.acl-demos.32.pdf-Figure3.png;'Der Text vergleicht die BBC und Fox News in Bezug auf die Verwendung von Propagandatechniken bei der Berichterstattung über Waffenkontrolle und Waffenrechte.  Welche Technik, abgesehen von ''Loaded Language'', wird von jeder Quelle am häufigsten verwendet, und wie spiegeln diese Entscheidungen laut der Analyse des Artikels möglicherweise ihre unterschiedlichen Berichtsstile wider?';'The paper compares the BBC and Fox News regarding their use of propaganda techniques when reporting on gun control and gun rights. Besides ''Loaded Language,'' which technique is most heavily used by each source, and how do these choices potentially reflect their different reporting styles, according to the paper's analysis?';"BBC: Name_Calling, Labeling (858 Instanzen); Fox News: Flag-Waving und Slogans (beide mit 44 Instanzen). Der Artikel deutet an, dass die BBC durch Labeling gegensätzliche Ansichten kategorisiert und abtut, während Flag-Waving bei Fox News auf einen emotionaleren, patriotischeren Ansatz hindeutet.";"BBC: Name_Calling, Labeling (858 instances); Fox News: Flag-Waving and Slogans (both with 44 instances). The paper suggests BBC's labeling categorizes and dismisses opposing views, while Fox News's Flag-Waving indicates a more emotional, patriotic approach.";"BBC: Name_Calling, Labeling; Fox News: Flag-Waving, Slogans";"BBC: Name_Calling, Labeling; Fox News: Flag-Waving, Slogans";Requires Paper Context;'For example, Figures 3a and 3b show the distribution of the techniques used by the BBC vs. Fox News when covering the topic of Gun Control _and Gun Rights. We can see that both media use_ a lot of loaded language, which is the most common technique media use in general. However, the BBC also makes heavy use of labeling and doubt, whereas Fox News has a higher preference for flag waving and slogans.'
2020.acl-main.217.pdf-Figure2.png;'Welche Farbe repräsentiert die Datenreihe ''Hybrid Cascade''?';'What color represents the ''Hybrid Cascade'' data series?';'Gold/Hellorange repräsentiert die Datenreihe ''Hybrid Cascade''.';'Gold/Light orange represents the ''Hybrid Cascade'' data series.';Gold/Hellorange;Gold/Light orange;Simple Retrieval;''
2020.acl-main.217.pdf-Figure2.png;'Was ist der Unterschied im ΔBLEU zwischen dem Modell ''Phone Cascade'' und dem Modell ''Hybrid Cascade'' bei 20 Stunden Trainingsdaten?';'What is the difference in ΔBLEU between the ''Phone Cascade'' model and the ''Hybrid Cascade'' model at 20 hours of training data?';'Das Modell ''Phone Cascade'' erreicht einen ΔBLEU von 11,3, während das Modell ''Hybrid Cascade'' 1,3 erreicht. Die Differenz beträgt 10.';'The ''Phone Cascade'' model achieves a ΔBLEU of 11.3, while the ''Hybrid Cascade'' model achieves 1.3. The difference is 10.';10;10;Simple Calculation;''
2020.acl-main.217.pdf-Figure2.png;Welche zwei Modelle haben bei 40 Stunden Trainingsdaten einen positiven ΔBLEU und wie hoch ist die Summe ihrer ΔBLEU-Werte?;Which two models have a positive ΔBLEU at 40 hours of training data and what is the sum of their ΔBLEU values?;'Die Modelle ''Phone Cascade'', ''Phone End-to-End'' und Hybrid Cascade haben positive ΔBLEU-Werte bei 40 Stunden. ''Phone Cascade'' hat 10,3, ''Phone End-to-End'' hat 5,0 und Hybrid Cascade hat 4,1. Die Summe ist 19,4.';'The ''Phone Cascade'', ''Phone End-to-End'' and Hybrid Cascade models have positive ΔBLEU scores at 40 hours. ''Phone Cascade'' has 10.3, ''Phone End-to-End'' has 5.0 and Hybrid Cascade has 4.1. The sum is 19.4.';19,4;19.4;Complex Calculation and Logical Reasoning;''
2020.acl-main.217.pdf-Figure2.png;'Ist die Summe der ΔBLEU-Werte für ''Baseline End-to-End'' und ''Salesky et al. (2019)'' bei 160 Stunden größer als der ΔBLEU-Wert für ''Baseline Cascade'' bei 20 Stunden?';'Is the sum of the ΔBLEU values for ''Baseline End-to-End'' and ''Salesky et al. (2019)'' at 160 hours greater than the ΔBLEU value for ''Baseline Cascade'' at 20 hours?';'Die Summe von ΔBLEU für ''Baseline End-to-End'' (-2,2) und ''Salesky et al. (2019)'' (-7,3) bei 160 Stunden ist -9,5. Der ΔBLEU für ''Baseline Cascade'' bei 20 Stunden ist 20,2. Daher ist die Summe (-9,5) kleiner als 20,2, also ist die Antwort nein.';'The sum of ΔBLEU for ''Baseline End-to-End'' (-2.2) and ''Salesky et al. (2019)'' (-7.3) at 160 hours is -9.5. The ΔBLEU for ''Baseline Cascade'' at 20 hours is 20.2. Therefore, the sum (-9.5) is smaller than 20.2, so the answer is no.';Nein;No;Complex Calculation and Logical Reasoning;''
2020.acl-main.217.pdf-Figure2.png;Welche der vorgeschlagenen Modelle übertreffen frühere Arbeiten unter ressourcenarmen Bedingungen (20 Stunden) und um wie viel im Vergleich zum besten Ergebnis in Salesky et al. (2019)? Beziehen Sie sich zur Beantwortung auf Abbildung 2 und den dazugehörigen Text to answer this question.;Which of the proposed models outperform previous work under low-resource conditions (20 hours), and by how much compared to the best result in Salesky et al. (2019)? Refer to Figure 2 and the accompanying text to answer this question.;Alle drei vorgeschlagenen Modelle (Phone Cascade, Phone End-to-End und Hybrid Cascade) übertreffen das beste Ergebnis in Salesky et al. (2019) nach 20 Stunden (10,0 BLEU). Phone Cascade übertrifft es um 21,5 BLEU, Phone End-to-End um 16,2 BLEU und Hybrid Cascade um 11,5 BLEU.;All three proposed models (Phone Cascade, Phone End-to-End, and Hybrid Cascade) outperform the best result in Salesky et al. (2019) at 20 hours (10.0 BLEU). Phone Cascade surpasses it by 21.5 BLEU, Phone End-to-End by 16.2 BLEU, and Hybrid Cascade by 11.5 BLEU.;Alle drei;All three;Caption Question/Complex Calculation and Logical Reasoning;'Figure 2: Performance of all models relative to Baseline Cascade ( = 0) across our 3 resource conditions. Cascaded models in orange, end-to-end models in purple. Our proposed models yield improvements across all three conditions, with a widening margin under low-resource conditions for the phone cascade.'
2020.acl-main.217.pdf-Figure3.png;'Welche Farbe hat der Balken für die ''Gold''-Telefonqualität bei 160 Stunden Trainingsdaten?';'What color is the bar representing ''Gold'' phone quality with 160 hours of training data?';Gold/Gelb;Gold/Yellow;Goldgelb;Gold/Yellow;Simple Retrieval;''
2020.acl-main.217.pdf-Figure3.png;'Wie groß ist der Unterschied im BLEU-Score zwischen ''Gold'' und ''High'' Telefonqualität bei 40 Stunden Trainingsdaten?';'What is the difference in BLEU score between ''Gold'' and ''High'' phone quality at 40 hours of training data?';12,3 (49,4 - 37,1 = 12,3);12.3 (49.4 - 37.1 = 12.3);12,3;12.3;Simple Calculation;''
2020.acl-main.217.pdf-Figure3.png;Ist die Differenz zwischen dem höchsten und dem niedrigsten BLEU-Score bei 160 Stunden Trainingsdaten größer als die gleiche Differenz bei 20 Stunden?;Is the difference between the highest and lowest BLEU score at 160 training hours greater than the same difference at 20 hours?;Ja, 24,5 (57,8 - 33,3) bei 160 Stunden vs. 15,3 (39,8 - 24,5) bei 20 Stunden.;Yes, 24.5 (57.8 - 33.3) at 160hrs vs. 15.3 (39.8 - 24.5) at 20hrs.;Ja;Yes;Simple Calculation;''
2020.acl-main.217.pdf-Figure3.png;Wie schneiden die Phone-Cascade-Modelle im Vergleich zu den anderen Modellen in der Abbildung hinsichtlich der Robustheit gegenüber verschiedenen Datenmengen ab, und welche Schlussfolgerung wird im Text dazu gezogen?;How do the phone cascade models compare to other models in the figure in robustness to differing data sizes, and what conclusion is drawn in the text regarding this?;Die Phone-Cascade-Modelle übertreffen in der Abbildung durchgängig die anderen Modelle bei allen Datenmengen (160 Stunden, 40 Stunden, 20 Stunden) und zeigen eine größere Robustheit gegenüber geringeren Ressourcen. Im Text wird daraus geschlossen, dass die Verwendung von Phone-Labels als Eingabe für MT in einer Kaskade effektiver ist als die Verwendung von BPE-Token, insbesondere in Umgebungen mit geringen Ressourcen.;The phone cascade models consistently outperform other models across all data sizes (160hr, 40hr, 20hr), showing greater robustness to lower resource conditions. The text concludes that this demonstrates that using phone labels as input for MT in a cascade is more effective than using BPE tokens, especially in low-resource settings.;Übertreffen andere Modelle;Outperform other models;Requires Paper Context;'The phone cascade performs still better, with marked improvements across all conditions over all other models (see Figure 2). On the full dataset, using phones as the source for MT in a cascade performs ∼2 BLEU better than using BPE, while at 40 and 20 hours this increases to up to 10 BLEU. We analyze the robustness of phone models further in Section 8.'
2020.acl-main.219.pdf-Figure4.png;Welche Farbe hat der Balken, der die menschlichen Ergebnisse darstellt?;What color is the bar representing the human results?;Blau;Blue;Blau;Blue;Simple Retrieval;''
2020.acl-main.219.pdf-Figure4.png;Wie groß ist der Unterschied im Gewinnprozentsatz zwischen Mensch und TransResNet-Ret (ResNeXt-IG-3.5B) in der ersten Runde?;What is the difference in win percentage between Human and TransResNet-Ret (ResNeXt-IG-3.5B) in the first round?;Ungefähr 0,01;Approximately 0.01;0,01;0.01;Simple Calculation;''
2020.acl-main.219.pdf-Figure4.png;In welcher Runde ist die Differenz zwischen der menschlichen Gewinnrate und der höchsten Modellgewinnrate am geringsten?;In which round is the difference between the human win rate and the highest model win rate the smallest?;Erste Runde. Der Unterschied ist am geringsten zwischen Mensch und TransResNet-Ret (ResNeXt-IG-3.5B).;First round. The difference is smallest between human and TransResNet-Ret (ResNeXt-IG-3.5B).;Erste Runde;First round;Complex Calculation and Logical Reasoning;''
2020.acl-main.219.pdf-Figure4.png;In welchen der drei Runden schneidet das auf ResNeXt-IG-3.5B basierende TransResNet-Ret Modell im Vergleich zu menschlichen Bewertungen am besten ab, und wie verhält sich diese Leistung zu den Ergebnissen der automatischen Bewertung in Tabelle 2?;In which of the three rounds does the TransResNet-Ret model based on ResNeXt-IG-3.5B perform best compared to human evaluations, and how does this performance relate to the automatic evaluation results in Table 2?;Das TransResNet-Ret-Modell basierend auf ResNeXt-IG-3.5B schneidet im Vergleich zu menschlichen Bewertungen in der ersten Runde am besten ab, mit einer Gewinnquote nahe der von Menschen. Diese Leistung stimmt mit den Ergebnissen der automatischen Bewertung in Tabelle 2 überein, wo das vollständige Modell (Stil + Dialog + Bild) die höchsten Punktzahlen in allen Runden erzielt, insbesondere in Runde 1 und Runde 2 sowohl für die R@1/100- als auch die ROUGE-L-Metriken.;The TransResNet-Ret model based on ResNeXt-IG-3.5B performs best compared to human evaluations in the first round, with a win percentage close to that of humans. This performance is consistent with the automatic evaluation results in Table 2, where the full model (Style + Dialogue + Image) achieves the highest scores across all turns, particularly in Turn 1 and Turn 2 for both R@1/100 and ROUGE-L metrics.;Erste Runde;First round;Requires Paper Context;"TRANSRESNETRET (R@1/100 ) TRANSRESNETGEN (ROUGE-L) Modules Turn 1 Turn 2 Turn 3 All Turn 1 Turn 2 Turn 3 All

Image Only 37.6 28.1 20.7 28.7 21.1 21.9 22.4 21.8 Style Only 18.3 15.3 17.0 16.9 20.2 20.9 22.0 21.0 Dialogue History Only 1.0 33.7 32.3 22.3 18.9 22.7 23.7 21.8

Style + Dialogue (no image) 18.3 45.4 43.1 35.4 20.4 24.1 24.8 23.1 Image + Dialogue (no style) 37.6 39.4 32.6 36.5 21.3 22.8 23.6 22.6 Image + Style (no dialogue) **54.0** 41.1 35.2 43.4 **23.7** 23.2 23.8 23.5

Style + Dialogue + Image (full model) **54.0** **51.9** **44.8** **50.3** **23.7** **24.2** **24.9** **24.3**"
2020.acl-main.219.pdf-Figure5.png;Um wie viel ist der Wert des roten Balkens im linken Diagramm höher als der des violetten Balkens?;What is the difference in value between the red bar and the purple bar in the left chart?;Ungefähr 0,08.;Approximately 0.08.;0.08;0.08;Simple Calculation;''
2020.acl-main.219.pdf-Figure5.png;Ist der BLEU-4-Wert für TransResNet-Gen höher oder niedriger als der von V&T Gen?  Geben Sie die ungefähren Werte für beide an.;Is the BLEU-4 score for TransResNet-Gen higher or lower than that of V&T Gen? Provide the approximate values for both.;Höher. TransResNet-Gen erreichte ungefähr 2,3, während V&T Gen ungefähr 1,5 erreichte.;Higher. TransResNet-Gen achieved approximately 2.3, while V&T Gen achieved approximately 1.5.;Höher;Higher;Simple Calculation;''
2020.acl-main.219.pdf-Figure5.png;Wie schneidet die Leistung von TransResNetRet im IGC-Datensatz im Vergleich zu seiner Leistung im IMAGE-CHAT-Datensatz gemäß der menschlichen Bewertung ab, und was könnte diesen Unterschied erklären?  Beziehen Sie sich dabei sowohl auf die Abbildung als auch auf den bereitgestellten Textauszug.;How does the performance of TransResNetRet on the IGC dataset compare to its performance on the IMAGE-CHAT dataset, according to human evaluation, and what might explain this difference?  Refer to both the figure and the provided text excerpt.;TransResNetRet schneidet bei IGC (62,9 % der menschlichen Leistung) besser ab als bei IMAGE-CHAT (49,4 % Gewinnrate gegen Menschen in Runde 1). Dies könnte daran liegen, dass sich IGC auf die Beantwortung von Fragen konzentriert, während IMAGE-CHAT offener ist, wodurch das stärker strukturierte Format von IGC möglicherweise besser für das Modell geeignet ist.;TransResNetRet performs better on IGC (62.9% of human performance) than on IMAGE-CHAT (49.4% win rate against humans in turn 1). This might be because IGC focuses on answering questions, while IMAGE-CHAT is more open-ended, possibly making IGC's more structured format better suited to the model.;Besser;Better;Requires Paper Context;'In turn 1, TRANSRESNETRET (ResNeXt-IG-3.5B) has a win rate against humans of 49.4% (difference not significant using a binomial two-tailed test, p > 0.5), ...Figure 5: IGC Evaluations. ... Our model narrows the gap between human and model performance, yielding a higher percentage of the human score (62.9% vs. 54.2%).'
2020.acl-main.222.pdf-Figure1.png;Welche Farbe hat der Balken für 'Image+Seq2Seq All Tasks MT' im Diagramm?;What color is the bar for 'Image+Seq2Seq All Tasks MT' in the chart?;Blau;Blue;Blau;Blue;Simple Retrieval;''
2020.acl-main.222.pdf-Figure1.png;Wie hoch ist die Summe der Gewinnquoten für 'Image+Seq2Seq All Tasks MT' in den Aufgaben 'Image Chat' und 'WoW (Seen)'?;What is the sum of the win percentages for 'Image+Seq2Seq All Tasks MT' for the 'Image Chat' and 'WoW (Seen)' tasks?;Ungefähr 1,2;Approximately 1.2;1.2;1.2;Simple Calculation;''
2020.acl-main.222.pdf-Figure1.png;Welches Modell hat die höchste durchschnittliche Gewinnquote über alle drei Aufgaben hinweg?;Which model has the highest average win percentage across all three tasks?;Image+Seq2Seq All Tasks MT;Image+Seq2Seq All Tasks MT;Image+Seq2Seq All Tasks MT;Image+Seq2Seq All Tasks MT;Complex Calculation and Logical Reasoning;''
2020.acl-main.222.pdf-Figure1.png;Inwiefern unterstützt die visuelle Darstellung in Abbildung 1 die Behauptung der statistischen Signifikanz (p < 0,05), die durch den Binomialtest ermittelt wurde, insbesondere hinsichtlich der Leistung des 'All Tasks MT'-Modells in der Kategorie 'WoW Unseen' im Vergleich zu bestehenden State-of-the-Art-Modellen? Führen Sie Belege aus dem entsprechenden Abschnitt des Forschungspapiers an, um den Zusammenhang zwischen dem visuellen Trend und dem statistischen Ergebnis zu erläutern.;How does the visual representation in Figure 1 support the claim of statistical significance (p < 0.05) obtained through the binomial test, specifically regarding the performance of the 'All Tasks MT' model in the 'WoW Unseen' category against existing state-of-the-art models? Provide evidence from the relevant paper section to explain the connection between the visual trend and the statistical outcome.;'Der blaue Balken, der 'All Tasks MT' in der Kategorie 'WoW (Unseen)' repräsentiert, ist deutlich höher als die Balken für 'Shuster et al. (2018)' und 'Dinan et al. (2019)'. Die Bildunterschrift besagt ausdrücklich, dass 'alle drei Ergebnisse statistisch signifikant sind (Binomialtest, p < 0,05)', was die visuelle Beobachtung untermauert, indem bestätigt wird, dass der Unterschied in den Gewinnraten (dargestellt durch die Balkenhöhen) wahrscheinlich nicht zufällig ist.';'The blue bar representing 'All Tasks MT' in the 'WoW (Unseen)' category is visibly taller than the bars for 'Shuster et al. (2018)' and 'Dinan et al. (2019)'. The figure caption explicitly states that 'All three results are statistically significant (binomial test, p < .05)', which reinforces the visual observation by confirming that the difference in win rates (represented by bar heights) is unlikely to have occurred by chance.';Höherer Balken/Signifikant;Taller bar/Significant;Caption Question/Complex Calculation and Logical Reasoning;''
2020.acl-main.244.pdf-Figure2.png;Welche Farbe repräsentiert die IID-Daten im oberen Diagramm?;What color represents the IID data in the top chart?;Blau;Blue;Blau;Blue;Simple Retrieval;''
2020.acl-main.244.pdf-Figure2.png;Wie hoch ist die Genauigkeit des BERT-Basismodells für IID-Daten im oberen Diagramm?;What is the accuracy of the BERT Base model on IID data in the top chart?;Ungefähr 92%;Approximately 92%;92%;92%;Simple Retrieval;''
2020.acl-main.244.pdf-Figure2.png;Welches Modell im oberen Diagramm erreicht die höchste Genauigkeit für OOD-Daten und wie hoch ist diese?;Which model achieves the highest OOD accuracy in the top chart, and what is that accuracy?;RoBERTa, ungefähr 91%;RoBERTa, approximately 91%;RoBERTa, 91%;RoBERTa, 91%;Simple Retrieval;''
2020.acl-main.244.pdf-Figure2.png;Im unteren Diagramm, welches Modell hat den größten Unterschied zwischen IID- und OOD-Genauigkeit und wie groß ist dieser Unterschied?;In the bottom chart, which model has the largest difference between IID and OOD accuracy, and what is the magnitude of this difference?;DistilBERT, ungefähr 10%;DistilBERT, approximately 10%;DistilBERT, 10%;DistilBERT, 10%;Simple Calculation;''
2020.acl-main.244.pdf-Figure2.png;Der Text erwähnt, dass die Destillation von Modellen die Robustheit verringern kann.  Wie verhält sich die Genauigkeit von DistilBERT im Vergleich zu BERT Base im unteren Diagramm für IID- und OOD-Daten?;The text mentions that model distillation can reduce robustness.  How does DistilBERT's accuracy compare to BERT Base's in the bottom chart, for both IID and OOD data?;Im unteren Diagramm liegt die exakte Übereinstimmungsrate von DistilBERT für IID-Daten (CNN) bei etwa 45 %, während die exakte Übereinstimmungsrate von BERT Base bei etwa 53 % liegt. Für OOD-Daten (Daily Mail) liegt die exakte Übereinstimmungsrate von DistilBERT bei etwa 34 %, während die von BERT Base bei etwa 52 % liegt. Dies deutet darauf hin, dass DistilBERT sowohl für IID- als auch für OOD-Daten eine geringere Genauigkeit als BERT Base aufweist, was die Beobachtung unterstützt, dass Modelldestillation die Robustheit verringern kann.;In the bottom chart, DistilBERT's exact match percentage for IID data (CNN) is approximately 45%, while BERT Base's exact match percentage is around 53%. For OOD data (Daily Mail), DistilBERT's exact match percentage is roughly 34%, whereas BERT Base's is about 52%. This indicates that DistilBERT has lower accuracy than BERT Base for both IID and OOD data, supporting the observation that model distillation can reduce robustness.;Niedriger;Lower;Caption Question/Simple Calculation;"Figure 2: Generalization results for sentiment analysis and reading comprehension. While IID accuracy does not vary much for IMDb sentiment analysis, OOD accuracy does. Here pretrained Transformers do best.

In keeping with results from vision (Hendrycks and Dietterich, 2019), we find that model distillation can reduce robustness, as evident in our DistilBERT results in Figure 2. This highlights that testing model compression methods for BERT (Shen et al., 2020; Ganesh et al., 2020; Li et al., 2020) on only in-distribution examples gives a limited account of model generalization, and such narrow evaluation may mask downstream costs."
2020.acl-main.245.pdf-Figure4.png;'Welche Farbe repräsentiert die Datenreihe ''CONNCOMP''?';'Which color represents the data series ''CONNCOMP''?';Blau;Blue;Blau;Blue;Simple Retrieval;''
2020.acl-main.245.pdf-Figure4.png;How high is the bar for CONNCOMP at size 1 of Bα on SST-2?;Wie hoch ist der Balken für CONNCOMP bei Größe 1 von Bα auf SST-2?;Ungefähr 0.87;Approximately 0.87;0.87;0.87;Simple Retrieval;''
2020.acl-main.245.pdf-Figure4.png;Ist die Summe der Balkenhöhen für CONNCOMP und AGGCLUST bei Größe 1 von Bα auf SST-2 größer als 1?;Is the sum of the bar heights for CONNCOMP and AGGCLUST at size 1 of Bα on SST-2 greater than 1?;Ja, ungefähr 0.87 + 0.66 = 1.53, was größer als 1 ist.;Yes, approximately 0.87 + 0.66 = 1.53, which is greater than 1.;Ja;Yes;Simple Calculation;''
2020.acl-main.245.pdf-Figure4.png;Was ist die Differenz zwischen dem höchsten und dem niedrigsten Wert von CONNCOMP über alle Größen von Bα auf RTE?;What is the difference between the highest and lowest value of CONNCOMP across all sizes of Bα on RTE?;Ungefähr 0.36;Approximately 0.36;0.36;0.36;Simple Calculation;''
2020.acl-main.245.pdf-Figure4.png;In der Bildunterschrift zu Abbildung 4 heißt es, dass '|Bα(x)| < 9 für die meisten x' ist. Bei visueller Betrachtung des Histogramms für SST-2, für ungefähr welchen Prozentsatz der Eingaben x ist |Bα(x)| größer oder gleich 5?;The caption of Figure 4 states that '|Bα(x)| < 9 for most x'. Visually inspecting the histogram for SST-2, for approximately what percentage of inputs x is |Bα(x)| greater than or equal to 5?;Ungefähr 4%;Approximately 4%;4%;4%;Caption Question/Simple Calculation;''
2020.acl-main.263.pdf-Figure5.png;Welcher POS-Tag hat im ersten Diagramm den höchsten Wert im ursprünglichen Datensatz?;Which POS Tag has the highest value in the original dataset in the first chart?;NN;NN;NN;NN;Simple Retrieval;''
2020.acl-main.263.pdf-Figure5.png;Was ist die Summe der Werte für die POS-Tags JJ und RB im ersten Diagramm des ursprünglichen Datensatzes?;What is the sum of the values for the POS Tags JJ and RB in the first chart's original dataset?;Ungefähr 0.15;Approximately 0.15;0.15;0.15;Simple Calculation;''
2020.acl-main.263.pdf-Figure5.png;Im zweiten Diagramm, welcher POS-Tag weist die größte absolute Differenz zwischen dem ursprünglichen Trainingsdatensatz (blau) und dem Morpheus Adversarial-Datensatz (orange) auf?;In the second chart, which POS Tag has the largest absolute difference between the original training set (blue) and the Morpheus Adversarial dataset (orange)?;NNS;NNS;NNS;NNS;Simple Calculation;''
2020.acl-main.263.pdf-Figure5.png;Im zweiten Diagramm, ist das Verhältnis zwischen dem höchsten Wert im ursprünglichen Trainingsdatensatz und dem niedrigsten Wert im adversarialen Datensatz von Morpheus größer als 3?;In the second chart, is the ratio between the highest value in the Original Training Set and the lowest value in the Morpheus Adversarial Distribution greater than 3?;Ja, ungefähr 27, was größer als 3 ist.;Yes, approximately 27, which is greater than 3.;Ja;Yes;Complex Calculation and Logical Reasoning;''
2020.acl-main.263.pdf-Figure5.png;Algorithmus 2 beschreibt, wie gegnerische Beispiele durch Fokussierung auf Substantive, Verben und Adjektive generiert werden.  Abbildung 5(b) zeigt die Verteilung der POS-Tags im gegnerischen Trainingsdatensatz. Basierend auf dem Diagramm und unter Berücksichtigung der Funktionsweise von Algorithmus 2, welche POS-Tags scheinen am anfälligsten für Flexionsänderungen im Kontext des gegnerischen Trainings zu sein, und warum?;Algorithm 2 describes how adversarial examples are generated by focusing on nouns, verbs, and adjectives. Figure 5(b) shows the distribution of POS tags in the adversarial training set. Based on the chart and considering the workings of Algorithm 2, which POS tags appear most vulnerable to inflectional changes in the context of adversarial training, and why?;Substantive, insbesondere Pluralformen (NNS), scheinen am anfälligsten zu sein. Das Diagramm zeigt einen signifikanten Rückgang des Anteils von NNS im gegnerischen Datensatz im Vergleich zum Original, was darauf hindeutet, dass Flexionsänderungen sie stark beeinflusst haben. Singular Substantive (NN) sind ebenfalls betroffen, jedoch in geringerem Maße.;Nouns, particularly plural nouns (NNS), appear most vulnerable. The chart shows a significant drop in the proportion of NNS in the adversarial set compared to the original, suggesting inflectional changes greatly impacted them.  Singular nouns (NN) are also affected, but to a lesser extent.;NNS;NNS;Caption Question/Complex Calculation and Logical Reasoning;"**Algorithm 2 RandomInflect** **Require: Original instance x, hyperparameter k**

Adversarial distribution Dadv

**Ensure: Adversarial training dataset Xx[′]** [for][ x]

_Xx[′]_ _[←{][x][}]_

**for i = 1 to k do**

_T ←_ TOKENIZE(x) **for all i = 1, . . ., |T** _| do_

**if POS(Ti) ∈{NOUN, VERB, ADJ} then**

_I ←_ GETINFLECTIONS(Ti) _Ti ←_ RANDOMWEIGHTED(I, Dadv)

**end if**

**end for** _x[′]_ _←_ DETOKENIZE(T ) _Xx[′]_ _[←]_ _[X]x[′]_ _[∪{][x][′][}]_

**end for** **return Xx[′]**

(a) SQuAD 2.0 dev set

(b) SQuAD 2.0 training set

Figure 5: Full versions of Figure 2"
2020.acl-main.307.pdf-Figure2.png;Welcher Datensatz (WSJ oder R&B) hat die höchste Genauigkeit für das vorgeschlagene Modell (WA+CS+DVR) über alle Zeiträume hinweg?;Which dataset (WSJ or R&B) has the highest accuracy for the proposed model (WA+CS+DVR) across all time periods?;R&B hat die höchste Genauigkeit für das vorgeschlagene Modell über alle Zeiträume hinweg.;R&B has the highest accuracy for the proposed model across all time periods.;R&B;R&B;Simple Retrieval;''
2020.acl-main.307.pdf-Figure2.png;Was ist die Genauigkeitsdifferenz zwischen dem vorgeschlagenen Modell (WA+CS+DVR) und dem einfachen Durchschnitt im WSJ-Datensatz nach einem Jahr?;What is the accuracy difference between the proposed model (WA+CS+DVR) and the simple average in the WSJ dataset after one year?;Die Genauigkeitsdifferenz beträgt etwa 4%.;The accuracy difference is approximately 4%.;4%;4%;Simple Calculation;''
2020.acl-main.307.pdf-Figure2.png;Berechnen Sie die durchschnittliche Genauigkeit des WA+CS-Modells im R&B-Datensatz über alle drei Zeiträume (1 Jahr, 3 Jahre und 7 Jahre).;Calculate the average accuracy of the WA+CS model in the R&B dataset across all three time periods (1 year, 3 years, and 7 years).;Die durchschnittliche Genauigkeit beträgt etwa 55%.;The average accuracy is approximately 55%.;55%;55%;Complex Calculation and Logical Reasoning;''
2020.acl-main.307.pdf-Figure2.png;Welches Modell im WSJ-Datensatz zeigt die geringste Verbesserung der Genauigkeit bei Verwendung von drei Jahren Daten im Vergleich zu nur einem Jahr Daten?;Which model in the WSJ dataset shows the smallest improvement in accuracy when using three years of data compared to only one year of data?;'Das Modell ''Weighted Average'' zeigt die geringste Verbesserung.';'The ''Weighted Average'' model shows the least improvement.';'Weighted Average';'Weighted Average';Simple Calculation;''
2020.acl-main.307.pdf-Figure2.png;Der Text erwähnt, dass die Stichprobengröße für jede Aktie etwa zwei Drittel der gesamten Handelstage beträgt. Wie wirkt sich diese relativ kleine Stichprobengröße laut Artikel auf das Training der Modelle aus, und welche Strategien wurden verwendet, um dies zu kompensieren?;The text mentions that the sample size for each stock is about two-thirds of the total trading days. According to the paper, how does this relatively small sample size affect the training of the models, and what strategies were employed to mitigate this?;Kleine Datensätze können zu Overfitting führen. Um dies zu mindern, wird die gemeinsame Nutzung von Klassifikatoren eingesetzt, wodurch die effektive Stichprobengröße um das 50- bis 100-fache erhöht wird.;Small datasets can lead to overfitting. Classifier sharing is employed to mitigate this by increasing the effective sample size 50 to 100 times.;Overfitting, Classifier Sharing;Overfitting, Classifier Sharing;Requires Paper Context;"Through such filtering, the number of samples for each stock became about two-thirds of the number of all trading days, or around[4] 2600 and 1200 samples for each stock, for the WSJ and R&B datasets, respectively.

**5.2** **Deep Learner System Settings**

...Specifically, the classifier is shared across all stocks, thus achieving a sample size about 50 to 100 times larger."
2020.acl-main.372.pdf-Figure4.png;Welcher Layer hat das höchste Softmax-Gewicht?;Which layer has the highest softmax weight?;Layer 8;Layer 8;8;8;Simple Retrieval;''
2020.acl-main.372.pdf-Figure4.png;Was ist der ungefähre Unterschied im Softmax-Gewicht zwischen Layer 8 und Layer 0?;What is the approximate difference in softmax weight between Layer 8 and Layer 0?;Ungefähr 0,035;Approximately 0.035;0,035;0.035;Simple Calculation;''
2020.acl-main.372.pdf-Figure4.png;Was ist das durchschnittliche Softmax-Gewicht der Layer 4, 5 und 6?;What is the average softmax weight of layers 4, 5, and 6?;Ungefähr 0,075;Approximately 0.075;0,075;0.075;Complex Calculation and Logical Reasoning;''
2020.acl-main.372.pdf-Figure4.png;Ist das Softmax-Gewicht von Layer 12 größer oder kleiner als der Durchschnitt aller Softmax-Gewichte?;Is the softmax weight of Layer 12 less than or greater than the average of all softmax weights?;Kleiner;Less;Kleiner;Less;Complex Calculation and Logical Reasoning;''
2020.acl-main.372.pdf-Figure4.png;Die Arbeit erwähnt, dass Aufgaben mit High-Level-Semantik dazu neigen, alle BERT-Layer zu nutzen. Beschreiben Sie den Trend der Softmax-Gewichte in Abbildung 4 und erklären Sie, inwiefern dieser Trend die Aussage der Arbeit unterstützt oder widerlegt.;The paper mentions that tasks involving high-level semantics tend to utilize all BERT layers. Describe the trend of the softmax weights in Figure 4 and explain how this trend supports or contradicts the paper's statement.;Die Gewichte sind relativ gleichmäßig über alle Schichten verteilt, mit einem Peak bei Schicht 8. Dies unterstützt im Allgemeinen die Behauptung der Arbeit, da alle Schichten signifikante Werte ungleich Null aufweisen, was auf ihre Verwendung bei der Aufgabe hinweist. Der leichte Peak bei Schicht 8 deutet darauf hin, dass einige Schichten mehr beitragen als andere, aber der Gesamttrend ist eine breite Nutzung.;The weights are relatively evenly distributed across all layers, peaking at layer 8. This generally supports the paper's claim, as all layers have significant non-zero weights, indicating their usage in the task. The slight peak at layer 8 suggests some layers contribute more than others, but the overall trend is one of broad utilization.;Unterstützt;Supports;Requires Paper Context;'To better understand whether there are any layers in BERT that are particularly important for our task, we freeze BERT and calculate the center of gravity (Tenney et al., 2019) based on scalar mixing weights (Peters et al., 2018). We find that all layers are similarly important for our task, with center of gravity = 6.19 (see Figure 4). This is consistent with Tenney et al. (2019), who have also found that tasks involving high-level semantics tend to make use of all BERT layers.'
2016.jeptalnrecital-jep.27.pdf-Figure3.png;Welche Gruppe (CI oder NH) hat im i,e,E-Diagramm für Bedingung P den höchsten Ausreißer?;In the i,e,E plot, which group (CI or NH) has the highest outlier for condition P?;Die NH-Gruppe hat im i,e,E-Diagramm für die Bedingung P den höchsten Ausreißer.;The NH group has the highest outlier in the i,e,E plot for condition P.;NH;NH;Simple Retrieval;''
2016.jeptalnrecital-jep.27.pdf-Figure3.png;Im y,2,9-Diagramm: Ist der Medianwert der CI-Gruppe für Bedingung R höher oder niedriger als der Medianwert der NH-Gruppe?;In the y,2,9 plot, is the median value of the CI group for condition R higher or lower than the median value of the NH group?;Im y,2,9-Diagramm ist der Medianwert der CI-Gruppe für Bedingung R niedriger als der Medianwert der NH-Gruppe.;The median of the CI group is lower than the median of the NH group in the y,2,9 plot for condition R.;Niedriger;Lower;Simple Calculation;''
2016.jeptalnrecital-jep.27.pdf-Figure3.png;"Welches Vokalgruppen-Diagramm (i,e,E; y,2,9; a; u,o,O) zeigt die größte Varianz innerhalb der CI-Gruppe für Bedingung P, gemessen an der Länge der Box?";"Which vowel group plot (i,e,E; y,2,9; a; u,o,O) shows the largest variance within the CI group for condition P, as measured by the length of the box?";Das y,2,9-Diagramm zeigt die größte Varianz innerhalb der CI-Gruppe für Bedingung P.;The y,2,9 plot shows the largest variance within the CI group for condition P.;y,2,9;y,2,9;Simple Retrieval;''
2016.jeptalnrecital-jep.27.pdf-Figure3.png;Betrachtet man alle Diagramme: Ist die Summe der Mediane der CI-Gruppe für Bedingung P in allen Vokalgruppen größer als die Summe der Mediane der NH-Gruppe für dieselbe Bedingung?;Considering all plots: Is the sum of the medians of the CI group for condition P across all vowel groups greater than the sum of the medians of the NH group for the same condition?;Nein, die Summe der Mediane der CI-Gruppe für Bedingung P ist kleiner als die Summe der Mediane der NH-Gruppe für dieselbe Bedingung.;No, the sum of the medians of the CI group for condition P is lower than the sum of the medians of the NH group for the same condition.;Nein;No;Complex Calculation and Logical Reasoning;''
2016.jeptalnrecital-jep.27.pdf-Figure3.png;In Abschnitt 4 (Diskussion/Konklusion) wird die im Diagramm dargestellte posteriore Produktion von anterioren gerundeten Vokalen durch CI-Kinder diskutiert. Welche Hypothese wird im Text zur Erklärung dieses Phänomens aufgestellt?;Section 4 (Discussion/Conclusion) discusses the more posterior production of anterior rounded vowels by CI children, as depicted in the figure. What hypothesis is proposed in the text to explain this phenomenon?;Die Arbeit stellt die Hypothese auf, dass diese Vokale bei CI-Kindern phonologisch schlecht von posterioren gerundeten Vokalen unterschieden werden, aufgrund von Ähnlichkeiten in Bezug auf visuelle Informationen.;The paper hypothesizes that these vowels are poorly phonologically distinguished in CI children from posterior rounded vowels, due to similarities in terms of visual information.;Visuelle Informationen;Visual Information;Requires Paper Context;'A travers cette étude acoustique, nous avons mis en évidence que (1) l’implantation permet aux enfants CI de percevoir certaines caractéristiques acoustiques des voyelles qui leur permettent ensuite de produire des voyelles globalement comparables en terme de hauteur, d’antériorité et de dispersion à celles d’enfants normo-entendants du même âge, sauf pour ce qui concerne la série des voyelles antérieures arrondies : les enfants CI ont tendance à produire ces voyelles de façon plus postérieure et avec plus de variabilité que les enfants NH. Une hypothèse explicative serait que ces voyelles sont mal distinguées phonologiquement chez les enfants CI des voyelles postérieures arrondies, en raison des similitudes en termes d'informations visuelles'
2016.jeptalnrecital-jep.60.pdf-Figure5.png;Welche Boxplot-Gruppe befindet sich am weitesten links in der Abbildung?;Which boxplot group is positioned furthest to the left in the figure?;SLA1;SLA1;SLA1;SLA1;Simple Retrieval;''
2016.jeptalnrecital-jep.60.pdf-Figure5.png;Was ist der Höhenunterschied zwischen dem oberen Whisker des weißen Feldes und dem unteren Whisker des grauen Feldes im SLA3-Boxplot?;What is the difference in height between the top whisker of the white box and the bottom whisker of the grey box in the SLA3 boxplot?;Ungefähr 1,1 Einheiten.;Approximately 1.1 units.;1.1;1.1;Simple Calculation;''
2016.jeptalnrecital-jep.60.pdf-Figure5.png;Ist der Medianwert (horizontale Linie in der Box) des weißen Feldes im SLA2-Boxplot höher oder niedriger als der Medianwert des weißen Feldes im SLA7-Boxplot?;Is the median value (horizontal line within the box) of the white box in the SLA2 boxplot higher or lower than the median value of the white box in the SLA7 boxplot?;Höher;Higher;Höher;Higher;Simple Calculation;''
2016.jeptalnrecital-jep.60.pdf-Figure5.png;Wie viele Boxplot-Gruppen haben einen Medianwert über 6 für das weiße Feld ('niveau1')?;How many boxplot groups have a median value above 6 for the white box ('niveau1')?;Zwei;Two;2;2;Simple Calculation;''
2016.jeptalnrecital-jep.60.pdf-Figure5.png;Im Text wird die Schwere der Sprachbeeinträchtigung bei Teilnehmern mit SLA diskutiert. Weisen die drei Personen mit den höchsten Schweregradbewertungen (SLA2, SLA4 und SLA8) in ihren Boxplots im Vergleich zu anderen Teilnehmern mit SLA in der Leseaufgabe einheitliche visuelle Unterschiede auf?;The paper discusses the severity of speech impairment in participants with SLA. Do the three individuals with the highest severity ratings (SLA2, SLA4 and SLA8) exhibit any consistent visual differences in their boxplots compared to other participants with SLA, in the reading task?;Ja, die drei Teilnehmer (SLA2, SLA4 und SLA8) zeigen durchweg eine längere Dauer für die erste Silbe (S1 - weißes Kästchen) im Vergleich zur zweiten Silbe (S2 - graues Kästchen). Dies unterscheidet sich von der Mehrheit der anderen SLA-Teilnehmer, bei denen S2 im Allgemeinen länger als S1 ist.;Yes, the three participants (SLA2, SLA4, and SLA8) consistently show a longer duration for the first syllable (S1 - white box) compared to the second syllable (S2 - grey box).  This is different from the majority of other SLA participants where S2 is generally longer than S1.;Ja;Yes;Requires Paper Context;"Il en va différemment pour la population des locuteurs SLA pour lesquels une forte variabilité interindividuelle peut être observée dans la tâche de lecture (figure 5). Nous avons choisi de présenter cette population car c¶est celle qui présente le plus de contraste entre locuteurs. C¶est aussi la population pour laquelle de degré de sévérité est le plus élevé. Plus spécifiquement, on constate que trois locuteurs ne parviennent pas à préserver le pattern rythmique iambique (figure 5, entouré de rouge). Ces trois locuteurs, SLA1, SLA4 et SLA8 sont également ceux qui montrent le degré de sévérité le plus élevé (respectivement : 2,9 ; 2,4 et 2,6 sur une échelle de 0 à 3)."
2016.jeptalnrecital-jep.67.pdf-Figure3.png;Welche Farbe hat der Kasten, der die Daten für 'Spont' im Abschnitt 'Femmes' darstellt?;What color is the box representing the data for 'Spont' in the 'Femmes' section?;Hellblau.;Light blue.;Hellblau;Light blue;Simple Retrieval;''
2016.jeptalnrecital-jep.67.pdf-Figure3.png;'Wie groß ist der Unterschied in der Dauer (Sek.) zwischen der oberen Kante des hellblauen Kastens und der oberen Kante des grünen Kastens im Abschnitt ''Femmes''?';'What is the difference in duration (sec) between the top edge of the light blue box and the top edge of the green box in the ''Femmes'' section?';Ungefähr 0,045 Sekunden.;Approximately 0.045 seconds.;0,045;0.045;Simple Calculation;''
2016.jeptalnrecital-jep.67.pdf-Figure3.png;'Ist die Summe der oberen Kanten der grünen und hellblauen Kästen im Abschnitt ''Femmes'' größer als die Oberkante des roten Kastens im selben Abschnitt?';'Is the sum of the top edges of the green and light blue boxes in the ''Femmes'' section greater than the top edge of the red box in the same section?';Ja;Yes;Ja;Yes;Complex Calculation and Logical Reasoning;''
2016.jeptalnrecital-jep.67.pdf-Figure3.png;In welcher Gruppe ('Femmes' oder 'Hommes') ist der Median der Vokaldauer im 'Lab'-Stil höher?;In which group ('Femmes' or 'Hommes') is the median vowel duration higher in the 'Lab' style?;'Femmes'.;'Femmes'.;Femmes;Femmes;Simple Retrieval;''
2016.jeptalnrecital-jep.67.pdf-Figure3.png;'Die Bildunterschrift erwähnt die ''durchschnittliche Dauer der Vokale''.  Zeigt Abbildung 3 die durchschnittliche Vokaldauer oder die Verteilung der Vokaldauern?';'The caption mentions ''average duration of vowels''. Does Figure 3 show the average vowel duration or the distribution of vowel durations?';Abbildung 3 zeigt die Verteilung der Vokaldauern.;Figure 3 shows the distribution of vowel durations.;Verteilung;Distribution;Caption Question/Simple Retrival;''
2016.jeptalnrecital-jep.68.pdf-Figure2.png;Welches Boxplot hat die größte Spannweite?;Which boxplot has the largest range?;EQ (Kinder) hat den größten Bereich.;EQ (children) has the largest range.;EQ (Kinder);EQ (Children);Simple Retrieval;''
2016.jeptalnrecital-jep.68.pdf-Figure2.png;Wie groß ist ungefähr die Differenz zwischen dem oberen Whisker von EQ (Kinder) und dem Median von AQ (Erwachsene)?;What is the approximate difference between the upper whisker of EQ (children) and the median of AQ (adults)?;Ungefähr 0.14;Approximately 0.14;0.14;0.14;Simple Calculation;''
2016.jeptalnrecital-jep.68.pdf-Figure2.png;Ist die Summe der Mediane von EL und EQ für Kinder größer als die Summe der Mediane von AL und AQ für Erwachsene?;Is the sum of the medians of EL and EQ for children greater than the sum of the medians of AL and AQ for adults?;Ja;Yes;Ja;Yes;Complex Calculation and Logical Reasoning;''
2016.jeptalnrecital-jep.68.pdf-Figure2.png;Wie viele der abgebildeten Gruppen haben mindestens einen Medianwert über 0?;How many of the displayed groups have at least one median value above 0?;Alle vier angezeigten Gruppen (EL, EQ, AL, AQ) haben Medianwerte über 0.;All four displayed groups (EL, EQ, AL, AQ) have median values above 0.;4;4;Simple Calculation;''
2016.jeptalnrecital-jep.68.pdf-Figure2.png;Der Text erwähnt, dass alle Verhältnisse signifikant von 0 verschieden sind. Welche Schlussfolgerungen lassen sich anhand von Abbildung 2 über den Einfluss der Testumgebung (Labor vs. Alltag) auf die Sprachwahrnehmung ziehen, wenn man diese Signifikanz berücksichtigt?;The text mentions that all ratios are significantly different from 0. Considering this significance, what conclusions can be drawn from Figure 2 about the impact of the testing environment (laboratory vs. daily life) on speech perception?;Obwohl alle Verhältnisse signifikant von 0 verschieden sind (was bedeutet, dass die veränderte Aussprache einen Effekt hat), deutet Abbildung 2 darauf hin, dass die Testumgebung selbst (Labor vs. Alltag) einen minimalen Einfluss hat. Dies liegt daran, dass die Mediane für EL vs. EQ (Kinder) und AL vs. AQ (Erwachsene) innerhalb jeder Altersgruppe visuell nahe beieinander liegen.;While all ratios are significantly different from 0 (meaning altered pronunciation has an effect), Figure 2 suggests the testing environment itself (lab vs. daily life) has minimal impact.  This is because the medians for EL vs. EQ (children) and AL vs. AQ (adults) are visually close within each age group.;Minimaler Einfluss;Minimal impact;Caption Question/Complex Calculation and Logical Reasoning;''
W12-0703.pdf-Figure5.png;Wie viele Ausreißer (Punkte außerhalb der Boxplots) sind im Diagramm dargestellt?;How many outliers (points outside the boxplots) are shown in the diagram?;4;4;4;4;Simple Retrieval;''
W12-0703.pdf-Figure5.png;What is the difference between the median value at 2 and 5 iterations?;Was ist die Differenz zwischen dem Medianwert bei 2 und bei 5 Iterationen?;Ungefähr 0,008;Approximately 0.008;0,008;0.008;Simple Calculation;''
W12-0703.pdf-Figure5.png;Was ist der Durchschnitt der Medianwerte aller Boxplots?;What is the average of the median values of all boxplots?;Ungefähr 0,029;Approximately 0.029;0,029;0.029;Complex Calculation and Logical Reasoning;''
W12-0703.pdf-Figure5.png;Bei wie vielen Iterationen liegt der Interquartilsabstand (IQR) des Boxplot über 0,005?;For how many iterations is the interquartile range (IQR) of the boxplot greater than 0.005?;15;15;15;15;Complex Calculation and Logical Reasoning;''
W12-0703.pdf-Figure5.png;Der Text erwähnt, dass die Fehlerraten ab 5 Iterationen nicht mehr stark variieren. Stimmt diese Aussage mit der Abbildung überein? Begründen Sie Ihre Antwort anhand des Diagramms.;The text mentions that the error rates do not change much starting from 5 iterations. Does this statement align with the figure? Justify your answer based on the diagram.;Ja, die Medianwerte der Boxplots erscheinen ab 5 Iterationen relativ stabil, was die Aussage im Text unterstützt. Allerdings zeigt das Diagramm auch eine beträchtliche Varianz, erkennbar an der Länge der Whisker und dem Vorhandensein von Ausreißern, insbesondere bei niedrigeren Iterationszahlen. Dies deutet darauf hin, dass sich zwar die mittlere Fehlerrate stabilisiert, einzelne Durchläufe aber dennoch Ergebnisse liefern können, die deutlich vom Median abweichen.;Yes, the median values of the boxplots appear relatively stable from 5 iterations onwards, which supports the statement in the text. However, the diagram also shows considerable variance, indicated by the length of the whiskers and the presence of outliers, especially at lower iterations. This suggests that while the median error rate stabilizes, individual runs can still produce results that differ significantly from the median.;Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;'Starting from 5 iterations, error rates do not change much, see figure 5 .'
W12-0703.pdf-Figure9.png;Welcher Beta-Wert hat den niedrigsten Median-I-Wert in der Abbildung?;Which beta value has the lowest median I-value in the figure?;Beta = 0.01;Beta = 0.01;0.01;0.01;Simple Retrieval;''
W12-0703.pdf-Figure9.png;Was ist der Unterschied zwischen dem maximalen und minimalen I-Wert für Beta = 0,5?;What is the difference between the maximum and minimum I-value for beta = 0.5?;Ungefähr 0.03;Approximately 0.03;0.03;0.03;Simple Calculation;''
W12-0703.pdf-Figure9.png;Was ist der durchschnittliche Median-I-Wert für alle dargestellten Beta-Werte?;What is the average median I-value across all displayed beta values?;Ungefähr 0.066;Approximately 0.066;0.066;0.066;Complex Calculation and Logical Reasoning;''
W12-0703.pdf-Figure9.png;Ist die Spannweite (Differenz zwischen Maximum und Minimum) der I-Werte für Beta = 0.01 größer oder kleiner als die Spannweite der I-Werte für Beta = 0.5?;Is the range (difference between maximum and minimum) of I-values for beta = 0.01 larger or smaller than the range of I-values for beta = 0.5?;Kleiner;Smaller;Kleiner;Smaller;Simple Calculation;''
W12-0703.pdf-Figure9.png;Der Artikel erwähnt, dass P_k-Raten und Varianz für Beta-Werte zwischen 0,01 und 0,1 relativ stabil sind. Welche visuellen Beobachtungen in Abbildung 9, insbesondere die Größe der Boxen und die Position der Ausreißer, unterstützen oder widerlegen diese Aussage beim Vergleich der Boxplots für Beta = 0,01, 0,1 und 0,5?;The paper mentions that P_k rates and variance are relatively stable for beta values between 0.01 and 0.1.  What visual observations in Figure 9, specifically regarding the size of the boxes and position of outliers, support or refute this statement when comparing the boxplots for beta = 0.01, 0.1, and 0.5?;Die Boxplots für Beta = 0,01 und 0,1 sind in Größe und Median ähnlich, was die Aussage der Stabilität unterstützt. Der Boxplot für Beta = 0,5 ist viel größer mit einem höheren Median und mehr Ausreißern, was auf höhere Varianz und P_k hindeutet, was mit der Aussage des Artikels übereinstimmt.;The boxplots for beta = 0.01 and 0.1 are similar in size and median, supporting the statement of stability. The boxplot for beta = 0.5 is much larger with a higher median and more outliers, indicating higher variance and P_k, which aligns with the paper's statement.;Stabil 0.01/0.1;Stable 0.01/0.1;Requires Paper Context;'Regarding values of β, we find that Pk rates and their variance are relatively stable between the recommended settings of 0.1 and 0.01. Values larger than 0.1 lead to much worse performance. Regarding variance, no patterns within the stable range emerge, see Figure 9.'
W13-4011.pdf-Figure4.png;'Welche Beschriftung befindet sich direkt links neben der Beschriftung ''CID_BX'' auf der x-Achse?';'Which label is located directly to the left of the label ''CID_BX'' on the x-axis?';CID_AP;CID_AP;CID_AP;CID_AP;Simple Retrieval;''
W13-4011.pdf-Figure4.png;'Ist der Anteil von ''mh'' für CID_AG größer als der Anteil von ''ah'' für CID_ML?';'Is the proportion of ''mh'' for CID_AG greater than the proportion of ''ah'' for CID_ML?';Ja;Yes;Ja;Yes;Simple Calculation;''
W13-4011.pdf-Figure4.png;Welches lexikalische Element ist am häufigsten für CID_LJ vertreten, und wie hoch ist der ungefähre Prozentsatz?;Which lexical item is most frequently used for CID_LJ, and what is its approximate percentage?;'''ouais'', ungefähr 20%';'''ouais'', approximately 20%';ouais;ouais;Simple Retrieval;''
W13-4011.pdf-Figure4.png;Welches lexikalische Element ist, gemessen an der Höhe des entsprechenden Balkenteils, am zweithäufigsten für CID_YM vertreten?;Considering the height of the corresponding bar segment, which lexical item is the second most frequent for CID_YM?;ah_ouais;ah_ouais;ah_ouais;ah_ouais;Simple Retrieval;''
S19-2116.pdf-Figure2.png;Was steht auf der horizontalen Achse?;What is the label of the horizontal axis?;Vorhergesagtes Label;Predicted label;Vorhergesagtes Label;Predicted label;Simple Retrieval;''
S19-2116.pdf-Figure2.png;Was ist die Summe der Werte in der zweiten Spalte?;What is the sum of the values in the second column?;111;111;111;111;Simple Calculation;''
S19-2116.pdf-Figure2.png;Was ist der normalisierte Wert des hellsten Feldes?;What is the normalized value of the lightest cell?;1;1;1;1;Simple Retrieval;''
S19-2116.pdf-Figure2.png;Ist die Summe der Werte in der oberen linken und unteren rechten Ecke größer als die Summe der Werte in der oberen rechten und unteren linken Ecke?;Is the sum of the values in the top-left and bottom-right corners greater than the sum of the values in the top-right and bottom-left corners?;Ja;Yes;Ja;Yes;Simple Calculation;''
S19-2116.pdf-Figure2.png;'In Abschnitt 4.1 wird die Leistung des MSOC-Modells in Unteraufgabe A diskutiert. Der Artikel erwähnt, dass es noch ''beleidigende Wörter gibt, die nicht im Wörterbuch definiert sind''. Wenn man sich Abbildung 2 ansieht und die Beschreibung eines Typ-II-Fehlers berücksichtigt, welche Art von Wörtern könnte im Wörterbuch fehlen, und wie würde sich deren Aufnahme auf die Abbildung auswirken?';'Section 4.1 discusses the performance of the MSOC model on Sub-task A.  The paper mentions that there are still ''offensive words... not defined in the dictionary''.  Looking at Figure 2, and considering the description of a Type II error, what kind of word might be missing from the dictionary, and how would its inclusion change the figure?';Subtil beleidigende Wörter, wie z. B. Slang oder neu geprägte Begriffe, könnten im Wörterbuch fehlen. Die Aufnahme dieser Wörter würde die Anzahl der falsch negativen Ergebnisse (untere linke Zelle, Wert 155) verringern und die Anzahl der richtig positiven Ergebnisse (untere rechte Zelle, Wert 85) erhöhen, wodurch die Modellleistung verbessert würde.;Subtly offensive words, such as slang or newly coined terms, might be missing from the dictionary.  Including these words would decrease the number of false negatives (bottom-left cell, value 155) and increase the number of true positives (bottom-right cell, value 85), improving the model performance.;Fehlende Wörter reduzieren falsch Negative/erhöhen richtig Positive;Missing words decrease false negatives/increase true positives;Requires Paper Context;'When identifying whether a sentence is offensive or not, two methods show great difference while the accuracy and F1-score are close (see Table 2). In RNN method, there is more type I error (see Figure 1) which means the model classifies some non-offensive sentences as offensive ones. Since origin dataset is unbalanced, the neural network may not have enough non-offensive training examples to learn. Consequently, it cannot catch the feature and structure of the non-offensive sentences. In MSOC method, this problem is improved. Due to fixed human defined offensiveness dictionary, the non-offensive sentence is not easily misclassified as offensive one. **However, since there are still some offensive words appeared in dataset that are not defined in the dictionary, there is still much type II error (see Figure 2).**'
S19-2116.pdf-Figure3.png;Was steht auf der vertikalen Achse?;What is the label of the vertical axis?;Wahres Label;True label;Wahres Label;True label;Simple Retrieval;''
S19-2116.pdf-Figure3.png;Was ist die Summe der Werte in der ersten Zeile?;What is the sum of the values in the first row?;213;213;213;213;Simple Calculation;''
S19-2116.pdf-Figure3.png;Was ist das Verhältnis des größten zum kleinsten Wert in der Konfusionsmatrix?;What is the ratio of the largest to the smallest value in the confusion matrix?;201/7 ≈ 28,7;201/7 ≈ 28.7;28,7;28.7;Simple Calculation;''
S19-2116.pdf-Figure3.png;Ist die Summe der Werte, die als TIN vorhergesagt wurden, größer als die Summe der Werte, die als UNT vorhergesagt wurden?;Is the sum of the values predicted as TIN greater than the sum of the values predicted as UNT?;Ja, 221 > 19;Yes, 221 > 19;Ja;Yes;Simple Calculation;''
S19-2116.pdf-Figure3.png;Die Arbeit erwähnt, dass gezielte beleidigende Sprache oft andere strukturelle Merkmale aufweist als nicht-gezielte Sprache. Scheint die Verteilung der Werte in Abbildung 3, die die Ergebnisse der RNN-Methode für Teilaufgabe B (Kategorisierung von Beleidigungsarten) darstellt, diese Behauptung zu unterstützen? Begründen Sie Ihre Antwort anhand der visuellen Darstellung in Abbildung 3.;The paper mentions that targeted offensive language often exhibits distinct structural characteristics compared to untargeted language. Looking at Figure 3, which depicts results for the RNN method on sub-task B (categorizing offense types), does the distribution of values appear to support this claim? Explain your reasoning based on the visual representation in Figure 3.;Ja, die Verteilung stützt die Behauptung. Die Konfusionsmatrix weist eine starke diagonale Dominanz auf, was darauf hindeutet, dass das Modell die große Mehrheit der gezielten (TIN) und nicht-gezielten (UNT) Instanzen korrekt klassifiziert hat. Die höheren Werte entlang der Diagonale (201 und 7) im Vergleich zu den Werten außerhalb der Diagonale (12 und 20) legen nahe, dass das Modell unterschiedliche Merkmale der einzelnen Beleidigungsarten effektiv genutzt hat.;Yes, the distribution supports the claim. The confusion matrix shows strong diagonal dominance, indicating that the model correctly classified a large majority of the targeted (TIN) and untargeted (UNT) instances. The higher values along the diagonal (201 and 7) compared to the off-diagonal values (12 and 20) suggest that the model effectively leveraged distinct characteristics of each offense type.;Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;''
S19-2116.pdf-Figure5.png;Was ist die Beschriftung der vertikalen Achse?;What is the label of the vertical axis?;Wahres Label;True label;Wahres Label;True label;Simple Retrieval;''
S19-2116.pdf-Figure5.png;Was ist der Wert in der Zelle in der ersten Zeile und ersten Spalte?;What is the value in the cell in the first row and first column?;54;54;54;54;Simple Retrieval;''
S19-2116.pdf-Figure5.png;Was ist die Summe aller Werte in der zweiten Zeile?;What is the sum of all values in the second row?;100;100;100;100;Simple Calculation;''
S19-2116.pdf-Figure5.png;Ist der Wert in der GRP/GRP-Zelle größer als die Summe der Werte in den IND/OTH- und OTH/IND-Zellen?;Is the value in the GRP/GRP cell greater than the sum of the values in the IND/OTH and OTH/IND cells?;Ja, 54 > 19;Yes, 54 > 19;Ja;Yes;Simple Calculation;''
S19-2116.pdf-Figure5.png;'Die Konfusionsmatrix in Abbildung 5 zeigt die Ergebnisse für die RNN-Methode in Teilaufgabe C. Wie viele Sätze wurden von der RNN-Methode als ''OTH'' klassifiziert, und welche Schlussfolgerung lässt sich daraus im Vergleich zur MSOC-Methode ziehen (wie im Artikel erwähnt)?';'The confusion matrix in Figure 5 shows the results for the RNN method in Sub-task C. How many sentences were classified as ''OTH'' by the RNN method, and what conclusion can be drawn from this in comparison to the MSOC method (as mentioned in the paper)?';'Null Sätze wurden von der RNN-Methode als ''OTH'' klassifiziert. Der Artikel gibt an, dass dies daran liegt, dass die ''OTH''-Klasse nicht so charakteristisch ist wie die anderen Klassen und die kleinste Partition hat. Im Gegensatz dazu ist die MSOC-Methode in der Lage, einige Sätze als ''OTH'' zu klassifizieren.';'Zero sentences were classified as ''OTH'' by the RNN method. The paper states that this is because the ''OTH'' class is not as characteristic as the other classes and has the smallest partition. In contrast, the MSOC method is able to classify some sentences as ''OTH''.';0;0;Requires Paper Context;'In offense target identification, RNN method, although has the similar accuracy and F1 score with MSOC method (see Table 4), fails to classify any of the test sentences into ’OTH’ class.(see Figure 5) The main reason of this result is ’OTH’ class is not as characteristic as other two classes and the partition of this class is the smallest as well. On contrast, MSOC method can successfully classify some test sentences in ’OTH’ class. (see Figure 6) This may contribute to the predefined dictionary and sentence structure.'
S19-2118.pdf-Figure5.png;Welche Beschriftung steht links neben der Zelle mit dem Wert 26?;What label is to the left of the cell with the value 26?;TIN;TIN;TIN;TIN;Simple Retrieval;''
S19-2118.pdf-Figure5.png;Was ist die Summe der Werte in der zweiten Zeile?;What is the sum of the values in the second row?;27;27;27;27;Simple Calculation;''
S19-2118.pdf-Figure5.png;Um wie viel ist die Anzahl der korrekt klassifizierten TIN-Tweets höher als die Anzahl der falsch klassifizierten UNT-Tweets?;By how much is the number of correctly classified TIN tweets greater than the number of misclassified UNT tweets?;166;166;166;166;Simple Calculation;''
S19-2118.pdf-Figure5.png;Wie hoch ist der Prozentsatz der korrekt vorhergesagten UNT-Tweets im Vergleich zu allen tatsächlichen UNT-Tweets?;What is the percentage of correctly predicted UNT tweets compared to all actual UNT tweets?;22,2%;22.2%;22,2%;22.2%;Simple Calculation;''
S19-2118.pdf-Figure5.png;In Abschnitt 4.2 werden die Ergebnisse des RNN-LSTM-Modells für Teilaufgabe B diskutiert.  Welche spezifische Fehlklassifizierung (wie in der Konfusionsmatrix dargestellt) trug am stärksten zu dem niedrigeren Makro-F1-Wert im Vergleich zur Gesamtgenauigkeit bei, und warum könnte diese Fehlklassifizierung im Kontext der Identifizierung gezielter Belästigung besonders problematisch sein (siehe entsprechende Diskussionen im Artikel)?;Section 4.2 discusses the RNN-LSTM model's performance in Sub-task B. Which specific misclassification (as shown in the confusion matrix) contributed most significantly to the lower Macro-F1 score compared to the overall accuracy, and why might this misclassification be particularly problematic in the context of identifying targeted harassment (refer to related discussions in the paper)?;Die Fehlklassifizierung von TIN-Tweets als UNT (26 Instanzen) trägt am stärksten zum niedrigeren Makro-F1-Wert bei. Dies liegt daran, dass es die Leistung des Modells auf die weniger häufige Klasse (UNT) beeinflusst, was einen größeren Effekt auf den Makro-F1-Wert als die Gesamtgenauigkeit hat. Die Fehlklassifizierung von gezielter Belästigung (TIN) als nicht-zielgerichtet (UNT) ist problematisch, da sie Opfer ohne Unterstützung und Täter ohne Herausforderung lassen könnte.;The misclassification of TIN tweets as UNT (26 instances) contributes most significantly to the lower Macro-F1 score. This is because it impacts the model's performance on the less frequent class (UNT), which has a larger effect on the Macro-F1 score than overall accuracy. Misclassifying targeted harassment (TIN) as non-targeted (UNT) is problematic as it could leave victims without support and perpetrators unchallenged.;TIN als UNT;TIN as UNT;Requires Paper Context;"**4.2** **Sub-task B:**

Our approach was similar to that in the previous Sub-task. We changed the training set and labels of the same appropriately, and got our results. We used 2 class layers for training.We observed that the model gives better validation accuracy while fitted with cleaned data parsing with @user. While training the RNN network, we used alternative targeted and non-targeted tweets from annotated data. We obtained best results for RNN with Macro-F1 0.54587543782 and overall Accuracy 0.804166666667. The Hyper-parameters of this model are: Batchsize:24, LSTM Units:64, Epochs Number:1,00,000, Glove embeddings:200D, Optimizer:Adam. In Machine Learning, we used several traditional techniques. Best validation accuracy was found for Logistic Regression as classifier, countvectorizer - trigram - 50k feature."
S19-2119.pdf-Figure3.png;Welche Zahl steht im mittleren Feld der Konfusionsmatrix?;What number is in the center square of the confusion matrix?;81;81;81;81;Simple Retrieval;''
S19-2119.pdf-Figure3.png;Was ist die Summe der Werte in der ersten Zeile der Konfusionsmatrix?;What is the sum of the values in the first row of the confusion matrix?;78;78;78;78;Simple Calculation;''
S19-2119.pdf-Figure3.png;Was ist der Durchschnitt der Werte in der letzten Spalte der Konfusionsmatrix?;What is the average of the values in the last column of the confusion matrix?;3,67;3.67;3,67;3.67;Simple Calculation;''
S19-2119.pdf-Figure3.png;Ist die Summe der Werte in der ersten Zeile größer als die Summe der Werte in der ersten Spalte der Konfusionsmatrix?;Is the sum of the values in the first row greater than the sum of the values in the first column of the confusion matrix?;Ja, die Summe der ersten Zeile ist 78, während die Summe der ersten Spalte 77 ist.;Yes, the sum of the first row is 78, while the sum of the first column is 77.;Ja;Yes;Simple Calculation;''
S19-2119.pdf-Figure3.png;Welcher Klassifikator wurde für Subtask C verwendet, und wie hoch waren Präzision, Recall und F1-Score für diesen Subtask (gemäß Abbildung 3 und dem dazugehörigen Text)?;Which classifier was used for Subtask C, and what were the precision, recall, and F1-score achieved for this subtask (according to Figure 3 and the associated text)?;Für Subtask C wurde ein Entscheidungsbaum-Klassifikator verwendet. Die erreichten Metriken waren eine Präzision von 52,84%, ein Recall von 59,15% und ein F1-Score von 55,31%.;A Decision Tree classifier was used for Subtask C. The achieved metrics were a precision of 52.84%, a recall of 59.15%, and an F1-score of 55.31%.;Entscheidungsbaum;Decision Tree;Requires Paper Context;'The third system was trained on two different classifier SVM and Decision Tree. We will be only reporting the final confusion matrix of the system C which was trained on Decision Tree. The precision of the system is 52.84%, recall is 59.15% and F1 score is 55.31%.'
S19-2128.pdf-Figure4.png;Welche Zahl steht im oberen linken Quadranten der Matrix?;What number is in the top left quadrant of the matrix?;206;206;206;206;Simple Retrieval;''
S19-2128.pdf-Figure4.png;Was ist die Differenz zwischen den Zahlen im oberen rechten und unteren linken Quadranten der Matrix?;What is the difference between the numbers in the top right and bottom left quadrants of the matrix?;10;10;10;10;Simple Calculation;''
S19-2128.pdf-Figure4.png;Was ist das Verhältnis der Summe der Zahlen in der TIN-Zeile zur Summe der Zahlen in der UNT-Zeile?;What is the ratio of the sum of the numbers in the TIN row to the sum of the numbers in the UNT row?;7,89;7.89;7,89;7.89;Simple Calculation;''
S19-2128.pdf-Figure4.png;Ist die Summe der Werte auf der Hauptdiagonalen (von oben links nach unten rechts) größer als die Summe der Werte auf der Nebendiagonalen (von oben rechts nach unten links)?;Is the sum of the values on the main diagonal (top left to bottom right) greater than the sum of the values on the anti-diagonal (top right to bottom left)?;Ja, 216 > 24;Yes, 216 > 24;Ja;Yes;Simple Calculation;''
S19-2128.pdf-Figure4.png;Abbildung 4 stellt die Ergebnisse von Unteraufgabe B mit dem bidirektionalen GRU-Modell dar. Inwiefern erklärt die Verteilung der vorhergesagten im Vergleich zu den tatsächlichen Labels, die in der Matrix dargestellt sind, die hohe F1-Bewertung, die in Tabelle 6 angegeben ist (unter Berücksichtigung der Definition und Bedeutung der F1-Bewertung im Kontext des Artikels)?;Figure 4 presents the results of Sub-task B using the Bidirectional GRU model. How does the distribution of predicted vs. true labels visualized in the matrix explain the high F1-score reported in Table 6 (considering the definition and importance of F1-score within the context of the paper)?;Der hohe F1-Wert von 0,6997 wird durch die hohe Anzahl korrekter Vorhersagen auf der Diagonalen erklärt (206 korrekt vorhergesagte TIN, 10 korrekt vorhergesagte UNT), was auf eine hohe Präzision und einen hohen Rückruf hinweist, insbesondere für die TIN-Klasse. Obwohl es einige Fehlklassifikationen gibt (7 TIN als UNT, 17 UNT als TIN), ist die Gesamtgenauigkeit hoch. Der Makro-Durchschnitt-F1 berücksichtigt beide Klassen, was trotz einer geringeren Leistung bei UNT (aufgrund der geringeren Anzahl wahrer UNT-Instanzen) aufgrund der starken Leistung bei TIN immer noch zu einem hohen Gesamtergebnis führt.;The high F1-score of 0.6997 is explained by the dominant number of correct predictions on the diagonal (206 TIN correctly predicted, 10 UNT correctly predicted), indicating high precision and recall, particularly for the TIN class.  Although there are some misclassifications (7 TIN as UNT, 17 UNT as TIN), the overall accuracy is high. The macro-average F1 considers both classes, which, despite a lower performance on UNT (due to the lower number of true UNT instances), still results in a high overall score due to the strong performance on TIN.;hohe Diagonalwerte;High diagonal values;Caption Question/Complex Calculation and Logical Reasoning;"**System** **F1** **Accuracy** **(macro)**

All TIN baseline 0.4702 0.8875

All UNT baseline 0.1011 0.1125

BI-LSTM 0.6511 0.8958

**BI-GRU** **0.6997** **0.9**

LSTM 0.6455 0.8917

**Table 6: Results for Sub-task B (Binary classification)**

Confusion Matrix

0.8

TIN

206 7

0.6

0.4

UNT

17 10 0.2

0.0

Predicted label

**Figure 4: Confusion Matrix shows results for** Sub-task B using Bidirectional GRU

"
S19-2128.pdf-Figure5.png;Welche Beschriftung befindet sich in der oberen linken Ecke des Diagramms?;What label is located in the top left corner of the chart?;GRP;GRP;GRP;GRP;Simple Retrieval;''
S19-2128.pdf-Figure5.png;Was ist die Summe der Werte in der letzten Spalte?;What is the sum of the values in the last column?;12;12;12;12;Simple Calculation;''
S19-2128.pdf-Figure5.png;Was ist der Durchschnitt aller Werte in der Konfusionsmatrix?;What is the average of all the values in the confusion matrix?;23,67;23.67;23,67;23.67;Complex Calculation and Logical Reasoning;''
S19-2128.pdf-Figure5.png;'Ist die Summe der Werte für die korrekte Vorhersage von ''IND'' größer als die Summe der Werte für die fälschliche Vorhersage von ''IND''?';'Is the sum of the values for the correct prediction of ''IND'' greater than the sum of the values for the incorrect prediction of ''IND''?';Ja;Yes;Ja;Yes;Simple Calculation;''
S19-2128.pdf-Figure5.png;Die Konfusionsmatrix (Abbildung 5) zeigt die Ergebnisse für Subaufgabe C unter Verwendung eines bidirektionalen LSTM.  Welche Kategorie ('IND', 'GRP' oder 'OTH') wird vom Modell am schlechtesten klassifiziert, und warum wird diese schlechte Leistung im Paper im Zusammenhang mit den Ergebnissen von Subaufgabe C diskutiert (siehe Abschnitte, die Subaufgabe C behandeln)?;The confusion matrix (Figure 5) shows the results for Sub-task C using a bidirectional LSTM. Which category ('IND', 'GRP', or 'OTH') is the model performing worst at classifying, and why is this poor performance discussed in the paper in the context of the Sub-task C results (refer to sections discussing Sub-task C)?;'OTH ist die Kategorie mit der schlechtesten Leistung. Die Konfusionsmatrix zeigt nur 4 korrekte Vorhersagen von 35 Instanzen (14+17+4). Das Paper gibt an, dass die 'OTH'-Klasse ''relativ schwieriger zu klassifizieren'' ist aufgrund ihrer vielfältigen und weniger definierten Natur im Vergleich zu den spezifischeren Kategorien 'IND' (Individuum) und 'GRP' (Gruppe).';'OTH is the worst performing category. The confusion matrix shows only 4 correct predictions out of 35 instances (14+17+4). The paper states that the 'OTH' class is ''relatively harder to classify'' due to its diverse and less defined nature compared to the more specific 'IND' (individual) and 'GRP' (group) categories.';OTH;OTH;Requires Paper Context;"Table 7 presents our results on the test set for Sub-task C. For this multi-class classification challenge, the results are lower as compared to other two Sub-tasks. All the participating teams had a lower performance with highest F1 score of 0.66, demonstrating the difficulty of the Sub-task. Our team ranked 41 out of 65 participating teams and Bidirectional LSTM give better results with F1 score of 0.49.

**System** **F1** **Accuracy** **(macro)**

All GRP baseline 0.1787 0.3662

All IND baseline 0.2130 0.4695

All OTH baseline 0.0941 0.1643

**BI-LSTM** **0.4903** **0.6056**

BI-GRU 0.4635 0.5775

LSTM 0.4810 0.6197

**Table 7: Results for Sub-task C (Multi-Class** Classification)"
S19-2133.pdf-Figure1.png;Welche Beschriftung steht an der y-Achse?;What is the label of the y-axis?;Wahres Label;True label;Wahres Label;True label;Simple Retrieval;''
S19-2133.pdf-Figure1.png;Was ist die Summe der Werte in der ersten Zeile der Konfusionsmatrix?;What is the sum of the values in the first row of the confusion matrix?;620;620;620;620;Simple Calculation;''
S19-2133.pdf-Figure1.png;'Wie viele Tweets wurden fälschlicherweise als ''OFF'' klassifiziert?';'How many tweets were incorrectly classified as ''OFF''?';191;191;191;191;Simple Retrieval;''
S19-2133.pdf-Figure1.png;'Ist der Anteil der korrekt als ''NOT'' klassifizierten Tweets größer als der Anteil der korrekt als ''OFF'' klassifizierten Tweets?  Geben Sie die jeweiligen Prozentsätze an.';'Is the proportion of tweets correctly classified as ''NOT'' greater than the proportion of tweets correctly classified as ''OFF''? Provide the respective percentages.';"Ja. NOT: 69,2%; OFF: 23,8%";"Yes. NOT: 69.2%; OFF: 23.8%";Ja;Yes;Complex Calculation and Logical Reasoning;''
S19-2133.pdf-Figure1.png;In Abschnitt 4 wird die Verwendung von Klassengewichten erwähnt, um das Problem der Datenschiefheit zu beheben.  Wie spiegelt sich die Datenschiefheit, die in Tabelle 2 für Teilaufgabe A dargestellt ist, in der Konfusionsmatrix (Abbildung 1) wider, und welche Auswirkungen hat sie auf die Bewertung der Modellleistung, insbesondere in Bezug auf die F1 (Makro)-Metrik, die in Tabelle 3 genannt wird?;Section 4 mentions the use of class weights to address data skewness. How is the data skewness, illustrated in Table 2 for Subtask A, reflected in the confusion matrix (Figure 1), and what are its implications for evaluating model performance, specifically regarding the F1 (macro) metric mentioned in Table 3?;'Die Konfusionsmatrix spiegelt die Datenschiefheit wider, indem sie eine hohe Anzahl wahrer Negative (429) für ''NOT'' im Vergleich zu wahren Positiven (57) für ''OFF'' zeigt. Dies entspricht dem Ungleichgewicht im Datensatz (Tabelle 2: 9460 NOT vs. 4640 OFF in den Trainingsdaten). Dies beeinflusst den F1 (Makro)-Score, da er die Beiträge beider Klassen ausgleicht, im Gegensatz zur Genauigkeit, die durch die Leistung der Mehrheitsklasse aufgebläht würde.';'The confusion matrix reflects the skewness with a high number of true negatives (429) for ''NOT'' compared to true positives (57) for ''OFF'', corresponding to the imbalance in the dataset (Table 2: 9460 NOT vs. 4640 OFF in training data). This impacts the F1 (macro) score as it balances the contributions of both classes, unlike accuracy which would be inflated by the majority class performance.';Datenschiefheit beeinflusst F1 (Makro);Skewness affects F1 (macro);Requires Paper Context;"**A** **B** **C** **Train** **Test** **Total**

OFF TIN IND 2407 100 2507

OFF TIN OTH 395 35 430

OFF TIN GRP 1074 78 1152

OFF UNT  - 524 27 551

NOT - - 8840 620 9460

**All** 13240 860 14100

Table 2: Distribution of the labels in the dataset

## 4 Methodology

...

Secondly, class weights were assigned to the different classes present in the data. The weights were approximately chosen to be proportional to the inverse of the respective frequencies of the classes. Intuitively, the model now gives equal weight to the skewed classes and this penalizes tendencies to overfit to the data. ...

**System** **F1 (macro)** **Accuracy**

All NOT baseline 0.4189 0.7209

All OFF baseline 0.2182 0.2790

BiLSTM 0.4650 0.5651

Table 3: Sub-task A, garain CodaLab 528038 (BiDirectional LSTM)"
S19-2138.pdf-Figure2.png;Welche Farbe hat das Feld, das die korrekten Vorhersagen für 'IND' darstellt?;What color is the square representing the correct predictions for 'IND'?;Weiß;White;Weiß;White;Simple Retrieval;''
S19-2138.pdf-Figure2.png;Wie viele 'IND'-Instanzen wurden fälschlicherweise als 'GRP' klassifiziert?;How many 'IND' instances were misclassified as 'GRP'?;8;8;8;8;Simple Retrieval;''
S19-2138.pdf-Figure2.png;Wie viele Instanzen wurden insgesamt korrekt klassifiziert (Diagonale der Matrix)?;How many instances were correctly classified in total (diagonal of the matrix)?;53 + 91 + 2 = 146;53 + 91 + 2 = 146;146;146;Simple Calculation;''
S19-2138.pdf-Figure2.png;Welcher Anteil der 'OTH'-Vorhersagen war korrekt, und wie hoch ist dieser Anteil in Prozent?;What proportion of the 'OTH' predictions were correct, and what is this proportion as a percentage?;2 von 5 'OTH'-Vorhersagen waren korrekt (2 + 1 + 2 = 5 'OTH'-Vorhersagen insgesamt). Das sind 40%.;2 out of 5 'OTH' predictions were correct (2 + 1 + 2 = 5 total 'OTH' predictions). This is 40%. ;40%;40%;Simple Calculation;''
S19-2138.pdf-Figure2.png;Abbildung 2 zeigt die Konfusionsmatrix für Teilaufgabe C. Wie wird die Klassifikatorleistung in Tabelle 4 bewertet, und welchen F1-Makro-Wert erreicht der SVM-Klassifikator? Ziehen Sie Schlussfolgerungen aus dem Vergleich der Konfusionsmatrix mit dem F1-Makro-Wert.;Figure 2 shows the confusion matrix for Subtask C. How is the classifier performance evaluated in Table 4, and what F1 macro score does the SVM classifier achieve? Draw conclusions by comparing the confusion matrix with the F1 macro score.;Die Klassifikatorleistung wird mit dem F1-Makro-Score und der Genauigkeit bewertet. Der SVM-Klassifikator erreicht einen F1-Makro-Score von 0,5243. Die Konfusionsmatrix zeigt, dass der Klassifikator 'IND'-Instanzen gut identifiziert (91 von 100 korrekt), aber mit 'GRP' (53/78 korrekt) und 'OTH' (2/35 korrekt) zu kämpfen hat. Die geringere Leistung bei diesen Klassen, insbesondere bei 'OTH', senkt den gesamten F1-Makro-Score, was den Effekt von Klassenungleichgewichten verdeutlicht.;The classifier performance is evaluated using the F1 macro score and accuracy. The SVM classifier achieves an F1 macro score of 0.5243. The confusion matrix reveals that the classifier performs well in identifying 'IND' instances (91 out of 100 correct), but struggles with 'GRP' (53/78 correct) and 'OTH' (2/35 correct). The lower performance on these classes, particularly 'OTH', lowers the overall F1 macro score, demonstrating the effect of class imbalance.;0,5243;0.5243;Requires Paper Context;"|System|F macro Accuracy 1| |---|---| |All GRP baseline All IND baseline All OTH baseline|0.1787 0.3662 0.2130 0.4695 0.0941 0.1643| |SVM classifier|0.5243 0.6854|
Table 4: The official UM-IU@LING results (SVM) for subtask C."
S19-2181.pdf-Figure2.png;Welche Zahl steht im hellsten Feld der Konfusionsmatrix?;What number is in the lightest colored square of the confusion matrix?;24;24;24;24;Simple Retrieval;''
S19-2181.pdf-Figure2.png;Was ist die Summe der Werte in der ersten Zeile der Konfusionsmatrix?;What is the sum of the values in the first row of the confusion matrix?;407;407;407;407;Simple Calculation;''
S19-2181.pdf-Figure2.png;Was ist die Summe aller Werte in der Konfusionsmatrix?;What is the sum of all the values in the confusion matrix?;645;645;645;645;Simple Calculation;''
S19-2181.pdf-Figure2.png;Ist die Summe der Werte in der Hauptdiagonale größer als die Summe der Werte in der Nebendiagonale?;Is the sum of the values on the main diagonal greater than the sum of the values on the off-diagonal?;Ja, 392 (178 + 214) ist größer als 253 (229 + 24).;Yes, 392 (178 + 214) is greater than 253 (229 + 24).;Ja;Yes;Simple Calculation;''
S19-2181.pdf-Figure2.png;'In Abschnitt 3.4 wird erwähnt, dass das Modell Schwierigkeiten mit Artikeln ''nach Artikel'' und nicht ''nach Herausgeber'' hatte. Welche Beobachtung aus Abbildung 2 könnte diese geringere Genauigkeit (0.6077) im Vergleich zum ersten Experiment unter Berücksichtigung des Unterschieds zwischen der Analyse von Artikeln ''nach Artikel'' im Vergleich zu ''nach Herausgeber'' erklären?  Beziehen Sie sich dabei auf konkrete Werte aus der Konfusionsmatrix und verbinden Sie diese mit den im Artikel genannten möglichen Gründen für die Leistungsunterschiede. (Hinweis: Abschnitt 3.4 erwähnt unterschiedliche Quellen für die Datensätze)';'Section 3.4 mentions that the model struggled with articles ''by article'' rather than ''by publisher.'' Looking at Figure 2, what observation might explain this lower accuracy (0.6077) compared to the first experiment, considering the difference between analyzing articles ''by article'' versus ''by publisher''?  Refer to specific values within the confusion matrix and connect them to the potential reasons for the discrepancy in performance mentioned in the paper. (Hint: Section 3.4 mentions differing sources for the datasets).';'Die Konfusionsmatrix (Abbildung 2) zeigt eine hohe Anzahl falsch positiver Ergebnisse (229). Das bedeutet, das Modell hat häufig nicht-verzerrte Artikel als verzerrt klassifiziert. Abschnitt 3.4 führt den Leistungsunterschied auf die unterschiedlichen Datenquellen für ''nach Herausgeber'' (Trainingsdaten) und ''nach Artikel'' (Testdaten) zurück. Dieser Unterschied, zusammen mit der manuellen Auswahl der ''nach Artikel''-Daten, führte wahrscheinlich zu Variationen, die das Modell nicht verarbeiten konnte, was zu der geringeren Genauigkeit führte.';'The confusion matrix (Figure 2) reveals a high number of false positives (229).  This means the model frequently classified non-biased articles as biased.  Section 3.4 attributes the performance difference to the differing data sources for ''by publisher'' (training data) and ''by article'' (test data). This difference, along with the manual selection of ''by article'' data, likely introduced variations the model wasn't trained to handle, leading to the lower accuracy.';229 Falsch Positive;229 false positives;Requires Paper Context;'We guess the reason why we get two different accuracies in two kinds of articles (by publisher, by article), is that the source of these two articles are different. Data by publisher is decided by the press and publisher, and the other is decided by manual selection. We only trained the data by publisher, so, it seems that it will not perform well on the type of data by article.'
U17-1006.pdf-Figure3.png;Welcher Wert befindet sich in der Zelle in der ersten Zeile und zweiten Spalte?;What value is in the cell in the first row and second column?;69,8;69.8;69,8;69.8;Simple Retrieval;''
U17-1006.pdf-Figure3.png;Was ist die Differenz zwischen dem Substitutionsfehler von M zu L und L zu M?;What is the difference between the substitution error of M to L and L to M?;7,2;7.2;7,2;7.2;Simple Calculation;''
U17-1006.pdf-Figure3.png;Wie hoch ist die durchschnittliche Substitutionsfehlerrate, wenn H durch einen anderen Ton ersetzt wird (ohne H selbst)?;What is the average substitution error rate when H is substituted by another tone (excluding H itself)?;25,0;25.0;25;25;Complex Calculation and Logical Reasoning;''
U17-1006.pdf-Figure3.png;Ist die Summe der Substitutionsraten auf der Diagonalen größer als die Summe aller anderen Substitutionsraten?;Is the sum of substitution rates on the diagonal greater than the sum of all other substitution rates?;Nein. Die Summe der Raten auf der Diagonalen ist 0. Die Summe aller anderen Raten ist größer als 0.;No. The sum of the rates on the diagonal is 0. The sum of all other rates is greater than 0.;Nein;No;Complex Calculation and Logical Reasoning;''
U17-1006.pdf-Figure3.png;Der Artikel erwähnt, dass die häufigsten Substitutionsfehler zwischen M und L liegen.  Wie hoch ist gemäß Abbildung 3 der prozentuale Unterschied zwischen der häufigsten Substitution von M durch einen anderen Ton und der häufigsten Substitution von L durch einen anderen Ton? Stimmt dies mit der Behauptung im Artikel überein? Welche Gründe nennt der Artikel für diese Ähnlichkeit?;The paper mentions that the most common substitution errors are between M and L. According to Figure 3, what is the percentage difference between the most frequent substitution of M for another tone and the most frequent substitution of L for another tone? Does this align with the claim in the paper? What reasons does the paper provide for this similarity?;Die häufigste Substitution von M ist für L (69,8%). Die häufigste Substitution von L ist für M (77%). Der prozentuale Unterschied beträgt 7,2%. Dies stimmt mit der Behauptung des Artikels überein. Der Artikel gibt an, dass M und L akustisch ähnlich sind, da sie benachbart sind, und dass derselbe Ton mit unterschiedlichen Tonhöhen an verschiedenen Stellen in einem Satz realisiert werden kann, was zu überlappenden Tonhöhenbereichen führt. Darüber hinaus sind M und L die häufigsten Tonbezeichnungen.;The most frequent substitution of M is for L (69.8%). The most frequent substitution of L is for M (77%). The percentage difference is 7.2%. This aligns with the paper's claim. The paper states that M and L are acoustically similar, being neighbors, and that the same tone can be realized with different pitches at different points in a sentence, leading to overlapping pitch ranges. Additionally, M and L are the most common tonal labels.;7,2%;7.2%;Caption Question/Complex Calculation and Logical Reasoning;"Figure 3: Confusion matrix showing the rates of substitution errors between tones (as a percentage, normalized per row).

The most common tonal substitution errors were those between between M and L. Acoustically, M and L are neighbours; as mentioned above, in Na the same tone can be realised with a different pitch at different points in a sentence, leading to overlapping pitch ranges between these tones. Moreover, M and L tones were by far the most common tonal labels."
W14-1616.pdf-Figure1.png;'Welche chinesischen Schriftzeichen sind mit dem englischen Wort ''We'' verbunden?';'Which Chinese characters are aligned with the English word ''We''?';women;women;women;women;Simple Retrieval;''
W14-1616.pdf-Figure1.png;Wie viele chinesische Schriftzeichen sind mit genau einem englischen Wort verbunden?;How many Chinese characters are aligned with exactly one English word?;6;6;6;6;Simple Calculation;''
W14-1616.pdf-Figure1.png;'Wenn man die Anzahl der Verbindungen von ''yinggai'' mit englischen Wörtern mit der Anzahl der Verbindungen von ''kaolv'' mit englischen Wörtern multipliziert, was ist das Ergebnis?';'If you multiply the number of alignments of ''yinggai'' with English words by the number of alignments of ''kaolv'' with English words, what is the result?';2;2;2;2;Simple Calculation;''
W14-1616.pdf-Figure1.png;Gibt es mehr Verbindungen zwischen chinesischen Schriftzeichen und englischen Wörtern oberhalb oder unterhalb der Diagonalen von links oben nach rechts unten?;Are there more alignments between Chinese characters and English words above or below the diagonal from top left to bottom right?;Unterhalb;Below;Unterhalb;Below;Simple Calculation;''
W14-33.pdf-Figure6.png;Welcher Wert befindet sich auf der vertikalen Achse an zweiter Stelle von oben?;What value is located on the vertical axis in the second position from the top?;2;2;2;2;Simple Retrieval;''
W14-33.pdf-Figure6.png;Welcher Wert entspricht dem hellsten Quadrat in der Heatmap?;What value corresponds to the lightest square in the heatmap?;0.0;0.0;0.0;0.0;Simple Retrieval;''
W14-33.pdf-Figure6.png;Wie hoch ist die Summe der Werte in der Diagonale von links oben nach rechts unten?;What is the sum of the values along the diagonal from top left to bottom right?;Ungefähr 0.0;Approximately 0.0;0.0;0.0;Simple Calculation;''
W14-33.pdf-Figure6.png;Ist die Summe der Werte der drei dunkelsten Quadrate größer als die Summe der Werte der drei hellsten Quadrate (ohne die weißen Quadrate)?;Is the sum of the values of the three darkest squares greater than the sum of the values of the three lightest squares (excluding the white squares)?;Ja.;Yes.;Ja;Yes;Simple Calculation;''
W14-33.pdf-Figure6.png;'Wie verändert sich die Verteilung der paarweisen Bewertungen in Abbildung 6 (erste 20 %) im Vergleich zu Abbildung 7 (letzte 20 %)?  Was sagt diese Veränderung über die Fokussierung von TrueSkill auf ''wettbewerbsfähige Spiele'' aus?';'How does the distribution of pairwise judgments change from Figure 6 (first 20%) to Figure 7 (last 20%)? What does this change indicate about TrueSkill's focus on ''competitive matches''?';'Die Verteilung verschiebt sich von relativ gleichmäßig über alle Paare (Abbildung 6) zu konzentriert entlang der Diagonale, die Vergleiche zwischen ähnlichen Systemen darstellt (Abbildung 7). Dies zeigt, dass TrueSkill ''wettbewerbsfähige Spiele'' - den Vergleich ähnlich qualifizierter Systeme - priorisiert, um die Fähigkeitsbewertungen im Laufe des Trainings effektiver zu verfeinern.';'The distribution shifts from relatively uniform across all pairs (Figure 6) to concentrated along the diagonal, which represents comparisons between similar systems (Figure 7). This shows TrueSkill prioritizing ''competitive matches'' - comparing similarly skilled systems - for more effective refinement of skill estimations as training progresses.';Gleichmäßig zu diagonal;Uniform to diagonal;Complex Calculation and Logical Reasoning;''
W16-2206.pdf-Figure4.png;'Welches deutsche Wort steht in der gleichen Zeile wie das englische Wort ''build''?';'Which German word is in the same row as the English word ''build''?';bauen;bauen;bauen;bauen;Simple Retrieval;''
W16-2206.pdf-Figure4.png;'Wie viele graue Kästchen befinden sich in der Zeile mit dem deutschen Wort ''und''?';'How many grey boxes are in the row with the German word ''und''?';1;1;1;1;Simple Retrieval;''
W16-2206.pdf-Figure4.png;'Wie viele graue Kästchen befinden sich in der Diagonalen von links unten nach rechts oben, angefangen beim deutschen Wort ''und'', ohne die Kästchen in der Zeile mit dem englischen Wort ''build'' mitzuzählen?';'How many grey boxes are there in the diagonal line from bottom left to top right, starting from the German word ''und'', excluding the boxes on the same row as the English word ''build''?';2;2;2;2;Simple Calculation;''
W16-2206.pdf-Figure4.png;Der deutsche Satz in Abbildung 4 ist vorverarbeitet. Welche Art der Vorverarbeitung wurde laut dem Artikel auf deutsche Sätze angewendet und warum ist diese Vorverarbeitung für die maschinelle Übersetzung wichtig?;The German sentence in Figure 4 is preordered. According to the paper, what kind of preprocessing was applied to German sentences and why is this preprocessing important for machine translation?;Es wurden regelbasierte Langstrecken-Verb-Umordnungen basierend auf Wortarten angewendet. Dies ist wichtig für die maschinelle Übersetzung, da Deutsch und Englisch unterschiedliche Wortstellungen haben, insbesondere in Bezug auf Verben. Die Vorordnung hilft, die deutsche Satzstruktur näher an die englische Struktur zu bringen, was es für das Übersetzungssystem einfacher macht, korrekte und flüssige Übersetzungen zu generieren.;Part-of-speech-based long-range verb reordering rules were applied. This is important for machine translation because German and English have different word orders, especially regarding verbs. Preordering helps bring the German sentence structure closer to the English structure, making it easier for the translation system to generate correct and fluent translations.;Verb-Umordnung;Verb reordering;Caption Question/Requires Paper Context;'We apply part-of-speech-based long-range verb reordering rules to the German side in a preprocessing step for all German English systems _→_ (Popovi´c and Ney, 2006), including the baselines.'
W16-2302.pdf-Figure1.png;Welche Metrik befindet sich in der ersten Zeile des ersten RR-Diagramms (de-en)?;Which metric is in the first row of the first RR plot (de-en)?;CharacTer;CharacTer;CharacTer;CharacTer;Simple Retrieval;''
W16-2302.pdf-Figure7.png;Welche Metrik wird in der zweiten Zeile von unten im ersten Diagramm (en-es) angezeigt?;Which metric is listed in the second row from the bottom in the first plot (en-es)?;mosesPER;mosesPER;mosesPER;mosesPER;Simple Retrieval;''
W16-2302.pdf-Figure7.png;Wie viele Metriken schneiden im Plot en-es signifikant besser ab als MPEDA (angezeigt durch ein dunkleres grünes Quadrat links von MPEDA)?;In the en-es plot, how many metrics perform significantly better than MPEDA (indicated by a darker green square to the left of MPEDA)?;4;4;4;4;Simple Calculation;''
W16-2302.pdf-Figure7.png;Ist die Anzahl der Metriken, die im Diagramm en-nl signifikant besser abschneiden als chrF1, größer als die Anzahl der Metriken, die im Diagramm en-pt signifikant besser abschneiden als chrF1?;Is the number of metrics significantly outperforming chrF1 in the en-nl plot greater than the number of metrics significantly outperforming chrF1 in the en-pt plot?;Ja.;Yes.;Ja;Yes;Simple Calculation;''
W16-2302.pdf-Figure9.png;Welche Metrik befindet sich in der untersten Zeile der Konfusionsmatrix?;Which metric is in the bottommost row of the confusion matrix?;sentBLEU;sentBLEU;sentBLEU;sentBLEU;Simple Retrieval;''
W16-2302.pdf-Figure9.png;Wie viele grüne Quadrate gibt es insgesamt in der Matrix?;How many green squares are there in total in the matrix?;29;29;29;29;Simple Calculation;''
W16-2302.pdf-Figure9.png;Wie hoch ist der Anteil der grünen Quadrate an der Gesamtzahl der Quadrate in der Matrix (in Prozent)?;What percentage of the total number of squares in the matrix are green?;35,8%;35.8%;35.8%;35.8%;Simple Calculation;''
W16-2302.pdf-Figure9.png;Gibt es mehr grüne Quadrate oberhalb oder unterhalb der Hauptdiagonalen (von oben links nach unten rechts)?;Are there more green squares above or below the main diagonal (from top left to bottom right)?;Oberhalb;Above;Oberhalb;Above;Simple Calculation;''
W16-2302.pdf-Figure9.png;Laut der Bildunterschrift wurde der Williams-Test verwendet, um die Ergebnisse zu generieren. Welche Nullhypothese testet der Williams-Test in diesem Kontext, und wie wird die Ablehnung dieser Nullhypothese in Abbildung 9 visuell dargestellt?;According to the caption, the Williams test was used to generate the results. What null hypothesis does the Williams test evaluate in this context, and how is the rejection of this null hypothesis visually represented in Figure 9?;Der Williams-Test prüft die Nullhypothese, dass kein statistisch signifikanter Unterschied zwischen den Korrelationen zweier Metriken mit menschlichen Bewertungen besteht. Die Ablehnung dieser Nullhypothese, d. h., es besteht *doch* ein statistisch signifikanter Unterschied, wird durch eine grüne Zelle dargestellt. Die grüne Zelle zeigt an, dass die Metrik in der entsprechenden Zeile eine signifikant höhere Korrelation mit menschlichen Bewertungen aufweist als die Metrik in der entsprechenden Spalte.;The Williams test evaluates the null hypothesis that there is no statistically significant difference between the correlations of two metrics with human judgments. The rejection of this null hypothesis, meaning that there *is* a statistically significant difference, is represented by a green cell. The green cell indicates that the metric in the corresponding row has a significantly higher correlation with human judgments than the metric in the corresponding column.;Unterschiedliche Korrelation mit menschlicher Bewertung;Different correlation with human judgement;Caption Question/Complex Calculation and Logical Reasoning;''
W16-2503.pdf-Figure5.png;'Was ist die Summe der Werte in der Zeile ''Currencies''?';'What is the sum of the values in the ''Currencies'' row?';0.9;0.9;0.9;0.9;Simple Calculation;''
W16-2503.pdf-Figure5.png;'Was ist der durchschnittliche Wert über alle neun Felder für ''Base to third person''?';'What is the average value across all nine fields for ''Base to third person''?';0.43;0.43;0.43;0.43;Complex Calculation and Logical Reasoning;''
W16-2503.pdf-Figure5.png;'In Abbildung 5 wird die Genauigkeit von ''ADD'' mit zwei Baselines verglichen. Stimmt die Aussage im Text, dass s2 in einigen morphologischen Kategorien (z.B. ''Base to third person'') viel besser abschneidet als s10, mit den in der Abbildung dargestellten Werten überein? Begründen Sie Ihre Antwort anhand konkreter Datenpunkte.';'Figure 5 compares the accuracy of ''ADD'' with two baselines. Does the statement in the text that s2 performs much better than s10 in some morphological inflection categories (e.g., ''Base to third person'') align with the values presented in the figure? Justify your answer using specific data points.';'Ja, die Aussage stimmt mit Abbildung 5 überein. Für ''Base to third person'' erreicht s2 eine Genauigkeit von 0.70, während s10 nur 0.44 erreicht. Dies zeigt einen signifikanten Vorteil für s2 in dieser spezifischen morphologischen Flexionskategorie, wie im Text hervorgehoben.';'Yes, the statement is consistent with Figure 5. For ''Base to third person'', s2 achieves an accuracy of 0.70, while s10 only reaches 0.44. This demonstrates a significant advantage for s2 in this specific morphological inflection category, as highlighted in the text.';Ja;Yes;Caption Question/Simple Calculation;'Yet the breakdown of the results by category (Figure 5) shows that the similarity in average performance across the spaces obscures differences across categories: _s2 performed much better than s10 in some of the_ morphological inflection categories (e.g., .7 compared to .44 for the base-to-third-person relation),'
W16-4821.pdf-Figure1.png;Welche Beschriftung steht in der untersten Zeile der Matrix?;What label is in the bottom row of the matrix?;sr;sr;sr;sr;Simple Retrieval;''
W16-4821.pdf-Figure1.png;Ist die Summe der Werte in der Zeile 'pt-pt' größer als die Summe der Werte in der Zeile 'es-es'?;Is the sum of the values in the 'pt-pt' row greater than the sum of the values in the 'es-es' row?;Nein. Beide Zeilen haben die gleiche Summe.;No. Both rows have the same sum.;Nein;No;Simple Calculation;''
W16-4821.pdf-Figure1.png;Welche Sprache wird am häufigsten mit 'fr-fr' verwechselt, gemessen an den Farbintensitäten in der Matrix (ausgenommen die korrekte Klassifizierung von 'fr-fr' als 'fr-fr')?;Which language is most often confused with 'fr-fr', judging by the color intensities in the matrix (excluding the correct classification of 'fr-fr' as 'fr-fr')?;fr-ca. Die Zelle am Schnittpunkt von 'fr-fr' (wahre Beschriftung) und 'fr-ca' (vorhergesagte Beschriftung) hat die höchste Intensität außerhalb der Diagonale in der 'fr-fr'-Zeile, was auf die häufigste Verwechslung hinweist.;fr-ca. The cell at the intersection of 'fr-fr' (true label) and 'fr-ca' (predicted label) has the highest intensity off the diagonal in the 'fr-fr' row, indicating the most frequent confusion.;fr-ca;fr-ca;Simple Retrieval;''
W16-4825.pdf-Figure2.png;Welche Sprache befindet sich in der zweiten Zeile von oben auf der y-Achse?;Which language is on the second row from the top on the y-axis?;es-ar;es-ar;es-ar;es-ar;Simple Retrieval;''
W16-4825.pdf-Figure2.png;Welchen Wert hat das hellste Quadrat in der Diagonale?;What is the value represented by the brightest square on the diagonal?;Ungefähr 0.7;Approximately 0.7;0.7;0.7;Simple Retrieval;''
W16-4825.pdf-Figure2.png;Ist der Wert für die Kombination fr-fr (wahrer Wert) und fr-ca (vorhergesagter Wert) größer oder kleiner als 0,2?;Is the value for the combination of fr-fr (true label) and fr-ca (predicted label) greater or less than 0.2?;Weniger als 0,2. Es scheint nahe bei 0 zu liegen.;Less than 0.2. It appears to be close to 0.;Kleiner;Less;Simple Calculation;''
W16-4825.pdf-Figure2.png;Welche drei Sprachen haben die höchsten Werte auf der Diagonale (d.h. die höchste Klassifizierungsgenauigkeit)?;Which three languages have the highest values on the diagonal (i.e., the highest classification accuracy)?;fr-fr, my und id.;fr-fr, my, and id.;fr-fr, my, id;fr-fr, my, id;Complex Calculation and Logical Reasoning;''
W16-4825.pdf-Figure2.png;Welche Faktoren könnten laut der Diskussion im Paper und der Konfusionsmatrix die Schwierigkeiten bei der Unterscheidung zwischen Bosnisch (bs) und Serbisch (sr) erklären?;Based on the confusion matrix and the discussion in the paper, what contributing factors might explain the observed difficulty in distinguishing between Bosnian (bs) and Serbian (sr)?;Der Artikel erwähnt, dass Bosnisch eine der schwierigsten zu klassifizierenden Sprachen war, nennt aber keine spezifischen Gründe für die Verwechslung mit Serbisch. Die Konfusionsmatrix bestätigt visuell diese Schwierigkeit und zeigt eine signifikante Verwechslung zwischen den beiden. Weitere Analysen könnten sprachliche Ähnlichkeiten oder Datenbeschränkungen umfassen.;The paper mentions that Bosnian was one of the most difficult languages to classify but doesn't give specific reasons for confusion with Serbian. The confusion matrix visually confirms the difficulty, showing significant confusion between the two.  Further analysis might involve linguistic similarities or data limitations.;Sprachliche Ähnlichkeiten/Datenbeschränkungen;Linguistic similarities/Data limitations;Requires Paper Context;'The confusion matrix[3] for Run 1 is given below in Table 7 and graphially in Figure 2. Bosnian and Mexican Spanish proved to be the most challenging classes.'
W19-5211.pdf-Figure10.png;Welche Beschriftung befindet sich links neben der dritten Zeile von oben?;What is the label to the left of the third row from the top?;Layer 3;layer 3;Layer 3;layer 3;Simple Retrieval;''
W19-5211.pdf-Figure10.png;Was ist die Summe der Werte in der zweiten Spalte von links in der ersten und zweiten Zeile?;What is the sum of the values in the second column from the left in the first and second rows?;1,17;1.17;1,17;1.17;Simple Calculation;''
W19-5211.pdf-Figure10.png;Was ist der Durchschnitt aller Werte in der vierten Zeile?;What is the average of all the values in the fourth row?;0,3471;0.3471;0,3471;0.3471;Complex Calculation and Logical Reasoning;''
W19-5211.pdf-Figure10.png;Ist die Summe der Werte in der vorletzten Spalte größer als die Summe der Werte in der zweiten Spalte?;Is the sum of the values in the second to last column greater than the sum of the values in the second column?;Ja;Yes;Ja;Yes;Complex Calculation and Logical Reasoning;''
W19-5211.pdf-Figure10.png;Die Genauigkeit der Klassifizierung ist für Wörter mit geringer Häufigkeit niedrig. Welche Erklärung liefert der Artikel für dieses Ergebnis in Abbildung 10?;The classification accuracy is low for low-frequency words. What explanation does the paper provide for this result shown in Figure 10?;Die geringere Genauigkeit für Wörter mit niedriger Frequenz ist auf das begrenzte Vorkommen entsprechender Transformer-Zustände in den Trainingsdaten des Klassifikators zurückzuführen. Der Klassifikator hat nicht genügend Beispiele dieser seltenen Wörter gesehen, um sie effektiv klassifizieren zu lernen.;The lower accuracy for low-frequency words is due to the limited occurrences of corresponding transformer states in the classifier's training data.  The classifier has not seen enough examples of these infrequent words to learn to classify them effectively.;begrenzte Vorkommen in den Trainingsdaten;Limited occurrences in training data;Requires Paper Context;'While classification accuracy is notably low for infrequent sub-words, this can be attributed to the limited occurrence of the corresponding transformer states in the classifier’s training data.'
W19-5211.pdf-Figure11.png;Was ist der Wert in der Zelle in der ersten Zeile und vierten Spalte?;What is the value in the cell in the first row and fourth column?;0.999;0.999;0.999;0.999;Simple Retrieval;''
W19-5211.pdf-Figure11.png;Was ist die Summe der Werte in der zweiten Zeile, dritter Spalte und der dritten Zeile, vierter Spalte?;What is the sum of the values in the second row, third column and the third row, fourth column?;0.895;0.895;0.895;0.895;Simple Calculation;''
W19-5211.pdf-Figure11.png;Was ist der Durchschnittswert aller Zellen in der fünften Zeile, die einen Wert über 0,1 haben?;What is the average value of all cells in the fifth row that have a value greater than 0.1?;0.362;0.362;0.362;0.362;Complex Calculation and Logical Reasoning;''
W19-5211.pdf-Figure11.png;Ist der Durchschnittswert aller Zellen in den ersten drei Zeilen größer als der Durchschnittswert der Zellen in den letzten drei Zeilen?;Is the average value of all the cells in the first three rows greater than the average value of the cells in the last three rows?;Ja.;Yes.;Ja;Yes;Complex Calculation and Logical Reasoning;''
W19-5211.pdf-Figure11.png;In Abbildung 11 wird die Genauigkeit der frequenzbasierten Klassifizierung für Zustände des Decoders mit lexikalischen Abkürzungen dargestellt.  Welche zwei Sprachpaare wurden in den Experimenten verwendet, die den Daten für diese Abbildung zugrunde liegen, und welcher Datensatz wurde jeweils für die Evaluation verwendet?;Figure 11 shows the frequency-based classification accuracy on states from the decoder with lexical shortcuts. Which two language pairs were used in the experiments underlying the data in this figure, and which dataset was used for evaluation in each case?;Englisch-Deutsch (EN→DE) ausgewertet mit newstest2014, und Englisch-Russisch (EN→RU) ausgewertet mit newstest2017.;English to German (EN→DE) evaluated with newstest2014, and English to Russian (EN→RU) evaluated with newstest2017.;EN→DE (newstest2014), EN→RU (newstest2017);EN→DE (newstest2014), EN→RU (newstest2017);Requires Paper Context;'Evaluation for EN DE models is _→_ done on newstest2014, while newstest2017 is used for EN RU models.'
W19-5211.pdf-Figure19.png;Welche Farbe repräsentiert den niedrigsten Wert in der Heatmap?;Which color represents the lowest value in the heatmap?;Hellblau repräsentiert den niedrigsten Wert in der Heatmap.;Light blue represents the lowest value in the heatmap.;Hellblau;Light blue;Simple Retrieval;''
W19-5211.pdf-Figure19.png;Was ist die Summe der Werte in der ersten Zeile?;What is the sum of the values in the first row?;Die Summe der Werte in der ersten Zeile ist 3,95.;The sum of the values in the first row is 3.95.;3,95;3.95;Simple Calculation;''
W19-5211.pdf-Figure19.png;Ist der Durchschnittswert der Zahlen in der ersten Spalte größer als der Durchschnittswert der Zahlen in der letzten Spalte?;Is the average of the numbers in the first column greater than the average of the numbers in the last column?;Nein, der Durchschnitt der ersten Spalte  ist kleiner als der Durchschnitt der letzten Spalte.;No, the average of the first column is less than the average of the last column.;Nein;No;Complex Calculation and Logical Reasoning;''
W19-5211.pdf-Figure19.png;Welches Wort aus den Spaltenbeschriftungen hat den höchsten Wert in der letzten Zeile (Layer 6)?;Which word from the column labels has the highest value in the last row (Layer 6)?;OTHER hat den höchsten Wert (0,895) in der letzten Zeile.;OTHER has the highest value (0.895) in the last row.;OTHER;OTHER;Simple Retrieval;''
W19-5211.pdf-Figure19.png;In Abschnitt A.3 werden verschiedene Auswertungen auf Basis von Wortarten und Subwort-Häufigkeiten erwähnt. Welche Art von Klassifikationsgenauigkeit wird in Abbildung 19 dargestellt, und wie wird diese im Text beschrieben (z.B. basierend auf Wortarten oder Häufigkeiten)?;Section A.3 mentions different evaluations based on part-of-speech tags and subword frequencies. What type of classification accuracy is visualized in Figure 19, and how is this described in the text (e.g., based on POS tags or frequencies)?;'Abbildung 19 visualisiert die POS-basierte Klassifikationsgenauigkeit. Abschnitt A.3 sagt explizit: ''Accuracy scores conditioned on POS tags are visualized in Figures 16-23.''';'Figure 19 visualizes POS-based classification accuracy.  Section A.3 explicitly states: ''Accuracy scores conditioned on POS tags are visualized in Figures 16-23.''';POS-basiert;POS-based;Requires Paper Context;'For frequency-based evaluation, we divide sub-words into ten equally-sized frequency bins, with bin 1 containing the least frequent sub-words and bin 10 containing the most frequent ones. We do not observe any immediately obvious, significant effects of either POS or frequency on the retention of lexical features. While classification accuracy is notably low for infrequent sub-words, this can be attributed to the limited occurrence of the corresponding transformer states in the classifier’s training data. Evaluation for EN DE models is _→_ done on newstest2014, while newstest2017 is used for EN RU models. Figures 8-15 present results _→_ for the frequency-based classification. Accuracy scores conditioned on POS tags are visualized in Figures 16-23.'
2015.jeptalnrecital-court.38.pdf-Figure4.png;Welcher Balken ist im linken Diagramm am höchsten?;Which bar is the tallest in the leftmost chart?;Der höchste Balken im linken Diagramm entspricht Delta = 0,005%.;The tallest bar in the leftmost chart corresponds to delta = 0.005%.;0,005%;0.005%;Simple Retrieval;''
2015.jeptalnrecital-court.38.pdf-Figure4.png;Was ist der F-Score im linken Diagramm, wenn Delta 0,05% beträgt?;What is the F-score in the leftmost chart when delta is 0.05%?;Ungefähr 0,62.;Approximately 0.62.;0,62;0.62;Simple Retrieval;''
2015.jeptalnrecital-court.38.pdf-Figure4.png;Im linken Diagramm: Wie groß ist die Differenz zwischen dem höchsten und dem niedrigsten F-Score-Wert?;In the leftmost graph, what is the difference between the highest and lowest F-score values?;Ungefähr 0,25.;Approximately 0.25.;0,25;0.25;Simple Calculation;''
2015.jeptalnrecital-court.38.pdf-Figure4.png;Abbildung 4 zeigt die Auswirkungen von Delta auf die Anzahl der extrahierten Motive und den F-Score. Beschreiben Sie den Trend, der sich mit steigendem Delta abzeichnet, und wie wird dieser Zusammenhang im Text hinsichtlich der Informationsverdichtung erklärt?;Figure 4 shows the impact of delta on the number of extracted motifs and the F-score. Describe the trend observed with increasing delta, and how is this relationship explained in the text with regard to information condensation?;'Mit steigendem Delta nimmt die Anzahl der extrahierten Motive ab, während sich der F-Score im Allgemeinen verbessert. Höhere Delta-Werte führen dazu, dass mehr Motive in Äquivalenzklassen gruppiert werden, wodurch redundante ''Super-Motive'' eliminiert und die relevanten Informationen in den verbleibenden Motiven kondensiert werden, was zu einer effizienteren Darstellung für die Klassifizierung führt.';'As delta increases, the number of extracted motifs decreases, while the F-score generally improves. Higher delta values lead to more motifs grouped into equivalence classes, eliminating redundant ''super-motifs'' and condensing the relevant information into the remaining motifs, leading to a more efficient representation for classification.';'Weniger Motive, höherer F-Score';'Fewer motifs, higher F-score';Caption Question/Complex Calculation and Logical Reasoning;''
2019.jeptalnrecital-court.22.pdf-Figure2.png;Welche Bewertungskategorie hat den kleinsten Anteil im Kreisdiagramm?;Which evaluation category has the smallest portion in the pie chart?;Beschreibung mit 3%.;Description, with 3%. ;Beschreibung;Description;Simple Retrieval;''
2019.jeptalnrecital-court.22.pdf-Figure2.png;'Wie hoch ist die Summe der Prozentanteile von ''Intention'' und ''Suggestion''?';'What is the sum of the percentages of ''Intention'' and ''Suggestion''?';'Die Summe von ''Intention'' (4%) und ''Suggestion'' (6%) ist 10%.';'The sum of ''Intention'' (4%) and ''Suggestion'' (6%) is 10%.' ;10%;10%;Simple Calculation;''
2019.jeptalnrecital-court.22.pdf-Figure2.png;'Wenn die Gesamtzahl der annotierten Bewertungen 2943 beträgt, wie viele Bewertungen entfallen dann auf ''Beschreibung'', ''Intention'' und ''Suggestion'' zusammen?';'If the total number of annotated evaluations is 2943, how many evaluations are accounted for by ''Description'', ''Intention'', and ''Suggestion'' combined?';Ungefähr 383 Bewertungen (3% + 4% + 6% = 13% von 2943).;Approximately 383 evaluations (3% + 4% + 6% = 13% of 2943). ;383;383;Simple Calculation;''
2019.jeptalnrecital-court.22.pdf-Figure2.png;Wie viel Prozentpunkte mehr machen positive Meinungen im Vergleich zu negativen und gemischten Meinungen zusammen aus?;How many more percentage points do positive opinions account for compared to the sum of negative and mixed opinions?;Positive Meinungen (68%) machen 49 Prozentpunkte mehr aus als die Summe der negativen (12%) und gemischten (7%) Meinungen (19%).;Positive opinions (68%) account for 49 percentage points more than the sum of negative (12%) and mixed (7%) opinions (19%). ;49;49;Simple Calculation;''
2019.jeptalnrecital-court.22.pdf-Figure2.png;'Abbildung 2 stellt die Verteilung der Bewertungskategorien dar. Der Text erwähnt Strategien zum Umgang mit unausgewogenen Klassen. Wie spiegelt sich diese Unausgewogenheit visuell in der Abbildung wider, und welche im Text erwähnte Strategie adressiert direkt die beobachtete Unausgewogenheit in Bezug auf die ''Meinungs''-Kategorien?';'Figure 2 shows the distribution of evaluation categories. The text mentions strategies for handling class imbalance. How is this imbalance visually reflected in the figure, and which strategy mentioned in the text directly addresses the observed imbalance specifically concerning the ''opinion'' categories?';'Die Unausgewogenheit zeigt sich in dem dominanten Anteil ''Positive Meinungen'' (68%). Oversampling-Techniken (Random Over-Sampling, SMOTE, ADASYN) werden verwendet, um die Unausgewogenheit zu beheben, da Kategorien neben Meinungen unterrepräsentiert sind.';'The imbalance is shown by the dominant ''Opinion Positive'' slice (68%). Oversampling techniques (Random Over-Sampling, SMOTE, ADASYN) are used to address the imbalance, chosen because categories besides opinions were under-represented.' ;Oversampling;Oversampling;Requires Paper Context;"Si l’on observe la répartition de chaque catégorie (cf. Figure 2), les opinions positives représentent 68% de toutes les évaluations annotées, alors que les descriptions ou les intentions en font que 3% et 4%. Ainsi, la distribution des classes est fortement déséquilibrée. Dans la section 4.3, nous montrerons comment le problème de cette disproportion a été résolu.

FIGURE 2: La répartition des classes dans le corpus de référence

...

Afin de gérer le déséquilibre entre les 6 catégories annotées, nous avons adopté différentes stratégies que l’on peut rassembler en deux groupes principaux : les stratégies d’échantillonnage et les stratégies algorithmiques (cf. le Tableau 1). Les stratégies d’échantillonnage consistent à dupliquer les observations de la classe minoritaire (sur-échantillonnage) ou à enlever celles de la classe dominante (sous-échantillonnage). Nous avons choisi le sur-échantillonnage car la classe minoritaire est sous-représentée dans les données annotées. Trois techniques de suréchantillonnage disponibles dans Imbalanced-learn [6], (Lemaître et al. 2017) ont été utilisées : Random _Over-sampling, SMOTE et ADASYN."
2020.acl-main.174.pdf-Figure4.png;Welches Segment ist das größte im Kreisdiagramm?;Which segment is the largest in the pie chart?;Beweismittel;Evidence;Beweismittel;Evidence;Simple Retrieval;''
2020.acl-main.174.pdf-Figure4.png;'Wie groß ist der prozentuale Unterschied zwischen dem Segment ''Beweismittel'' und dem Segment ''Tatort''?';'What is the percentage point difference between the ''Evidence'' segment and the ''Crime Scene'' segment?';23,7%;23.7%;23,7%;23.7%;Simple Calculation;''
2020.acl-main.174.pdf-Figure4.png;Wie viel Prozent machen die drei kleinsten Segmente im Kreisdiagramm zusammen aus?;What percentage do the three smallest segments in the pie chart represent combined?;34,9%;34.9%;34,9%;34.9%;Complex Calculation and Logical Reasoning;''
2020.acl-main.174.pdf-Figure4.png;'Ist der kombinierte Prozentsatz von ''Opfer'', ''Täter'' und ''Todesursache'' größer oder kleiner als der Prozentsatz von ''Beweismittel''?';'Is the combined percentage of ''Victim'', ''Perpetrator'', and ''Cause of Death'' greater or smaller than the percentage of ''Evidence''?';Größer;Greater;Größer;Greater;Complex Calculation and Logical Reasoning;''
2020.acl-main.174.pdf-Figure4.png;'Warum nimmt der Aspekt ''Beweismittel'' im Durchschnitt einen größeren Anteil einer Zusammenfassung von CSI-Folgen ein als andere Aspekte wie ''Tatort'' oder ''Opfer''?';'Why does the ''Evidence'' aspect take up a larger portion of a CSI episode summary on average than other aspects like ''Crime Scene'' or ''Victim''?';'Der angegebene Text gibt an, dass ''Beweismittel'' einen größeren Anteil (36,1 %) der Zusammenfassung einnehmen als andere Aspekte, die typischerweise 10-15 % ausmachen. Der Text erklärt jedoch nicht die Gründe für diesen Unterschied.';'The provided text indicates that ''Evidence'' occupies a larger portion (36.1%) of the summary compared to other aspects, which typically account for 10-15%.  However, the text doesn't explain the reasons behind this difference.';Kein Grund angegeben;No reason given;Requires Paper Context;'As described in Section 4, we collected aspectbased summary labels for all episodes in the CSI corpus. In Figure 4 we illustrate the average composition of a summary based on the different aspects seen in a crime investigation (e.g., crime scene, victim, cause of death, perpetrator, evidence). Most of these aspects are covered in 10–15% of a summary, which corresponds to approximately two scenes in the episode. Only the “Evidence” aspect occupies a larger proportion of the summary (36.1%) corresponding to five scenes. However, there exist scenes which cover multiple aspects (an as a result are annotated with more than one label) and episodes that do not include any scenes related to a specific aspect (e.g., if the murder was a suicide, there is no perpetrator).'
2020.acl-main.284.pdf-Figure3.png;'Welche Farbe hat das Segment, das ''Pfad / URL'' darstellt?';'What color is the segment representing ''Path / URL''?';Hellviolett/Lavendel;Light purple/lavender;Hellviolett/Lavendel;Light purple/lavender;Caption Question/Simple Retrieval;''
2020.acl-main.284.pdf-Figure3.png;'Ist der Anteil von ''Befehl / Code'' größer als der Anteil von ''Dateiinhalt (kein Code)''?';'Is the segment for ''Command / Code'' larger than the segment for ''File Content (Not Code)''?';Nein;No;Nein;No;Caption Question/Simple Calculation;''
2020.acl-main.284.pdf-Figure3.png;'Welcher der beiden Segmente ''Befehlsausgabe / Infomeldung'' und ''Fehlermeldung / Stack-Trace'' ist größer?';'Which of the two segments, ''Command Output / Info Message'' and ''Error Message / Stack Trace'', is larger?';Befehlsausgabe / Infomeldung;Command Output / Info Message;Befehlsausgabe;Command Output;Caption Question/Simple Calculation;''
2020.acl-main.284.pdf-Figure3.png;Machen die drei kleinsten Segmente zusammen mehr als 10 % des Kreisdiagramms aus?;Do the three smallest segments combined represent more than 10% of the pie chart?;Ja;Yes;Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;''
2020.acl-main.284.pdf-Figure3.png;'Abbildung 3 zeigt die relativen Häufigkeiten jedes Tags im Datensatz. Abschnitt 4.3 erwähnt die Verwendung von kontextbezogenen Einbettungen aus mehreren Sprachmodellen, die mit verschiedenen Datenquellen vortrainiert wurden (englischer Text, Code-Schnipsel, Konfigurations-/Protokolldateien). In Anbetracht der relativen Häufigkeit von ''Dateiinhalt (kein Code)''-Tags in Abbildung 3, warum könnte das Vortrainieren auf Konfigurations-/Protokolldateien für diese Aufgabe von Vorteil sein?';'Figure 3 shows the relative frequencies of each tag in the dataset. Section 4.3 mentions the use of contextual embeddings from multiple language models pre-trained on different data sources (English text, code snippets, config/log files). Considering the relative frequency of ''File Content (Not Code)'' tags in Figure 3, why might pre-training on config/log files be beneficial for this task?';'Das Vortrainieren mit Konfigurations-/Protokolldateien ermöglicht es dem Modell, die spezifischen Muster und das Vokabular zu lernen, die in diesen Dateien üblich sind und auch in den ''Dateiinhalt (kein Code)''-Tags vorkommen. Dieses spezialisierte Vortraining sollte zu besseren Wortrepräsentationen und einer verbesserten Leistung im Vergleich zur Verwendung eines allgemeinen englischen Sprachmodells führen.';'Pre-training on config/log files allows the model to learn the specific patterns and vocabulary common in these files, which are also present in the ''File Content (Not Code)'' tags. This specialized pre-training should lead to better word representations and improved performance compared to using a general English language model.';Spezialisiertes Vortraining;Specialized pre-training;Requires Paper Context;"We also include contextual embeddings from the pre-trained bi-directional language model in ELMo (Peters et al., 2018). We observe that the non-natural language segments exhibit wide differences in syntactic and semantic structure, as is evident from Fig 1. We propose contextual embeddings from multiple language models; each trained on a different data source - English text, code snippets, config/log file contents. We hypothesize that combined embeddings from language models trained on separate data sources can capture word relationships better and can give richer word representations, as opposed to a single model trained on a large English corpora. For combining multiple contextual embeddings, we explore two techniques - (1) a naive concatenation, and (2) a weighted sum, with weights learned from context-independent DME (Dynamic Meta-Embeddings) and context-dependent CDME (Contextualised Dynamic Meta-Embeddings) selfattention mechanisms as proposed by Kiela et al. (2018)."
2020.cl-1.4.pdf-Figure1.png;Welcher Kategorie entspricht der größte Anteil im linken Kreisdiagramm?;Which category represents the largest portion in the left pie chart?;'''Nicht einfacher'', mit 34%.';'Not simpler', with 34%.;Nicht einfacher;Not simpler;Simple Retrieval;''
2020.cl-1.4.pdf-Figure1.png;'Wie viel Prozent größer ist der Anteil von ''Deletion only'' im linken Kreisdiagramm im Vergleich zu ''Paraphrase only''?';'How much larger in percentage is the portion of ''Deletion only'' in the left pie chart compared to ''Paraphrase only''?';18%;18%;18;18;Simple Calculation;''
2020.cl-1.4.pdf-Figure1.png;'Wie viel Prozent des linken Kreisdiagramms machen ''Deletion only'', ''Paraphrase only'' und ''Not simpler'' zusammen aus?';'What combined percentage of the left pie chart do ''Deletion only'', ''Paraphrase only'', and ''Not simpler'' represent?';76%;76%;76;76;Simple Calculation;''
2020.cl-1.4.pdf-Figure1.png;'Ist die Summe der Prozentsätze von ''Deletion + Paraphrase'' und ''Paraphrase only'' im rechten Kreisdiagramm größer oder kleiner als der Prozentsatz von ''Not simpler'' im linken Kreisdiagramm?';'Is the sum of the percentages of ''Deletion + Paraphrase'' and ''Paraphrase only'' in the right pie chart greater or smaller than the percentage of ''Not simpler'' in the left pie chart?';Größer. 86% ist größer als 34%.;Greater. 86% is greater than 34%. ;Größer;Greater;Simple Calculation;''
2020.cl-1.4.pdf-Figure1.png;In Abbildung 1 wird die manuelle Kategorisierung von Vereinfachungstransformationen in Beispielsätzen aus zwei vereinfachten Versionen des Newsela-Korpus dargestellt. Welche Vereinfachungstransformationen zeigen die Diagramme, und welche Schlussfolgerungen ziehen Xu, Callison-Burch und Napoles (2015) daraus?;Figure 1 shows the manual categorization of simplification transformations in sample sentences from two simplified versions of the Newsela corpus. What simplification transformations do the charts depict, and what conclusions do Xu, Callison-Burch, and Napoles (2015) draw from them?;'Die Diagramme zeigen Transformationen wie ''Deletion only'', ''Paraphrase only'', ''Deletion + Paraphrase'', ''Splitting'' und ''Not aligned/Not simpler''.  Xu, Callison-Burch und Napoles (2015) schlussfolgern, dass zwar immer noch eine Präferenz für Kompression und lexikalische Substitution (Deletion und Paraphrase) besteht, aber ''Splitting'' in frühen Vereinfachungsversionen (Simp-2) auftritt. Sie stellen außerdem eine insgesamt bessere Präsenz und Verteilung von Vereinfachungstransformationen im Newsela-Korpus im Vergleich zu Wikipedia-basierten Korpora fest.';The charts depict transformations such as deletion only, paraphrase only, deletion + paraphrase, splitting, and not aligned/not simpler.  Xu, Callison-Burch, and Napoles (2015) conclude that while there's still a preference for compression and lexical substitution (deletion and paraphrase), splitting emerges in early simplification versions (Simp-2). They also note a better overall presence and distribution of simplification transformations in the Newsela corpus compared to Wikipedia-based corpora.;Deletion, Paraphrase, Splitting, Not aligned/simpler;Deletion, Paraphrase, Splitting, Not aligned/simpler;Caption Question/Complex Calculation and Logical Reasoning;''
2020.figlang-1.23.Dataset.pdf-Figure4.png;Welche Beschriftung befindet sich neben dem zweitgrößten orangen Segment?;What label is next to the second largest orange segment?;Medizin;Medicine;Medizin;Medicine;Simple Retrieval;''
2020.figlang-1.23.Dataset.pdf-Figure4.png;'Ist das Segment ''Körper aus Wasser'' größer oder kleiner als das Segment ''Bewegung''?';'Is the ''Body of Water'' segment larger or smaller than the ''Movement'' segment?';Kleiner;Smaller;Kleiner;Smaller;Simple Calculation;''
2020.figlang-1.23.Dataset.pdf-Figure4.png;'Wie viele Segmente sind kleiner als das Segment ''Krieg''?';'How many segments are smaller than the ''War'' segment?';14;14;14;14;Complex Calculation and Logical Reasoning;''
2020.figlang-1.23.Dataset.pdf-Figure4.png;'Wenn man die Größe der Segmente ''Medizin'', ''Krieg'' und ''Unfall'' zusammenzählt, ist die kombinierte Größe größer oder kleiner als das Segment ''Physischer Standort''?';'If you combine the size of the ''Medicine'', ''War'', and ''Accident'' segments, is the combined size larger or smaller than the segment ''Physical Location''?';Größer;Larger;Größer;Larger;Complex Calculation and Logical Reasoning;''
2020.figlang-1.23.Dataset.pdf-Figure4.png;Laut dem Artikel machen traditionelle Standpunkte etwa 10% der extrahierten Metaphern aus. Abbildung 4 zeigt die Metaphernverteilung innerhalb der moderaten Standpunkte. Welche Hypothese könnten Sie aufstellen, warum der traditionelle Standpunkt im Vergleich zum moderaten Standpunkt im Gesamtbild unterrepräsentiert ist, wenn man die potenziellen Unterschiede in der Online-Präsenz oder im Engagement zwischen diesen Gruppen berücksichtigt?;According to the paper, traditional stance sources account for approximately 10% of the extracted metaphors. Figure 4 depicts the moderate stance metaphor distribution. Can you hypothesize why the traditional stance might have a lower representation in the overall metaphor count compared to the moderate stance, considering the potential differences in online presence or engagement between these groups?;Traditionelle Standpunkte könnten eine geringere Online-Präsenz und ein geringeres Engagement im Vergleich zu moderaten Standpunkten aufweisen, was dazu führt, dass weniger Fälle von metaphorischer Sprache in den Daten erfasst werden.;Traditional stances may have lower online presence and engagement compared to moderate stances, leading to fewer instances of metaphorical language being captured in the data.;Geringere Online-Präsenz;Lower online presence;Requires Paper Context;"Figure 4. Distribution of marriage equality metaphors in the moderate stance sources.
...
We note that sources representing traditional views account for only about 10% of extracted metaphors."
2020.finnlp-1.7.pdf-Figure4.png;Welches Segment stellt den größten Anteil im Kreisdiagramm dar?;Which segment represents the largest portion in the pie chart?;EBITDA;EBITDA;EBITDA;EBITDA;Simple Retrieval;''
2020.finnlp-1.7.pdf-Figure4.png;'Wie hoch ist der prozentuale Unterschied zwischen den Segmenten ''Free Cash Flow'' und ''EBIT''?';'What is the percentage difference between the ''Free Cash Flow'' and ''EBIT'' segments?';15%;15%;15%;15%;Simple Calculation;''
2020.finnlp-1.7.pdf-Figure4.png;'Welcher Prozentsatz wird durch die Kombination von ''Free Cash Flow'', ''EBITDA'' und ''EBIT'' dargestellt?';'What percentage is represented by the combination of ''Free Cash Flow'', ''EBITDA'', and ''EBIT''?';68%;68%;68%;68%;Simple Calculation;''
2020.finnlp-1.7.pdf-Figure4.png;'Ist die Summe der Prozentwerte aller Segmente, die mit ''E'' beginnen, größer oder kleiner als die Summe der Prozentwerte der restlichen Segmente?';'Is the sum of the percentages of all segments starting with ''E'' greater or less than the sum of the percentages of the remaining segments?';Kleiner als;Less than;Kleiner;Less;Simple Calculation;''
2020.finnlp-1.7.pdf-Figure4.png;Der Text erwähnt, dass die Nutzung von Nicht-GAAP-Kennzahlen zunimmt, sich aber die Verteilung ändert. Unter Berücksichtigung des in Abbildung 4 dargestellten Trends für das erste Halbjahr und der Aussage im Text, dass die EBIT-Nutzung im zweiten Halbjahr um 8% gestiegen ist, wie hoch wäre der ungefähre Gesamtanteil von EBIT in der Mitte der Experimente?;The text mentions that the use of non-GAAP measures is growing, but the distribution is changing. Considering the trend shown in Figure 4 for the first half of the experiments and the text stating that EBIT usage grew by 8% in the second half, what would be the approximate total percentage of EBIT at the midpoint of the experiments?;19%;19%;19%;19%;Requires Paper Context;'Over time, however, we see that the use of non-GAAP measures is growing, but the distribution is changing. When we compare the midway results with the overall results (Figure 5), we find that while Earnings before Interest, Tax, Decpreciation and Amortization (EBITDA), Earnings before Iterest and Tax (EBIT), and Free Cash Flow (FCF) are still the three main non-GAAP measures used, the percentages for EBITDA and Free Cash Flow have decreased by 6% and 4% respectively, while EBIT has grown by 8%, seen in Figure 5, below.'
2020.finnlp-1.7.pdf-Figure5.png;Welches Segment des Kreisdiagramms ist mit ''Free Cash Flow'' beschriftet?;Which segment of the pie chart is labeled ''Free Cash Flow''?;Das orange Segment mit 22%.;The orange segment with 22%.;Orange;Orange;Simple Retrieval;''
2020.finnlp-1.7.pdf-Figure5.png;Was ist die Summe der Prozentsätze von ''EBITDA'' und ''EBIT''?;What is the sum of the percentages of ''EBITDA'' and ''EBIT''?;25% + 19% = 44%;25% + 19% = 44%;44%;44%;Simple Calculation;''
2020.finnlp-1.7.pdf-Figure5.png;Ist der kombinierte Prozentsatz von ''Adjusted EPS'' und ''EBITDAR'' größer oder kleiner als der Prozentsatz von ''Unbilled''?;Is the combined percentage of ''Adjusted EPS'' and ''EBITDAR'' greater or less than the percentage of ''Unbilled''?;Größer als. Adjusted EPS (2%) + EBITDAR (3%) = 5%, was größer als Unbilled (3%) ist.;Greater than. Adjusted EPS (2%) + EBITDAR (3%) = 5%, which is greater than Unbilled (3%).;Größer;Greater;Simple Calculation;''
2020.finnlp-1.7.pdf-Figure5.png;Welches Nicht-GAAP-Maß macht weniger als 5% des Kreisdiagramms aus?;Which non-GAAP measure accounts for less than 5% of the pie chart?;ROCE (2%), Core Earnings (1%), Unbilled (3%), Adjusted EPS (2%) und EBITDAR (3%).;ROCE (2%), Core Earnings (1%), Unbilled (3%), Adjusted EPS (2%), and EBITDAR (3%).;ROCE, Core Earnings, Unbilled, Adjusted EPS, EBITDAR;ROCE, Core Earnings, Unbilled, Adjusted EPS, EBITDAR;Complex Calculation and Logical Reasoning;''
2020.finnlp-1.7.pdf-Figure5.png;Der Text erwähnt eine Veränderung in der Verwendung von Free Cash Flow im Vergleich zu Abbildung 4. Welche Aussage trifft zu: A) Die Verwendung von Free Cash Flow ist gestiegen, B) Die Verwendung von Free Cash Flow ist gesunken, C) Die Verwendung von Free Cash Flow ist gleich geblieben?;The text mentions a change in the use of Free Cash Flow compared to Figure 4. Which statement is true: A) The use of Free Cash Flow increased, B) The use of Free Cash Flow decreased, C) The use of Free Cash Flow stayed the same?;B) Die Verwendung von Free Cash Flow ist gesunken.;B) The use of Free Cash Flow decreased.;Gesunken;Decreased;Requires Paper Context;'Over time, however, we see that the use of non-GAAP measures is growing, but the distribution is changing. When we compare the midway results with the overall results (Figure 5), we find that while Earnings before Interest, Tax, Decpreciation and Amortization (EBITDA), Earnings before Iterest and Tax (EBIT), and Free Cash Flow (FCF) are still the three main non-GAAP measures used, the percentages for EBITDA and Free Cash Flow have decreased by 6% and 4% respectively, while EBIT has grown by 8%, seen in Figure 5, below.'
2020.jeptalnrecital-taln.24.pdf-Figure1.png;Welcher Kategorie entspricht der kleinste Abschnitt im Kreisdiagramm?;Which category corresponds to the smallest segment in the pie chart?;BESCHREIBUNG;DESCRIPTION;BESCHREIBUNG;DESCRIPTION;Simple Retrieval;''
2020.jeptalnrecital-taln.24.pdf-Figure1.png;Wie hoch ist der Prozentsatz von NEG_OPINION im Kreisdiagramm?;What is the percentage of NEG_OPINION in the pie chart?;9,7%;9.7%;9,7%;9.7%;Simple Retrieval;''
2020.jeptalnrecital-taln.24.pdf-Figure1.png;Wie hoch ist der kombinierte Prozentsatz von POS_OPINION, NEG_OPINION und MIX_OPINION?;What is the combined percentage of POS_OPINION, NEG_OPINION, and MIX_OPINION?;84,5%;84.5%;84,5%;84.5%;Simple Calculation;''
2020.jeptalnrecital-taln.24.pdf-Figure1.png;Welche Kategorien machen zusammen etwa 20% der gesamten Antworten aus?;Which categories together make up approximately 20% of the total responses?;SUGGESTION (8,8%), NEG_OPINION (9,7%) und DESCRIPTION (1,8%), die zusammen 20,3% ergeben, was ungefähr 20% entspricht.;SUGGESTION (8.8%), NEG_OPINION (9.7%), and DESCRIPTION (1.8%) which together represent 20.3%, approximately 20%. ;20,3%;20.3%;Complex Calculation and Logical Reasoning;''
2020.jeptalnrecital-taln.24.pdf-Figure1.png;Inwiefern spiegelt die in Abbildung 1 dargestellte Verteilung angesichts der Priorisierung von SUGGESTION und INTENTION während der Annotation eine potenzielle Verzerrung gegenüber diesen Kategorien wider, und wie könnte sich diese Verzerrung auf die Schlussfolgerungen der Studie hinsichtlich der Prävalenz verschiedener Sentimenttypen in Restaurantbewertungen auswirken?;Given the prioritization of SUGGESTION and INTENTION categories during annotation, how does the distribution visualized in Figure 1 potentially reflect a bias towards these categories, and how might this bias affect the conclusions drawn from the study regarding the prevalence of different sentiment types in restaurant reviews?;Die Priorisierung von SUGGESTION und INTENTION während der Annotation könnte ihre Repräsentation im Datensatz erhöhen, was möglicherweise zu einer Überschätzung ihrer Prävalenz und einer Unterschätzung anderer Kategorien wie POS_OPINION oder NEG_OPINION führt. Diese Verzerrung könnte die Schlussfolgerungen der Studie hinsichtlich der Verteilung von Stimmungstypen in Restaurantbewertungen verfälschen.;The prioritization of SUGGESTION and INTENTION during annotation could inflate their representation in the dataset, potentially leading to an overestimation of their prevalence and an underestimation of other categories like POS_OPINION or NEG_OPINION. This bias could skew the study's conclusions regarding the distribution of sentiment types in restaurant reviews.;Überschätzung SUGGESTION/INTENTION;Overestimation SUGGESTION/INTENTION;Caption Question/Complex Calculation and Logical Reasoning;'Annotation. Chaque phrase a été annotée selon l’une des six catégories : POS_OPINION, NEG_OPINION, MIX_OPINION, SUGGESTION, INTENTION et DESCRIPTION. Dans les cas d’ambiguïté où plusieurs catégories sont possibles, SUGGESTION ou INTENTION ont été privilé- giées car celles-ci sont peu représentées dans les données. La phrase « Toujours aussi excellent, nous y retournerons c’est certain » par exemple, peut être classée dans les deux catégories POS_OPINION et INTENTION. Nous l’avons cependant annotée comme INTENTION.'
2020.lrec-1.141.pdf-Figure4.png;Welches ist das zweitgrößte Segment im Kreisdiagramm?;Which is the second largest segment in the pie chart?;'Das ''who''-Segment.';'The ''who'' segment.';who;who;Simple Retrieval;''
2020.lrec-1.141.pdf-Figure4.png;'Wie groß ist der prozentuale Unterschied zwischen dem ''what''- und dem ''how''-Segment (geschätzt)?';'What is the approximate percentage difference between the ''what'' and ''how'' segments?';'Das ''what''-Segment scheint etwa 15-20% größer zu sein als das ''how''-Segment.';'The ''what'' segment appears to be roughly 15-20% larger than the ''how'' segment.';15-20%;15-20%;Simple Calculation;''
2020.lrec-1.141.pdf-Figure4.png;'Wenn man die Segmente ''other'', ''why'', ''where'', ''who'' und ''when'' kombiniert, welchen Anteil (geschätzt) nehmen sie am gesamten Kreisdiagramm ein?';'If you combine the ''other'', ''why'', ''where'', ''who'', and ''when'' segments, approximately what percentage of the entire pie chart do they represent?';Diese Segmente zusammen scheinen etwa 25-30 % des Kreisdiagramms auszumachen.;These segments combined appear to represent approximately 25-30% of the pie chart.;25-30%;25-30%;Complex Calculation and Logical Reasoning;''
2020.lrec-1.141.pdf-Figure4.png;'Ist die Summe der Prozentsätze der vier kleinsten Segmente größer oder kleiner als der Prozentsatz des ''how''-Segments?';'Is the sum of the percentages of the four smallest segments greater or less than the percentage of the ''how'' segment?';'Kleiner. Das ''how''-Segment ist größer als die vier kleinsten zusammen.';'Less than. The ''how'' segment is larger than the four smallest combined.';Kleiner;Less than;Complex Calculation and Logical Reasoning;''
2020.lrec-1.141.pdf-Figure4.png;'Im Text wird erwähnt, dass ''where''- und ''who''-Fragen oft Meta-/Klärungsfragen sind. Erscheint die relative Größe der ''where''- und ''who''-Segmente in Abbildung 4 proportional im Vergleich zu anderen Fragetypen, angesichts ihrer Klassifizierung als weniger wichtig für die Hauptpunkte des Sprechers? Begründen Sie Ihre Antwort anhand von Belegen aus der Abbildung und dem bereitgestellten Textauszug.';'The text mentions that ''where'' and ''who'' questions are often meta/clarification questions. Considering the relative size of the ''where'' and ''who'' segments in Figure 4, do these question types appear proportionally represented compared to other question types, given their classification as less crucial for the speaker's main points? Justify your answer using evidence from both the figure and the provided text excerpt.';'Die ''where''- und ''who''-Segmente sind die kleinsten, was die Behauptung des Textes widerspiegelt, dass sie weniger wichtig sind. Ihre geringere Größe deutet auf eine geringere Häufigkeit hin und unterstützt die Behauptung des Textes.';'The ''where'' and ''who'' segments are the smallest, reflecting the text's assertion that they are less crucial.  Their smaller size indicates lower frequency and supports the text's claim.';Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;'Where/who-questions are often meta/clarification questions (e.g., Who are they talking about? Where are they?).'
2020.lrec-1.203.pdf-Figure3.png;Welche Emotion wird durch den größten Abschnitt des Kreisdiagramms dargestellt?;Which emotion is represented by the largest segment of the pie chart?;Wut;Anger;Wut;Anger;Simple Retrieval;''
2020.lrec-1.203.pdf-Figure3.png;Wie viel mal größer ist der Prozentanteil von Wut im Vergleich zu Überraschung?;How many times larger is the percentage of anger compared to surprise?;Ungefähr 7,4-mal;Approximately 7.4 times;7,4;7.4;Simple Calculation;''
2020.lrec-1.203.pdf-Figure3.png;Wenn man die Segmente für Überraschung, Traurigkeit und Angst kombinieren würde, wären sie zusammen größer oder kleiner als das Segment für Glück? Begründen Sie Ihre Antwort anhand der visuellen Darstellung des Diagramms.;If you combined the surprise, sadness, and fear segments, would they together be larger or smaller than the happiness segment? Justify your answer based on the visual representation of the chart.;Größer. Der kombinierte Prozentsatz von Überraschung, Traurigkeit und Angst (21,1%) ist größer als der von Glück (2,5%).;Larger. The combined percentage of surprise, sadness, and fear (21.1%) is greater than happiness (2.5%).;Größer;Larger;Complex Calculation and Logical Reasoning;''
2020.lrec-1.203.pdf-Figure3.png;Wie viel Prozent der im Kreisdiagramm dargestellten Emotionen machen Wut, Traurigkeit und Angst zusammen aus?;What percentage of the total emotions represented in the pie chart do anger, sadness, and fear comprise?;87,2%;87.2%;87,2%;87.2%;Simple Calculation;''
2020.lrec-1.203.pdf-Figure3.png;Abbildung 4 im Artikel zeigt die Verteilung rhetorischer Fragen pro Emotion in allen Beiträgen. Stimmt die Aussage in Abbildung 4 mit der Darstellung in Abbildung 3 überein, dass Wut die häufigste Emotion ist, die durch rhetorische Fragen ausgedrückt wird? Begründen Sie Ihre Antwort durch Bezugnahme auf beide Abbildungen und den dazugehörigen Text.;Figure 4 in the paper shows the distribution of rhetorical questions per emotion across all posts. Does the statement in Figure 4 align with the representation in Figure 3 that anger is the most common emotion expressed through rhetorical questions?  Justify your answer by referring to both figures and the relevant text.;Nein. Abbildung 3 zeigt, dass Wut 76,4% der rhetorischen Fragen zu Emotionen ausmacht und damit am häufigsten vorkommt. Abbildung 4 hingegen zeigt den Anteil der rhetorischen Fragen *im Verhältnis zur Gesamtzahl der Beiträge pro Emotion*, wobei Überraschung (41,1%) einen höheren Anteil hat als Wut (37,3%). Der Text verdeutlicht diesen entscheidenden Unterschied.;No. Figure 3 shows anger represents 76.4% of rhetorical questions regarding emotions, making it the most prevalent. Figure 4, however, shows the proportion of rhetorical questions *relative to the total posts per emotion*, where surprise (41.1%) has a higher proportion than anger (37.3%). The text clarifies this crucial distinction.;Nein;No;Requires Paper Context;"Previous work suggests that rhetorical questions are a rather productive means of expressing or evoking emotions, in particular the negative ones (Roberts and Kreuz 1994; Gibbs et al. 2002; Lee 2017, Lau and Lee 2018). This claim is also supported by our corpus data as in Figure 3.

[...]

One may doubt whether the strongest connection between rhetorical questions and _anger is due to the large number of comments containing_ _anger. In order to support the claim that rhetorical_ questions do have a tendency towards negative emotions Figure 4 illustrates the distribution of rhetorical question per emotion in all post.

[...]

Figure 4 is calculated relative to the total number of comments of a given emotion type. It illustrates that rhetorical questions are rather productive in expressing emotions. Among all the five emotions, the surprise emotion has the greatest tendency (41.1%) to be expressed through rhetorical questions, followed by anger (37.3%), fear (15.7%), sadness (11.9%), and happiness (3.7%). Different from the claim proposed in previous studies that rhetorical questions are most frequently used to express negative emotions, statistics illustrate that rhetorical questions are even more tightly associated with the neutral emotion, surprise (41.1%). Therefore, rhetorical questions are not only particularly productive in evoking negative emotions such as anger and fear, but also in evoking the neutral emotion surprise."
2020.lrec-1.260.pdf-Figure2.png;Welche Produktkategorie hat den größten Anteil am Kreisdiagramm?;Which product category occupies the largest area in the pie chart?;PC;PC;PC;PC;Simple Retrieval;''
2020.lrec-1.260.pdf-Figure2.png;Wie groß ist der numerische Unterschied zwischen den Werten für 'PC' und 'Telefon'?;What is the numerical difference between the values for 'PC' and 'Phone'?;672;672;672;672;Simple Calculation;''
2020.lrec-1.260.pdf-Figure2.png;Wie hoch ist die Summe der drei kleinsten Zahlenwerte im Kreisdiagramm?;What is the sum of the three smallest numerical values in the pie chart?;4186 (Mediaplayer: 2343, Haushaltsgerät: 1333, Haushalt: 1710);4186 (Media Player: 2343, Appliance: 1333, Household: 1710);4186;4186;Complex Calculation and Logical Reasoning;''
2020.lrec-1.260.pdf-Figure2.png;Ist die Summe der Werte für 'Mac' und 'Tablet' größer als der Wert für 'Kamera'?;Is the sum of the values for 'Mac' and 'Tablet' greater than the value for 'Camera'?;Ja, 2868 + 2756 = 5624, was größer als 2761 ist.;Yes, 2868 + 2756 = 5624, which is greater than 2761.;Ja;Yes;Simple Calculation;''
2020.lrec-1.260.pdf-Figure2.png;Wie viele Reparaturanleitungen gibt es für Mac Laptops, und wie verhält sich diese Zahl anteilig zur Gesamtzahl der gesammelten Anleitungen (unter Verwendung der im Text angegebenen Gesamtzahl und der Information, dass alle Anleitungen für Mac Laptops in der Kategorie 'Mac' enthalten sind)?;How many repair manuals are there for Mac Laptops, and what is this number as a proportion of the total manuals collected (using the total provided in the text, and the information that all Mac Laptop manuals are within the 'Mac' category)?;Es gibt 1497 Anleitungen für Mac Laptops. Dies entspricht (1497/31601) * 100 = etwa 4,7% der gesamten gesammelten Anleitungen.;There are 1497 manuals for Mac Laptops.  This represents (1497/31601) * 100 = approximately 4.7% of the total manuals collected.;4.7%;4.7%;Caption Question/Simple Calculation;'In total, 31,601 repair manuals were collected from the iFixit API in 15 basic categories, see Figure 2 . There is a high variation in the number of steps (average=9.68, me-dian=7.00, variance ='
2020.lrec-1.409.pdf-Figure1.png;Welche Textart hat den kleinsten Anteil im Kreisdiagramm?;Which text type has the smallest slice in the pie chart?;Sonstige, mit 0,3 %.;Other, representing 0.3%.;Sonstige;Other;Simple Retrieval;''
2020.lrec-1.409.pdf-Figure1.png;Wie hoch ist der kombinierte Prozentsatz von Zeitungen und Zeitschriften?;What is the combined percentage of Newspapers and Magazines?;Zeitungen machen 47,8 % und Zeitschriften 16,5 % aus, was insgesamt 64,3 % entspricht.;Newspapers represent 47.8% and Magazines 16.5%, totaling 64.3%.;64,3%;64.3%;Simple Calculation;''
2020.lrec-1.409.pdf-Figure1.png;Ist der Prozentsatzanteil von Internet größer als der kombinierte Prozentsatzanteil von Belletristik und Sachbüchern?;Is the percentage of Internet texts greater than the combined percentage of Fiction and Non-Fiction texts?;Ja. Internet-Texte machen 28 % aus, während Belletristik (3,5 %) und Sachbücher (3,8 %) zusammen 7,3 % ausmachen.;Yes. Internet texts represent 28%, while Fiction (3.5%) and Non-Fiction (3.8%) combined represent 7.3%.;Ja;Yes;Simple Calculation;''
2020.lrec-1.409.pdf-Figure1.png;Um wie viel Prozent ist der Anteil des Zeitungssegments größer als der Anteil des Zeitschriftensegments?;By what percentage is the Newspaper slice larger than the Magazine slice?;Das Zeitungssegment (47,8 %) ist 31,3 Prozentpunkte größer als das Zeitschriftensegment (16,5 %). Dies entspricht einer Steigerung von etwa 190 %.;The Newspaper slice (47.8%) is 31.3 percentage points larger than the Magazine slice (16.5%). This represents an increase of approximately 190%.;190%;190%;Simple Calculation;''
2020.lrec-1.409.pdf-Figure1.png;Angesichts der Zunahme des Anteils von Internettexten in Gigafida 2.0 (wie in Abbildung 1 und Tabelle 1 dargestellt), welche potenziellen Verzerrungen oder Herausforderungen könnte dies für die linguistische Forschung mit dem Korpus mit sich bringen? Berücksichtigen Sie die Diskussionen im Artikel über Datenquellen und die Zusammensetzung des Korpus.;Given the increase in internet text proportion in Gigafida 2.0 (as shown in Figure 1 and Table 1), what potential biases or challenges might this introduce when using the corpus for linguistic research? Consider the discussions in the paper about data sources and corpus composition.;Der erhöhte Anteil an Internettexten, die aus dem IJS Newsfeed stammen, könnte Online-Nachrichtenartikel überrepräsentieren und andere Formen der Online-Kommunikation unterrepräsentieren. Dies könnte den Korpus in Richtung informeller Sprache verzerren und Merkmale, die in Online-Nachrichten häufig vorkommen, überrepräsentieren, was zu Verzerrungen in der Sprachforschung führen kann. Es beeinflusst auch das Gleichgewicht zwischen formeller und informeller Sprache im Korpus.;The increased proportion of internet texts, sourced from IJS Newsfeed, might overrepresent online news articles and underrepresent other online communication forms.  This could skew the corpus towards informal language and overrepresent features common in online news, potentially creating biases in linguistic research.  It also affects the balance between formal and informal language in the corpus.;Verzerrung durch Online-Nachrichten;Bias from online news;Requires Paper Context;"As seen in Table 1 and Figure 1, Gigafida 2.0 is mainly comprised of newspapers (amost half of all words), online texts (about one quarter), and periodicals (one sixth), with


smaller percentages coming from non-fiction, fiction, and other genres, with the percentages comparable to those of Gigafida 1.0. The greatest discrepancy occurs with online texts, with Gigafida 2.0 containing about 12% more. The new version has fewer newspaper texts (a decrease of 8%) and periodicals (a decrease of 5%) and a slightly larger proportion of fiction (an increase of 1.5%). However, it should be mentioned that online texts also include news: in the previous version, these were only included in the Newspapers category. In Gigafida 2.0, they were obtained in digital form through the IJS Newsfeed (see Section 2.3), and were thus categorised as online texts. The actual differences in the distribution of genres between the two versions are thus smaller than suggested by the percentages."
2020.lrec-1.51.pdf-Figure6.png;Welches Segment ist gelb?;Which segment is yellow?;'Das Segment ''Capable'' ist gelb.';'The ''Capable'' segment is yellow.';Capable;Capable;Simple Retrieval;''
2020.lrec-1.51.pdf-Figure6.png;'Was ist der prozentuale Unterschied zwischen dem ''Easy to use''- und dem ''Quick''-Segment?';'What is the percentage difference between the ''Easy to use'' and ''Quick'' segments?';'Der Unterschied zwischen ''Easy to use'' und ''Quick'' beträgt 21,7%.';'The difference between ''Easy to use'' and ''Quick'' is 21.7%.';21,7%;21.7%;Simple Calculation;''
2020.lrec-1.51.pdf-Figure6.png;Welche drei Segmente machen zusammen mehr als 75 % des Kreisdiagramms aus?;Which three segments combine to represent more than 75% of the pie chart?;'''Capable'' (51,8%), ''Easy to use'' (25,3%) und ''Experience'' (10,8%) ergeben zusammen 87,9%.';Capable (51.8%), Easy to use (25.3%), and Experience (10.8%) combine to 87.9%.;'Capable, Easy to use, Experience';Capable, Easy to use, Experience;Complex Calculation and Logical Reasoning;''
2020.lrec-1.51.pdf-Figure6.png;'Ist die Summe der Prozentsätze von ''Other'' und ''Experience'' größer als der Prozentsatz von ''Easy to use''?';'Is the sum of the percentages of ''Other'' and ''Experience'' greater than the percentage of ''Easy to use''?';'Nein, ''Other'' (8,4%) + ''Experience'' (10,8%) = 19,2%, was weniger ist als ''Easy to use'' (25,3%).';'No, ''Other'' (8.4%) + ''Experience'' (10.8%) = 19.2%, which is less than ''Easy to use'' (25.3%).';Nein;No;Simple Calculation;''
2020.lrec-1.51.pdf-Figure6.png;Der Text erwähnt, dass die Benutzer mindestens zwei Bearbeitungen durchführen sollten. Die beiden größten Kategorien im Kreisdiagramm geben die häufigsten Gründe an, warum Benutzer das System mochten. Wie hoch ist der Prozentsatz der Benutzer, die mehr als die geforderten zwei Bearbeitungen durchgeführt haben, und wie lässt sich diese Zahl mit der Benutzerzufriedenheit in Bezug auf die Erfüllung der Anforderung von zwei Bearbeitungen in Verbindung bringen?;The text mentions users were asked to perform at least two edits. The two largest categories in the pie chart represent the two most common reasons users liked the system. What percentage of users performed more than the required two edits, and how does this relate to user satisfaction in meeting the two-edit requirement?;'30,1 % der Benutzer führten mehr als zwei Bearbeitungen durch. Dies deutet auf Zufriedenheit hin, die wahrscheinlich mit ''Capable'' und ''Easy to use'' korreliert.';'30.1% of users performed more than two edits. This suggests satisfaction, likely correlating with ''Capable'' and ''Easy to use''.';30,1%;30.1%;Caption Question/Complex Calculation and Logical Reasoning;"**Instructions** We introduced our system as “an image editing chatbot that is able to detect objects in the image and adjust several image attributes”. We asked users to perform at least 2 edits and interact with our system for at least 10 turns. There were no restrictions on what to edit. To limit overall dialogue length, users could end the dialogue at 30 turns. Upon task completion, we asked users to rate overall system performance, plus 3 specific system features. We then asked users to provide feedback on what they liked, disliked and what improvements would make the system better.

### 6.2. Results **Edits** We assess our system by the number of edits users can complete in each dialogue. All 83 users completed the required 2 edits, with 5 users exceeded 30 turns. 25 users (30.1%) performed 3 or more edits, with the maximum observed being 5. This implies that our system is usable, and"
2020.lrec-1.657.pdf-Figure1.png;Welcher Silbentyp kommt in der vorgelesenen Geschichte am häufigsten vor?;Which syllable type has the largest percentage in the read story?;CV hat mit 61,20 % den größten Anteil.;CV has the largest percentage with 61.20%.;CV;CV;Simple Retrieval;''
2020.lrec-1.657.pdf-Figure1.png;Wie groß ist der prozentuale Unterschied zwischen CVC und CVV in der vorgelesenen Geschichte?;What is the percentage difference between CVC and CVV in the read story?;Der Unterschied beträgt 26,33 %.;The difference is 26.33%.;26,33%;26.33%;Simple Calculation;''
2020.lrec-1.657.pdf-Figure1.png;Wie viel Prozent der Silben in der vorgelesenen Geschichte sind nicht CV?;What percentage of syllables in the read story are not CV?;38,8 % der Silben sind nicht CV.;38.8% of the syllables are not CV.;38,8%;38.8%;Simple Calculation;''
2020.lrec-1.657.pdf-Figure1.png;Ist der kombinierte Anteil von CVVC und CVCC größer oder kleiner als der Anteil von CVV?;Is the combined percentage of CVVC and CVCC greater or less than the percentage of CVV?;Der kombinierte Anteil von CVVC und CVCC (5,68 %) ist größer als der Anteil von CVV (3,37 %).;The combined percentage of CVVC and CVCC (5.68%) is greater than the percentage of CVV (3.37%).;Größer;Greater;Simple Calculation;''
2020.lrec-1.657.pdf-Figure1.png;Der Text enthielt 178 Silben und wurde von 10 Sprechern gelesen. Wie lange hat es durchschnittlich gedauert, bis ein Sprecher den Text gelesen hat?;The passage contained 178 syllables and was read by 10 speakers.  How long did it take on average for one speaker to read the passage?;Es dauerte ungefähr 4 Minuten für jeden Sprecher, den Text zu lesen.;It took roughly 4 minutes for each speaker to read the passage.;4 Minuten;4 minutes;Requires Paper Context;'The passage was subdivided roughly into 8 sentences with 178 phonological syllables. The total duration of utterances was around 4 minutes per speaker.'
2020.lrec-1.678.pdf-Figure3.png;Welche Farbe hat den größten Anteil im Kreisdiagramm (a)?;Which color represents the largest segment in the pie chart (a)?;Rosa;Pink;Rosa;Pink;Simple Retrieval;''
2020.lrec-1.678.pdf-Figure3.png;'Um wie viel Prozent ist der ''Who''-Abschnitt im Kreisdiagramm (a) größer als der ''What''-Abschnitt?';'By what percentage is the ''Who'' segment larger than the ''What'' segment in pie chart (a)?';5%;5%;5%;5%;Simple Calculation;''
2020.lrec-1.678.pdf-Figure3.png;Was ist die Summe der Prozentsätze der drei kleinsten Abschnitte im Kreisdiagramm (b)?;What is the sum of the percentages of the three smallest segments in pie chart (b)?;11,42%;11.42%;11,42%;11.42%;Simple Calculation;''
2020.lrec-1.678.pdf-Figure3.png;Welcher Prozentsatz im Kreisdiagramm (b) liegt am nächsten an 10 %? Wie groß ist die prozentuale Differenz zu 10 %?;Which percentage in pie chart (b) is closest to 10%? What is the percentage difference between this segment and 10%?;'9,7%, was für ''what [other]'' steht. Die Differenz beträgt 0,3 %.';'9.7%, representing ''what [other]''. The difference is 0.3%.';"9,7%; 0,3%";"9.7%; 0.3%";Simple Calculation;''
2020.lrec-1.678.pdf-Figure3.png;Laut der Arbeit sind 'Wo'-Fragen häufiger als 'Wer'- und 'Was'-Fragen. Unterstützt die in Abbildung 3(a) dargestellte Verteilung, die alle Fragetypen abdeckt, diese Behauptung visuell? Wie verhält sich insbesondere das Segment, das 'Wo'-Fragen repräsentiert (das anhand der Informationen zu den ersten Fragewörtern und Segmentgrößen in Abbildung 3(b) abgeleitet werden kann), in der Größe zum kombinierten Segment der 'Wer'- und 'Was'-Fragen in Abbildung 3(a)?;According to the paper, 'Where' questions are more frequent than 'Who' and 'What' questions. Does the distribution presented in Figure 3(a), which covers all question types, visually support this assertion? Specifically, how does the segment representing ‘where’ questions (which can be inferred based on the information about first question words and segment sizes in Figure 3(b)) compare in size to the combined size of the ‘who’ and ‘what’ segments in Figure 3(a)?;„Wo“-Fragen sind häufiger (43 %) als „Wer“- (31 %) und „Was“-Fragen (26 %).;'Where' questions are more frequent (43%) than 'Who' (31%) and 'What' (26%) questions.;Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;''
2020.lrec-1.751.pdf-Figure4.png;Welches Subreddit wird im äußeren Ring durch den größten orangen/korallfarbenen Abschnitt dargestellt?;Which subreddit is represented by the largest orange/coral section in the outer ring?;AskReddit;AskReddit;AskReddit;AskReddit;Simple Retrieval;''
2020.lrec-1.751.pdf-Figure4.png;Welcher Subreddit im inneren Ring belegt den kleinsten Bereich und welche Farbe hat er?;Which subreddit occupies the smallest area in the inner ring, and what color is it?;trees, hellblau;trees, light blue;trees, hellblau;trees, light blue;Simple Retrieval;''
2020.lrec-1.751.pdf-Figure4.png;In der Arbeit wird erwähnt, dass die Datenerhebung auf selbstberichteten Geschlechtsangaben beruht. Welche möglichen Einschränkungen ergeben sich daraus für die Interpretation der Ergebnisse in Abbildung 4 hinsichtlich der beliebtesten Subreddits nach Geschlecht, wie in der Arbeit diskutiert?;The paper mentions that the data collection relies on self-reported gender identification. Considering this, what are the potential limitations for interpreting the results in Figure 4 regarding most popular subreddits by gender as discussed in the paper?;Die Verwendung von selbstberichteten Geschlechtsangaben spiegelt möglicherweise nicht die tatsächliche Geschlechterverteilung auf Reddit wider, da einige Benutzer ihr Geschlecht falsch darstellen oder nicht angeben könnten. Dies könnte die beobachtete Popularität von Subreddits innerhalb jeder Geschlechterkategorie verzerren und es schwierig machen, die Ergebnisse auf die gesamte Reddit-Population zu verallgemeinern.;Self-reported gender might not accurately represent the true gender distribution on Reddit, as some users could misrepresent their gender or choose not to disclose it. This could bias the observed popularity of subreddits within each gender category, making it difficult to generalize the results to the overall Reddit population.;Selbstberichtete Geschlechtsangaben;Self-reported gender;Requires Paper Context;'For each labeled user in our dataset, we retrieved posts authored by the user along with the subreddits these posts were written in, which allows us to investigate the dependencies between personal attributes and subreddits. For instance, Figure 4 shows the distribution of genders in RedDust as well as the distribution of most popular subreddits for each gender. The chart exposes females as the dominant users in our dataset, which does not conform to statistics from other sources.[8] However, due to peculiarities of our labeling patterns, note that RedDust does not give the true outlook of real life population as well as Reddit demography.'
2020.lrec-1.87.pdf-Figure4.png;Welche Farbe hat der größte Abschnitt im Kreisdiagramm?;What is the color of the largest segment in the pie chart?;Mittelblau.;Medium blue.;Mittelblau;Medium blue;Simple Retrieval;''
2020.lrec-1.87.pdf-Figure4.png;Wie viel Prozent macht der zweitgrößte Abschnitt im Kreisdiagramm aus?;What percentage does the second largest segment in the pie chart represent?;17,78%;17.78%;17,78%;17.78%;Simple Retrieval;''
2020.lrec-1.87.pdf-Figure4.png;Wie viele Prozentpunkte Unterschied gibt es zwischen dem größten und dem kleinsten Segment des Kreisdiagramms?;What is the percentage point difference between the largest and smallest segments of the pie chart?;67,4%;67.4%;67,4%;67.4%;Simple Calculation;''
2020.lrec-1.87.pdf-Figure4.png;Wie viel Prozent der Antworten machen die Stufen 3, 4 und 5 zusammen aus und wie viele absolute Antworten entspricht das?;What percentage of responses do levels 3, 4, and 5 represent combined, and how many actual responses does this equate to?;14,24%, was 5410 Antworten entspricht.;14.24%, which equates to 5410 responses.;14,24%;14.24%;Simple Calculation;''
2020.lrec-1.87.pdf-Figure4.png;Abbildung 4 zeigt die Verteilung der Antworten im Auswertungsdatensatz.  Im Text wird erwähnt, dass die Konkretheit der Antworten mit dem Grad der Empathie zusammenhängt.  Betrachtet man die Aufteilung der Antwortlevel in Abbildung 4, welches Level würde man basierend auf der Häufigkeit der Antworten als am wenigsten einfühlsam erwarten und warum?;Figure 4 shows the breakdown of responses in the evaluation data. The text mentions that the concreteness of responses is related to the degree of empathy. Looking at the distribution of response levels in Figure 4, which level would you expect to be the least empathetic based on the frequency of responses and why?;Stufe 1 wäre voraussichtlich am wenigsten einfühlsam.  Dies liegt daran, dass sie den größten Anteil der Antworten (67,98%) ausmacht, und laut Text neigen weniger konkrete Antworten (die weniger Berücksichtigung der Erzählung erfordern) dazu, weniger Empathie zu zeigen.;Level 1 would be expected to be the least empathetic. This is because it has the largest portion of responses (67.98%), and as per text, less concrete responses (requiring less consideration of the narrative) tend to show lower empathy.;Stufe 1;Level 1;Requires Paper Context;"It is confirmed that responses on level 1 account for more than 65% of all responses and those in either level 1 or 2 account for more than 85%.

### 4.1. Evaluation in terms of concreteness

It was evaluated whether the classification of types of attentive listening responses is appropriate in terms of response concreteness. In this section, the concreteness of the response refers to its information value. It is considered that the concreteness of the response depends on their type. Here is an example of a narrative and its two attentive listening responses:

**[narrative] I enjoyed traveling to Italy the most**

**[response 5 (admiration)] uh**

**[response 6 (echoic response)] Italy travel**

The concreteness of “response 6” is higher than that of “response 5.” Furthermore, the degree of empathy shown by “response 6” is also thought to be higher than that by “response 5.” Since for uttering responses with the high concreteness like “response 6” it is necessary to deeply consider the content of narratives, the degree of empathy shown by these responses tends to be high. On the other hand, since it is not necessary to deeply consider the content of narratives for uttering responses with low concreteness like ”response 5,” the degree of empathy shown by these responses tends to be low. Therefore, the concreteness of responses is thought to reflect the degree of empathy they express. This research measured the concreteness index of responses. The following two features were adopted as the index:

1. length: the number of morphemes in the response 2. info: information value of the response"
2020.lrec-1.875.pdf-Figure8.png;Welches Segment im Kreisdiagramm ist am kleinsten?;Which segment in the pie chart is the smallest?;Das hellblaue Segment;The light blue segment;Hellblau;Light blue;Simple Retrieval;''
2020.lrec-1.875.pdf-Figure8.png;'Ist das violette Segment (''Spoken'') größer als das blaue Segment (''Written of L2 Learners'')?';'Is the purple segment (''Spoken'') larger than the blue segment (''Written of L2 Learners'')?';Ja;Yes;Ja;Yes;Simple Calculation;''
2020.lrec-1.875.pdf-Figure8.png;'Ist das rote Segment (''Written'') größer als die Summe der beiden anderen Segmente?';'Is the red segment (''Written'') larger than the sum of the other two segments?';Ja;Yes;Ja;Yes;Simple Calculation;''
2020.lrec-1.875.pdf-Figure8.png;'Abbildung 8 zeigt die Ergebnisse einer Skewer-Suche für das Wort ''dearu'' (\'sein\\'). Tabelle 4 im Text nennt die absoluten Häufigkeiten für jedes Korpus. Wie oft kommt ''dearu'' im CSJ vor, und in welchem Kontext wird es dort häufig verwendet?';'Figure 8 displays the results of a skewer-search for the word ''dearu'' ('be'). Table 4 in the text provides the absolute frequencies for each corpus. How many occurrences of ''dearu'' are there in the CSJ, and in what context is it frequently used within that corpus?';'''Dearu'' erscheint 302 Mal im CSJ, und seine häufige Verwendung ist mit Konferenzvorträgen verbunden, die im CSJ-Datensatz stark vertreten sind.';'''Dearu'' appears 302 times in the CSJ, and its frequent use is associated with conference lectures, which are heavily represented in the CSJ dataset.';302, Konferenzvorträge;302, Conference lectures;Requires Paper Context;'|Corpus|Actual frequency| |---|---| |BCCWJ NWJC CSJ CEJC NUCC CWPC CHJ COJADS I-JAS|4,774 4,119 302 50 60 17 1,681 27 306|'
2020.ngt-1.24.pdf-Figure2.png;'Wie hoch ist der Anteil der ''TopK''-Operation vor der Optimierung?';'What is the percentage of the ''TopK'' operation before optimization?';4%;4%;4%;4%;Simple Retrieval;''
2020.ngt-1.24.pdf-Figure2.png;'Um wie viel Prozent ist der Anteil von ''MM'' nach der Optimierung im Vergleich zu vor der Optimierung gesunken?';'By what percentage did the proportion of ''MM'' decrease after optimization compared to before optimization?';19%;19%;19%;19%;Simple Calculation;''
2020.ngt-1.24.pdf-Figure2.png;Wie hoch ist der Gesamtanteil der drei kleinsten Segmente in Diagramm (a)?;What is the combined percentage of the three smallest segments in chart (a)?;23%;23%;23%;23%;Simple Calculation;''
2020.ngt-1.24.pdf-Figure2.png;'Ist die Summe der Anteile von ''MM'' und ''Memcpy'' in Diagramm (b) größer oder kleiner als der Anteil von ''MM'' in Diagramm (a)?';'Is the sum of the proportions of ''MM'' and ''Memcpy'' in chart (b) greater or smaller than the proportion of ''MM'' in chart (a)?';Kleiner. (MM in (a) ist 37%, MM + Memcpy in (b) ist 18% + 14% = 32%);Smaller. (MM in (a) is 37%, MM + Memcpy in (b) is 18% + 14% = 32%);Kleiner;Smaller;Simple Calculation;''
2020.ngt-1.24.pdf-Figure2.png;Welche spezifische Optimierungsstrategie wurde laut Text angewendet, um den Engpass bei der Matrixmultiplikation und Speicherverwaltung während der GPU-basierten Dekodierung zu beheben, und welche Geschwindigkeitsverbesserung wurde dadurch erzielt?;According to the text, what specific optimization strategy was employed to address the bottleneck of matrix multiplication and memory management during GPU-based decoding, and what was the resulting speedup?;Ein Speicherpool wurde verwendet, um die Speicherzuweisung/-freigabe zu steuern, wobei Blöcke während der Dekodierung dynamisch zugewiesen und nach Abschluss der Übersetzung freigegeben werden. Diese Strategie führte zu einer signifikanten Verbesserung der Effizienz und erreichte eine bis zu 3-fache Beschleunigung.;A memory pool was used to control memory allocation/deallocation, dynamically allocating blocks during decoding and releasing them after translation finished. This strategy led to a significant improvement in efficiency, achieving up to a 3x speedup.;Speicherpool;Memory Pool;Requires Paper Context;'Therefore we use a memory pool to control allocation/deallocation, which dynamically allocates blocks during decoding and releases them after the translation finished. Compared with the on-the-fly mode, this strategy significantly improves the efficiency of our systems by up to 3x speedup and slightly increases the memory usage.'
2020.trac-1.25.pdf-Figure1.png;Welche Sprache hat den kleinsten Anteil im Kreisdiagramm?;Which language has the smallest segment in the pie chart?;HI-EN Mix;HI-EN Mix;HI-EN Mix;HI-EN Mix;Simple Retrieval;''
2020.trac-1.25.pdf-Figure1.png;'Was ist die Summe der Prozentanteile von ''Bangladeshi Bangla'' und ''HI-EN Mix''?';'What is the sum of the percentages of ''Bangladeshi Bangla'' and ''HI-EN Mix''?';12,3%;12.3%;12,3%;12.3%;Simple Calculation;''
2020.trac-1.25.pdf-Figure1.png;Wie viele Prozentpunkte machen die drei kleinsten Sprachsegmente zusammen aus?;How many percentage points do the three smallest language segments make up in total?;33%;33%;33%;33%;Complex Calculation and Logical Reasoning;''
2020.trac-1.25.pdf-Figure1.png;Wenn man die beiden größten Segmente kombiniert, übersteigen sie die Summe der restlichen Segmente? Um wie viel Prozentpunkte?;If the two largest segments are combined, do they exceed the sum of the remaining segments? By how many percentage points?;Ja, um 33 Prozentpunkte.;Yes, by 33 percentage points.;Ja, 33;Yes, 33;Complex Calculation and Logical Reasoning;''
2020.trac-1.25.pdf-Figure1.png;Abbildung 1 zeigt die Sprachverteilung des Datensatzes. Der Text erwähnt, dass über 80% der frauenfeindlichen Kommentare auch aggressiv sind. Inwiefern ist die in Abbildung 1 dargestellte Sprachverteilung relevant für die Interpretation dieser 80%-Statistik?;Figure 1 shows the language distribution of the dataset. The text mentions that over 80% of misogynistic comments are also aggressive. How is the language distribution shown in Figure 1 relevant for interpreting this 80% statistic?;Die Sprachverteilung ist wichtig, da verschiedene Sprachen unterschiedliche kulturelle Normen in Bezug auf Aggression haben könnten. Wenn eine Sprache mit einer höheren Prävalenz aggressiver Kommentare einen größeren Teil des Datensatzes ausmacht, könnte dies die Gesamtstatistik von 80 % erhöhen. Umgekehrt könnte die Statistik verringert werden, wenn eine Sprache mit einer geringeren Prävalenz von Aggression dominiert.;The language distribution is important because different languages might have different cultural norms regarding aggression. If a language with a higher prevalence of aggressive comments makes up a larger portion of the dataset, it could inflate the overall 80% statistic. Conversely, if a language with a lower prevalence of aggression is dominant, it could deflate the statistic.;Kulturelle Normen könnten Statistik beeinflussen;Cultural norms could influence statistic;Requires Paper Context;"Overall, it turns out that over 80% of the gendered comments are also aggressive; on the other hand, less than 30% of non-gendered comments are aggressive. These results shows that misogyny may be strongly correlated with aggression and even though a substantial proportion of non-gendered comments are also aggressive (in our dataset), a much larger proportion of gendered comments are aggressive. A languagewise break-up of proportion of aggression in gendered as well as non-gendered comments are given in Figure 4 and Figure 5."
2020.acl-main.220.pdf-Figure3.png;Welche Farbe haben die Punkte, die im oberen rechten Bereich des zweiten Diagramms von links gruppiert sind?;What color are the points clustered in the top right area of the second plot from the left?;Rot;Red;Rot;Red;Simple Retrieval;''
2020.acl-main.220.pdf-Figure3.png;Im dritten Diagramm von links scheinen sich die Punkte stärker zu vermischen. Gibt es im dritten Diagramm Cluster, die aus mindestens drei verschiedenen Farben bestehen?;The points appear more mixed together in the third plot from the left. In the third plot, are there any clusters that are made up of at least three different colors?;Ja, es gibt mehrere Cluster, in denen sich violette, cyanfarbene, hellgrün/gelbe und rot/orange Punkte überlappen.;Yes, there are several clusters where purple, cyan, light green/yellow, and red/orange points overlap.;Ja;Yes;Simple Retrieval;''
2020.acl-main.220.pdf-Figure3.png;Welche zwei Diagramme zeigen die deutlichste Trennung der farbigen Punkte in verschiedene Cluster?;Which two plots show the clearest separation of the colored points into distinct clusters?;Das erste und zweite Diagramm von links.;The first and second plots from the left.;1.& 2.;1. & 2.;Simple Retrieval;''
2020.acl-main.220.pdf-Figure3.png;Im Text wird die Fähigkeit von BERT, die Struktur von Dialogen zu erfassen, diskutiert. Welche visuellen Unterschiede in der Cluster-Trennung zwischen den Scatterplots für Frames/MultiWOZ (zielorientiert) und PersonaChat/DailyDialog (Chit-Chat) unterstützen die Diskussion im Artikel über die Effektivität von BERT bei der Erfassung der Dialogstruktur?;The paper discusses BERT's ability to capture the structure of dialogues. Comparing the scatter plots for Frames/MultiWOZ (goal-oriented) and PersonaChat/DailyDialog (chit-chat), what visual differences in cluster separation support the paper's discussion on BERT's effectiveness in capturing dialogue structure?;Die zielorientierten Dialoge (Frames und MultiWOZ, die ersten beiden Diagramme) zeigen eine deutlich klarere Cluster-Trennung als die Chit-Chat-Dialoge (PersonaChat und DailyDialog, die letzten beiden Diagramme). Dies unterstützt visuell die Idee, dass BERT Strukturen in zielorientierten Dialogen effektiver erfasst.;The goal-oriented dialogues (Frames and MultiWOZ, the first two plots) show much clearer cluster separation than the chit-chat dialogues (PersonaChat and DailyDialog, the last two plots). This visually supports the idea that BERT is more effective at capturing structure in goal-oriented dialogues.;Zielorientierte Dialoge, klarere Cluster;Goal-oriented dialogues, clearer clusters;Caption Question/Simple Retrieval;'Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat).'
2020.acl-main.333.pdf-Figure1.png;Welche Farbe hat die Linie in Abbildung (a)?;What color is the line in plot (a)?;Rot.;Red.;Rot;Red;Simple Retrieval;''
2020.acl-main.333.pdf-Figure1.png;Im linken Diagramm, wie hoch ist der Wert auf der vertikalen Achse, wenn der Wert auf der horizontalen Achse 0,2 beträgt?;In the left plot, what is the value on the vertical axis when the value on the horizontal axis is 0.2?;Ungefähr 0.2.;Approximately 0.2.;0.2;0.2;Simple Retrieval;''
2020.acl-main.333.pdf-Figure1.png;Wie viele Punkte im Diagramm (a) liegen unter der roten Linie und haben einen Wert auf der horizontalen Achse von weniger als 0,5?;How many points in plot (a) lie below the red line and have a value on the horizontal axis of less than 0.5?;Ungefähr 27.;Approximately 27.;27;27;Simple Calculation;''
2020.acl-main.333.pdf-Figure1.png;Ist die Streuung der Punkte um die rote Linie im Diagramm (a) größer oder kleiner als im Diagramm (b)? Begründen Sie Ihre Antwort anhand der visuellen Darstellung.;Is the dispersion of the points around the red line in plot (a) greater or smaller than in plot (b)? Justify your answer based on the visual representation.;Größer. Die Punkte in Diagramm (a) sind weiter von der roten Linie entfernt als die Punkte in Diagramm (b), die dichter gruppiert sind.;Greater. The points in plot (a) are more spread out from the red line compared to the points in plot (b), which are more tightly clustered.;Größer;Greater;Simple Calculation;''
2020.acl-main.333.pdf-Figure1.png;Die Bildunterschrift erwähnt das Hinzufügen zufälliger Schwankungen (Jitters). Erklären Sie anhand des Artikels, warum diese Schwankungen eingeführt wurden und welche Auswirkungen sie auf die visuelle Interpretation von Punkten haben, die in Abbildung 1 überlappen?;The caption mentions adding random jitters. According to the paper, why were these jitters introduced, and how do they impact the visual interpretation of overlapping points in Figure 1?;Die zufälligen Schwankungen wurden hinzugefügt, um überlappende Punkte sichtbar zu machen. Ohne sie würden überlappende Punkte als einzelner Punkt erscheinen, was die tatsächliche Datendichte verdeckt. Die kleinen zufälligen Verschiebungen machen deutlich, wo mehrere Datenpunkte nahezu identische Werte haben.;The jitters were introduced to visualize overlapping points. Without them, overlapping points would appear as a single point, obscuring the true data density. The small random displacements make it clear where multiple data points have nearly identical values.;Überlappende Punkte sichtbar machen;Visualize overlapping points;Caption Question/Simple Calculation;''
2020.acl-main.333.pdf-Figure2.png;Welche Farbe hat die Linie im linken Diagramm?;What is the color of the line in the left plot?;Rot.;Red.;Rot;Red;Simple Retrieval;''
2020.acl-main.333.pdf-Figure2.png;Liegt der Fluency Metric-Wert im linken Diagramm jemals unter 0,1?;Does the Fluency Metric value ever fall below 0.1 in the left plot?;Ja.;Yes.;Ja;Yes;Simple Retrieval;''
2020.acl-main.333.pdf-Figure2.png;Wie viele Punkte im linken Diagramm liegen oberhalb der roten Linie und haben gleichzeitig einen Fluency Metric-Wert von weniger als 0,3?;How many points in the left plot lie above the red line and simultaneously have a Fluency Metric value less than 0.3?;Ungefähr 33.;Approximately 33.;33;33;Complex Calculation and Logical Reasoning;''
2020.acl-main.333.pdf-Figure2.png;Welches Diagramm, links oder rechts, zeigt eine höhere maximale Fluency Metric und um wie viel?;Which plot, left or right, shows a higher maximum Fluency Metric, and by approximately how much?;Das rechte Diagramm, um ungefähr 0,2.;The right plot, by approximately 0.2.;Rechts, 0,2;Right, 0.2;Simple Calculation;''
2020.acl-main.333.pdf-Figure2.png;Inwiefern beeinflusst das Hinzufügen von zufälligem Jitter, wie im Artikel beschrieben, die visuelle Interpretation der Korrelation zwischen Fluency Metric und menschlichen Bewertungen in Abbildung 2, insbesondere im Hinblick auf überlappende Datenpunkte?;How does the addition of random jitter, as described in the paper, affect the visual interpretation of the correlation between the fluency metric and human ratings in Figure 2, specifically concerning overlapping data points?;Der Jitter trennt visuell überlappende Datenpunkte und ermöglicht so eine klarere Sicht auf die Korrelation. Ohne Jitter könnten Überlappungen die wahre Punktdichte in einem bestimmten Bereich verschleiern.;The jitter separates visually overlapping data points, allowing for a clearer view of the correlation. Without jitter, overlaps could obscure the true density of points in a given area.;Trennt Punkte;Separates points;Caption Question/Complex Calculation and Logical Reasoning;'Note that random jitters sampled from (0, 0.05[2]) are added to human ratings in visualizing scatter plots _N_ showed in this paper to overlapping points.'
2020.acl-main.343.pdf-Figure4.png;Welche Farbe repräsentiert die Textmodalität in jedem Subplot?;What color represents the text modality in each subplot?;Rot repräsentiert die Textmodalität.;Red represents the text modality.;Rot;Red;Simple Retrieval;''
2020.acl-main.343.pdf-Figure4.png;Wie viele Subplots gibt es in der Abbildung?;How many subplots are there in the figure?;Es gibt 6 Subplots.;There are 6 subplots.;6;6;Simple Retrieval;''
2020.acl-main.343.pdf-Figure4.png;'Im Subplot mit der Bezeichnung ''LMF'', welcher Modalität (rot, grün oder blau) folgt am ehesten einer U-förmigen Kurve?';'In the subplot labeled ''LMF'', which modality (red, green, or blue) most closely follows a U-shaped curve?';Alle drei Modalitäten (rot, grün und blau) folgen im LMF-Subplot einer U-förmigen Kurve.;All three modalities (red, green, and blue) follow a U-shaped curve in the LMF subplot.;Alle drei;All three;Simple Retrieval;''
2020.acl-main.343.pdf-Figure4.png;Die Autoren verwenden t-SNE zur Visualisierung der unimodalen Repräsentationen. Basierend auf dem bereitgestellten Text, welche Schlussfolgerung ziehen die Autoren hinsichtlich der Unterscheidbarkeit der Repräsentationen in Modellen mit unimodalen Annotationen (zweite Zeile) im Vergleich zu Modellen ohne diese (erste Zeile)?;The authors use t-SNE to visualize the unimodal representations. Based on the provided text, what conclusion do the authors draw regarding the distinctiveness of the representations in models with unimodal annotations (second row) compared to models without them (first row)?;Die Autoren kommen zu dem Schluss, dass Modelle, die mit unimodalen Annotationen trainiert wurden (zweite Zeile), deutlichere unimodale Repräsentationen lernen als Modelle ohne diese (erste Zeile). Dies wird durch die klarere Trennung der farbigen Punkte in den Teildiagrammen der zweiten Zeile belegt.;The authors conclude that models trained with unimodal annotations (second row) learn more distinctive unimodal representations compared to models without them (first row). This is evidenced by the clearer separation of the colored points in the second row subplots.;Deutlicher;More distinctive;Requires Paper Context;'Another motivation for us to propose CH-SIMS is that we think the unimodal representation differences will be greater with independent unimodal annotations. We use t-SNE (Maaten and Hinton, 2008) to visualize intra-modal representations learned in original models (LF-DNN, TFN, and LMF) and new models (MLF-DNN, MTFN, and MLMF), shown as Figure 4. It is relatively obvious that new models learn more distinctive unimodal representations compare to original models. Therefore, unimodal annotations can help the model to obtain more differentiated information and improve the complementarity between modalities.'
2020.acl-main.416.pdf-Figure2.png;Welche Farbe haben die Punkte, die 2-Gramme in Abbildung 2 darstellen?;What color are the points representing 2-grams in Figure 2?;Grün;Green;Grün;Green;Simple Retrieval;''
2020.acl-main.416.pdf-Figure2.png;What is the highest value on the y-axis in Figure 2(a)?;Wie hoch ist der höchste Wert auf der y-Achse in Abbildung 2(a)?;1,5 * 10^3;1.5 * 10^3;1,5 * 10^3;1.5 * 10^3;Simple Retrieval;''
2020.acl-main.416.pdf-Figure2.png;Ist der Unterschied in der Anzahl der 4-Gramme (rote Punkte) zwischen dem größten und kleinsten Wert von |G| in Abbildung 2(a) größer oder kleiner als der gleiche Unterschied in Abbildung 2(b)?;Is the difference in the number of 4-grams (red points) between the largest and smallest value of |G| in Figure 2(a) greater or smaller than the same difference in Figure 2(b)?;Kleiner;Smaller;Kleiner;Smaller;Simple Calculation;''
2020.acl-main.416.pdf-Figure2.png;Die Bildunterschrift erwähnt, dass die größte Anzahl von 4-Gramme, die aus einem Graphen in PMB extrahiert wurden, 2,27 * 10^3 ist. Entspricht die Verteilung der Punkte in Abbildung 2(b) dieser Aussage? Begründen Sie Ihre Antwort anhand der Darstellung im Graphen und unter Berücksichtigung der Aussage im Paper, dass die x-Achse logarithmisch skaliert ist.;The caption mentions that the largest number of 4-grams extracted from one graph in PMB is 2.27 * 10^3. Does the distribution of points in Figure 2(b) correspond to this statement? Justify your answer by referring to the graph's representation and by considering the paper's statement that the x-axis is logarithmically scaled.;Ja. Die Verteilung in Abbildung 2(b) stimmt mit der Aussage überein. Die roten Punkte (4-Gramme) nähern sich der 2 * 10^3-Marke auf der y-Achse an, überschreiten sie aber nicht sichtbar. Die logarithmische Skalierung der x-Achse komprimiert größere |G|-Werte. Daher liefern die begrenzte Anzahl von Datenpunkten bei höheren |G|-Werten und der Fokus der Bildunterschrift auf das Maximum aus *einem* Graphen weiteren Kontext.;Yes. The distribution in 2(b) aligns with the statement.  The red points (4-grams) approach, but do not visibly surpass, 2 * 10^3 on the y-axis. The logarithmic x-axis scale compresses larger |G| values. Therefore, the limited number of data points at higher |G| values and the caption's focus on the maximum from *one* graph provide further context.;Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;''
2020.acl-main.447.pdf-Figure4.png;'Welche Farbe repräsentiert die Kategorie ''Jahr''?';'What color represents the ''year'' category?';Grün;Green;Grün;Green;Simple Retrieval;''
2020.acl-main.447.pdf-Figure4.png;'Ist der Cluster für ''Wort'' größer als der Cluster für ''PDF-Referenz'', wenn man die Anzahl der Punkte im Scatterplot betrachtet?';'Is the cluster for ''word'' larger than the cluster for ''pdf_reference'' in terms of the number of points in the scatter plot?';'Ja, der Cluster für ''Wort'' scheint mehr Punkte zu haben als der Cluster für ''PDF-Referenz''.';'Yes, the cluster for ''word'' appears to have more points than the cluster for ''pdf_reference''.';Ja;Yes;Simple Calculation;''
2020.acl-main.447.pdf-Figure4.png;Die Abbildung visualisiert die kontextuellen Repräsentationen von numerischen Oberflächenformen. Warum wurde Schicht 9 von S2ORC-SCIBERT für diese Visualisierung gewählt, und wie spiegelt die Darstellung in der Abbildung die Qualität der Einbettungen aus dieser Schicht wider (z.B. Clusterbildung)?;This figure visualizes contextual representations of numeric surface forms. Why was layer 9 of S2ORC-SCIBERT chosen for this visualization, and how does the representation in the figure reflect the quality of the embeddings from this layer (e.g., clustering)?;Schicht 9 wurde gewählt, weil die letzten 2-3 BERT-Schichten sich durch prädiktive Sprachmodellierung auszeichnen. Die deutliche Clusterbildung verschiedener numerischer Oberflächenformen (Jahre, Zitate usw.) spiegelt die Qualität der Einbettungen von Schicht 9 wider, indem sie zeigt, wie effektiv Kontextinformationen erfasst werden.;Layer 9 was chosen because the final 2-3 BERT layers excel at predictive language modeling.  The distinct clustering of different numeric surface forms (years, citations, etc.) reflects the quality of the embeddings from layer 9 by demonstrating its ability to capture contextual information effectively.;Schicht 9 wegen prädiktiver Sprachmodellierung;Layer 9 for predictive language modelling;Requires Paper Context;"Following Peters et al. (2018b); Liu et al. (2019a), we observe that the final 2-3 BERT layers provide embeddings that excel at predictive language modeling; as such, Figure 4 uses embeddings from layer 9 of S2ORC-SCIBERT."
2020.acl-main.50.pdf-Figure2.png;Welche Farbe haben die Punkte, die Cluster 0 darstellen?;What color are the points representing Cluster 0?;Blau.;Blue.;Blau;Blue;Caption Question/Simple Retrieval;''
2020.acl-main.50.pdf-Figure2.png;Wie viele Punkte gehören ungefähr zu Cluster 1?;Approximately how many points belong to Cluster 1?;Ungefähr 100.;Approximately 100.;100;100;Caption Question/Simple Calculation;''
2020.acl-main.50.pdf-Figure2.png;Welcher Cluster ist am weitesten von den anderen Clustern entfernt, und wie ist seine ungefähre Position auf der X- und Y-Achse?;Which cluster is furthest removed from the other clusters, and what is its approximate position on the x and y axes?;Cluster 1 ist am weitesten entfernt und befindet sich ungefähr bei x = -0.7 und y = 0.25.;Cluster 1 is furthest removed, located approximately at x = -0.7 and y = 0.25.;Cluster 1;Cluster 1;Caption Question/Simple Calculation;''
2020.acl-main.50.pdf-Figure2.png;Sind mehr Punkte oberhalb oder unterhalb der x-Achse dargestellt?;Are more points plotted above or below the x-axis?;Mehr Punkte sind unterhalb der x-Achse dargestellt.;More points are plotted below the x-axis.;Unterhalb;Below;Caption Question/Simple Calculation;''
2020.acl-main.50.pdf-Figure2.png;'Im Artikel wird die Kosinusähnlichkeit zwischen den Retweet-Vektoren der Benutzer erwähnt. Welche Auswirkungen hat die Kosinusähnlichkeit auf die Anordnung der Punkte in Abbildung 2, insbesondere im Hinblick auf die Unterscheidung zwischen ''Cluster 0'' und ''Nicht gruppiert''?';The paper mentions using cosine similarity between user retweet vectors. Considering the methodology described in the paper, how does the cosine similarity influence the arrangement of points in Figure 2, specifically regarding the distinction between 'Cluster 0' and 'Not clustered'?;Benutzer mit ähnlichen Retweet-Mustern, gemessen durch höhere Kosinusähnlichkeit zwischen ihren Retweet-Vektoren, werden in der 2D-Projektion näher beieinander platziert. Cluster 0 repräsentiert Benutzer mit ähnlichem Retweet-Verhalten. 'Nicht gruppierte' Punkte stellen Benutzer dar, deren Retweet-Muster sowohl zu Cluster 0 als auch zu Cluster 1 unähnlich sind, was zu ihrer verstreuten Platzierung aufgrund geringer Kosinusähnlichkeit mit anderen Benutzern führt.;Users with similar retweet patterns, as measured by higher cosine similarity between their retweet vectors, are placed closer together in the 2D projection. Cluster 0 represents users with similar retweet behavior. 'Not clustered' points represent users whose retweet patterns are dissimilar to both Cluster 0 and Cluster 1, resulting in their scattered placement due to low cosine similarity with other users.;Ähnliche Retweets -> nähere Punkte;Similar retweets -> closer points;Requires Paper Context;'Given the tweets for each topic, we compute the similarity between the top 1,000 most active users. To compute similarity, we construct a vector for each user containing the number of all the accounts that a user has retweeted, and then we compute the pairwise cosine similarity between them. ... When performing dimensionality reduction, UMAP places users on a two-dimensional plane such that similar users are placed closer together and dissimilar users are pushed further apart. Figure 2 shows the top users for the “midterm” topic projected with UMAP onto the 2D plane. After the projection, we use Mean Shift to cluster the users as shown in Figure 2.'
W12-0203.pdf-Figure2.png;Welche Farbe wird für das Wort 'beeldscherm' verwendet?;What color is used for the word 'beeldscherm'?;Blau;Blue;Blau;Blue;Simple Retrieval;''
W12-0203.pdf-Figure2.png;Wie viele Wörter sind in der Legende aufgeführt?;How many words are listed in the legend?;3;3;3;3;Simple Retrieval;''
W12-0203.pdf-Figure2.png;Gibt es überlappende Punkte im Streudiagramm, und wenn ja, welche Farben sind beteiligt?;Are there any overlapping points in the scatter plot, and if so, which colors are involved?;Ja, es gibt überlappende Punkte. Die überlappenden Punkte betreffen alle drei Farben: Blau ('beeldscherm'), Grün ('computer_scherm') und Gelb ('monitor').;Yes, there are overlapping points. The overlapping points involve all three colors: blue ('beeldscherm'), green ('computer_scherm'), and yellow ('monitor').;Ja;Yes;Simple Retrieval;''
W12-0203.pdf-Figure2.png;Welche Wortgruppe hat die größte Streuung im Diagramm, gemessen an der Fläche, die die Punkte einnehmen?;Which word group has the largest spread in the diagram, as measured by the area the dots occupy?;Die gelben Punkte, die für 'monitor' stehen, haben die größte Streuung.;The yellow dots representing 'monitor' have the largest spread.;Gelb/Monitor;Yellow/Monitor;Simple Retrieval;''
W12-0203.pdf-Figure2.png;'Die Forschungsarbeit erwähnt die Verwendung eines ''gewichteten'' im Vergleich zu einem ''ungewichteten'' Token-Level-SVS. Basierend auf Abbildung 2 und dem bereitgestellten Kontext, was könnte ein potenzieller Vorteil der Verwendung eines gewichteten Ansatzes zur Unterscheidung der verschiedenen Bedeutungen von \'monitor\' sein?';'The research paper discusses using a ''weighted'' vs. ''unweighted'' token-level SVS. Based on Figure 2 and the provided context, what might be a potential advantage of using a weighted approach for distinguishing the different senses of \'monitor\'?';'Der gewichtete Ansatz räumt Kontextwörtern, die stark mit einer bestimmten Bedeutung von 'monitor' assoziiert sind, mehr Bedeutung ein. In Abbildung 2 sind die 'monitor'-Punkte, die ''Supervisor'' darstellen, separat gruppiert. Ein gewichtetes SVS könnte den Einfluss von Kontextwörtern wie ''Jugend'' oder ''Aktivitäten'' für diese Punkte verstärken und gleichzeitig den Einfluss weniger relevanter Wörter verringern, wodurch die Trennung zwischen den Bedeutungen verbessert wird.';'The weighted approach gives more importance to context words that are strongly associated with a particular sense of 'monitor'. In Figure 2, the 'monitor' points representing ''supervisor'' are clustered separately. A weighted SVS could amplify the influence of context words like ''youth'' or ''activities'' for those points, while diminishing the impact of less relevant words, thus improving the separation between senses.';Gewichtung wichtiger Kontextwörter;Weighting important context words;Requires Paper Context;"_⃗o[w]i_ [=]


�n _j∈Ci[w]_ _[⃗c][j]_

_n_


where _o[⃗][w]i_ [is the token vector for the][ i][th][ occur-] rence of noun w and Ci[w] is the set of n type vectors ⃗cj for the context words in the window around that i[th] occurrence of noun w. However, this summation means that each first order context word has an equal weight in determining the token vector. Yet, not all first-order context words are equally informative for the meaning of a token. In a sentence like “While walking to work, the teacher saw a dog barking and chasing a cat”, bark and cat are much more indicative of the meaning of dog than say teacher or work. In a second, weighted version, we therefore increased the contribution of these informative context words by using the first-order context words’ PMI values with the noun in the synset. PMI can be regarded as a measure for informativeness and target-noun/context-word PMI-values were available anyway from our large type-level SVS. The PMI of a noun w and a context word cj can now be seen as a weight pmi[w]cj [. In constructing the to-] ken vector _o[⃗][w]i_ [for the][ i][th occurrence of noun][ w][,] we now multiply the type vector ⃗cj of each context word with the PMI weight pmi[w]cj [, and then] normalize by the sum of the pmi-weights:


_⃗o[w]i_ [=]


�n _j∈Ci[w]_ _[pmi]c[w]j_ _[∗]_ _[⃗c][j]_ �n _j_ _[pmi]c[w]j_"
W12-2206.pdf-Figure1.png;Welche Farbe haben die Datenpunkte mit dem niedrigsten GULPEASE-Wert?;What color are the data points with the lowest GULPEASE value?;Schwarz.;Black.;Schwarz;Black;Simple Retrieval;''
W12-2206.pdf-Figure1.png;Was ist die Differenz im Dokument-ID-Wert zwischen dem ersten und letzten sichtbaren Datenpunkt?;What is the difference in DOCUMENT ID value between the first and last visible data point?;180.;180.;180;180;Simple Calculation;''
W12-2206.pdf-Figure1.png;Wie viele Datenpunkte haben einen GULPEASE-Wert über 64?;How many data points have a GULPEASE value greater than 64?;Ungefähr 11.;Approximately 11.;11;11;Simple Calculation;''
W12-2206.pdf-Figure1.png;Der Text erwähnt, dass die drei Klassen im Korpus nicht einfach anhand des Gulpease-Index trennbar sind. Konzentrieren Sie sich auf die Datenpunkte mit GULPEASE-Werten zwischen 50 und 60 und analysieren Sie visuell deren Verteilung über die DOKUMENT-IDs. Unterstützen die visuellen Muster in diesem Bereich die Behauptung des Textes?;The text mentions that the three classes in the corpus are not easily separable based on the Gulpease index. Focusing on the data points with GULPEASE scores between 50 and 60, visually analyze their distribution across DOCUMENT IDs. Do the visual patterns within this range support the text's assertion?;Ja. Die Datenpunkte mit GULPEASE-Werten zwischen 50 und 60 sind über fast den gesamten Bereich der DOKUMENT-IDs verteilt, ohne klare Trennung oder Clusterbildung. Dies unterstützt die Aussage des Textes, dass die Klassen nicht einfach anhand des GULPEASE-Wertes trennbar sind.;Yes. The data points with GULPEASE values between 50 and 60 are distributed across nearly the full range of DOCUMENT IDs with no clear separation or clustering.  This supports the text's statement that the classes are not easily separable by GULPEASE score.;Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;'Although the highest readability score is obtained by a document of Class 1, and the lowest scores concern documents in Class 3, the three classes do not seem to be separable based solely on Gulpease. In particular, documents in Class 2, written for students in middle school, show scores partly overlapping with Class 1 and partly with Class 3. Furthermore, the great majority of the documents in the corpus have a Gulpease index included between 50 and 60 and the average Gulpease does not differ consistently across the three classes (Table 1).'
W13-1801.pdf-Figure4.png;Welche Farbe haben die Punkte im Streudiagramm?;What color are the dots in the scatter plot?;Die Punkte sind rot.;The dots are red.;Rot;Red;Simple Retrieval;
W13-1801.pdf-Figure4.png;Was ist der Unterschied im Wert der x-Achsenbeschriftungen zwischen zwei aufeinanderfolgenden Hauptmarkierungen?;What is the difference in value of the x-axis labels between two consecutive major ticks?;Jede Hauptmarkierung repräsentiert eine Größenordnung (eine Zehnerpotenz). Daher erhöht sich der Unterschied zwischen den Markierungen jedes Mal um den Faktor 10.;Each major tick represents an order of magnitude (a power of 10). Therefore, the difference between ticks increases by a factor of 10 each time.;Faktor 10;Factor 10;Simple Calculation;
W13-1801.pdf-Figure4.png;Gibt es Punkte mit einem relativen Fehler von mehr als 90%? Wenn ja, wo ungefähr auf der x-Achse befinden sie sich?;Are there any points that have a relative error greater than 90%, and if so, approximately where on the x-axis are they located?;Ja, es gibt einen Punkt mit einem relativen Fehler von fast 95 %. Er befindet sich ganz rechts im Diagramm, etwa bei 1e-01 auf der x-Achse.;Yes, there is one point with a relative error close to 95%. It's located at the far right of the graph, around 1e-01 on the x-axis.;Ja, bei 1e-01;Yes, at 1e-01;Simple Retrieval;
W13-1801.pdf-Figure4.png;Der Text erwähnt die Schwierigkeit, realistische PFA zum Testen zu generieren, und stellt fest, dass in Sprachmodellen die wahrscheinlichste Zeichenkette oft sehr kurz oder leer ist. Betrachtet man Abbildung 4, wie hoch ist der ungefähre relative Fehler für Konsensusstrings mit Wahrscheinlichkeiten um 1e-06? Warum könnte dieser Wahrscheinlichkeitsbereich angesichts der Diskussion im Text bei der Bewertung der Leistung des vorgeschlagenen Algorithmus für realistischere, potenziell anspruchsvolle Daten von besonderem Interesse sein?;The text discusses the challenge of generating realistic PFA for testing, noting that in language models, the most probable string is often very short or empty. Looking at Figure 4, what is the approximate relative error for consensus strings with probabilities around 1e-06? Considering the discussion in the text, why might this range of probabilities be of particular interest when evaluating the performance of the proposed algorithm on more realistic, potentially challenging data?;'Der relative Fehler für Konsensusstrings mit Wahrscheinlichkeiten um 1e-06 liegt etwa zwischen 40% und 70%. Dieser Bereich ist interessant, da, wie im Text erwähnt, realistische Daten (wie die eines Sprachmodells) oft zu sehr kurzen oder leeren wahrscheinlichsten Zeichenketten führen. Diese Zeichenketten haben hohe Wahrscheinlichkeiten (in Richtung der rechten Seite der x-Achse) und daher einen geringen relativen Fehler, wodurch sie für Algorithmen ''leicht'' zu finden sind. Der Wahrscheinlichkeitsbereich 1e-06 stellt einen Mittelweg dar, in dem die Konsensusstrings länger und komplexer (realistischer) sind und dennoch der relative Fehler signifikant genug ist, um die Robustheit und Effizienz des vorgeschlagenen Algorithmus bei der Handhabung anspruchsvollerer Daten zu testen.';The relative error for consensus strings with probabilities around 1e-06 is approximately between 40% and 70%. This range is interesting because, as the text mentions, realistic data (like those from a language model) often result in very short or empty most probable strings. These strings have high probabilities (towards the right of the x-axis) and thus low relative error, making them 'easy' for algorithms to find. The 1e-06 probability range represents a middle ground where the consensus strings are longer and more complex (more realistic) yet the relative error is still significant enough to test the robustness and efficiency of the proposed algorithm in handling more challenging data.;40%-70%;40%-70%;Caption Question/Complex Calculation and Logical Reasoning;'A more extensive experimentation may consist in building a collection of random PFA, in the line of what has been done in HMM/PFA learning competitions, for instance [Verwer et al., 2012]. A connected graph is built, the arcs are transformed into transitions by adding labels and weights. A normalisation phase takes place so as to end up with a distribution of probabilities. The main drawback of this procedure is that, most often, the consensus string will end up by being the empty string (or a very short string) and any algorithm will find it easily. more realistic data: a language model built from ngrams will often have as most probable string the empty string.'
W14-1802.pdf-Figure4.png;Welche Farbe haben die Punkte im Streudiagramm?;What color are the dots in the scatter plot?;Rot.;Red.;Rot;Red;Simple Retrieval;''
W14-1802.pdf-Figure4.png;Was ist der ungefähre Unterschied zwischen dem höchsten und dem niedrigsten Wert auf der vertikalen Achse ('Machine Overall')?;What is the approximate difference between the highest and the lowest value on the vertical axis ('Machine Overall')?;14;14;14;14;Simple Calculation;''
W14-1802.pdf-Figure4.png;Gibt es Punkte im Streudiagramm, die mehr als 2 Einheiten von der Hauptaggregation der Punkte entfernt liegen? Wenn ja, wo im Diagramm befinden sich diese Punkte (z.B. oben links, unten rechts)?;Are there any dots in the scatter plot that are positioned more than 2 units away from the main cluster of dots? If so, where are they located in the plot (e.g., top left, bottom right)?;Ja, es gibt einige Ausreißerpunkte. Einige befinden sich unterhalb des Hauptclusters. Speziell in Richtung unten links.;Yes, there are some outlier points. Some are located below the main cluster. Specifically towards the bottom left.;Unten links;Bottom left;Complex Calculation and Logical Reasoning;''
W14-1802.pdf-Figure4.png;Wenn Sie eine Regressionsgerade durch die Punktewolke zeichnen würden, würde diese im Allgemeinen steigen oder fallen?;If you were to draw a line of best fit through the scatter plot, would that line generally rise or fall?;Steigen;Rise;Steigen;Rise;Simple Calculation;''
W14-1802.pdf-Figure4.png;Wie hoch ist der Korrelationskoeffizient (r) zwischen den Bewertungen von Menschen und Maschinen für Stufe IV, wie in der Bildunterschrift erwähnt?;What is the correlation coefficient (r) between human and machine scores for Stage IV, as mentioned in the figure caption?;0,95;0.95;0,95;0.95;Caption Question/Simple Retrival;''
W16-18.pdf-Figure4.png;Welche Farbe haben die Punkte, die die Standardabweichung des zusammengesetzten Scores darstellen?;What color are the dots representing the standard deviation of the compound score?;Blau;Blue;Blau;Blue;Simple Retrieval;''
W16-18.pdf-Figure4.png;Wie hoch ist der Schwellenwert für hohe Standardabweichung auf der y-Achse?;What is the value of the high standard deviation threshold on the y-axis?;1,5;1.5;1,5;1.5;Simple Retrieval;''
W16-18.pdf-Figure4.png;Gibt es Punkte, die sowohl unter dem Schwellenwert für hohe Standardabweichung (1,5) als auch rechts vom Mittelwert von 2 auf der x-Achse liegen?;Are there any dots that are both below the high standard deviation threshold (1.5) and to the right of the mean value of 2 on the x-axis?;Ja, es gibt zahlreiche Punkte, die diese Kriterien erfüllen.;Yes, there are numerous dots that meet this criteria.;Ja;Yes;Simple Calculation;''
W16-18.pdf-Figure4.png;Welche Farbpunkte weisen die größte vertikale Streuung auf (größter Unterschied zwischen dem höchsten und niedrigsten y-Wert) und wo ungefähr auf der x-Achse tritt diese Streuung auf?;Which color dots exhibit the largest vertical spread (greatest difference between highest and lowest y-value) and approximately where on the x-axis does this spread occur?;Die grünen Punkte, die den Modifikatorwert darstellen, weisen die größte vertikale Streuung auf, die bei ungefähr x = 2 auftritt.;The green dots, which represent the modifier score, have the largest vertical dispersion, which occurs at approximately x = 2.;Grün, x=2;Green, x=2;Complex Calculation and Logical Reasoning;''
W12-0207.pdf-Figure1.png;Welche Disziplin wird durch den hellrosa Kreis dargestellt?;Which discipline is represented by the light pink circle?;Linguistik;Linguistics;Linguistik;Linguistics;Simple Retrieval;''
W12-0207.pdf-Figure1.png;Wie viele Disziplinen überschneiden sich mit Informatik?;How many disciplines overlap with Computer Science?;4;4;4;4;Simple Calculation;''
W12-0207.pdf-Figure1.png;Welche Disziplinen überschneiden sich mit Informatik, aber nicht mit Biologie?;Which disciplines overlap with Computer Science, but not Biology?;Computerlinguistik, Mikroelektronik und Digitale Konstruktion;Computational Linguistics, Microelectronics, and Digital Construction;Computerlinguistik, Mikroelektronik, Digitale Konstruktion;Computational Linguistics, Microelectronics, Digital Construction;Simple Calculation;''
W12-0207.pdf-Figure1.png;Welche Disziplin überschneidet sich sowohl mit Informatik als auch mit Biologie, und wie lautet ihre Abkürzung im Diagramm?;Which discipline overlaps with both Computer Science and Biology, and what is its abbreviation in the diagram?;Bioinformatik (B2);Bioinformatics (B2);Bioinformatik (B2);Bioinformatics (B2);Simple Retrieval;''
W16-2921.pdf-Figure2.png;Wie viele Sätze wurden nur von Annotator 1 annotiert?;How many sentences were annotated only by Annotator 1?;300;300;300;300;Simple Retrieval;''
W16-2921.pdf-Figure2.png;Wie viele Sätze wurden von mindestens zwei Annotatoren annotiert?;How many sentences were annotated by at least two annotators?;200;200;200;200;Simple Calculation;''
W16-2921.pdf-Figure2.png;Im Text wird erwähnt, dass Probleme mit der Satzsegmentierung im Testdatensatz behoben wurden. Wie hätte sich dies auf die Überschneidungen in Abbildung 2 ausgewirkt, wenn diese Korrekturen nicht vorgenommen worden wären? Begründen Sie Ihre Antwort.;The paper mentions correcting segmentation issues in the testing dataset. Considering this, how might the overlaps in Figure 2 have been affected if these corrections hadn't been made? Explain your reasoning.;Wenn Satzsegmentierungsprobleme nicht korrigiert worden wären, könnten die Überschneidungen in Abbildung 2 künstlich höher gewesen sein.  Dies liegt daran, dass eine falsche Segmentierung dazu führen könnte, dass mehrere Annotatoren Textabschnitte als separate Sätze markieren, obwohl diese Abschnitte Teile desselben ursprünglichen Satzes gewesen sein könnten. Dies würde die Überschneidungszahlen erhöhen, da die Übereinstimmungen auf möglicherweise kleineren Textsegmenten beruhen würden.;If sentence segmentation issues hadn't been corrected, the overlaps in Figure 2 might have been artificially higher. This is because incorrect segmentation could lead to multiple annotators tagging what they perceived as separate sentences, even though these segments might have been parts of the same original sentence. This would inflate the overlap counts since agreements would be based on potentially smaller text segments.;Höher;Higher;Requires Paper Context;'...segmentation issues -e.g. different sentences that were not separated by the tokenizer- were corrected...'
