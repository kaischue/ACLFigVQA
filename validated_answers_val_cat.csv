img_file_name;question_german;question_english;corrected_answer_german;corrected_answer_english;short_answer_german;short_answer_english;category;context
2015.jeptalnrecital-long.2.pdf-Figure8.png;'Welche Farbe repräsentiert die Linie für 'random'?';'What color represents the line for 'random'?';'Die Linie für 'random' wird durch Dunkelblau/Blau dargestellt.';'The line for 'random' is represented by dark blue/blue.';'Blau';Blue;Caption Question/Simple Retrival;'
2015.jeptalnrecital-long.2.pdf-Figure8.png;'Wie hoch ist der Wert für 'Information Density' bei 1000 annotierten Wörtern?';'Wie hoch ist der Wert für 'Information Density' bei 1000 annotierten Wörtern?';'Der Wert für 'information density' bei 1000 annotierten Wörtern beträgt ungefähr 0,55.';'The value for 'information density' at 1000 annotated words is approximately 0.55.';'0,55';0.55;Caption Question/Simple Retrival;'
2015.jeptalnrecital-long.2.pdf-Figure8.png;'Bei wie vielen Wörtern (auf der x-Achse) übersteigen sowohl 'confiance minimale' als auch 'confiance minimale normalisée' den Wert 0,7?';'At how many words (on the x-axis) do both 'confiance minimale' and 'confiance minimale normalisée' exceed the value of 0.7?';'Sowohl 'confiance minimale' als auch 'confiance minimale normalisée' überschreiten den Wert 0,7 ab ca. 75000 Wörtern.';'Both 'confiance minimale' and 'confiance minimale normalisée' exceed 0.7 at approximately 75000 words and above.';'75000';75000;Caption Question/Simple Calculation;'
2015.jeptalnrecital-long.2.pdf-Figure8.png;Welche Methode erreicht als erste eine Genauigkeit von 0,5 und bei wie vielen annotierten Wörtern?;Which method is the first to reach an accuracy of 0.5 and at how many annotated words?;'Proportion' (Grün) erreicht als erste Methode eine Genauigkeit von 0,5 bei ca. 500 annotierten Wörtern.;'Proportion' (Grün) achieves an accuracy of 0.5 with approximately 500 annotated words as the first method.;'Proportion, 500';Proportion, 500;Caption Question/Simple Calculation;'
2015.jeptalnrecital-long.2.pdf-Figure8.png;'In Abschnitt 5.2 werden die verschiedenen Kurvenverläufe diskutiert. Warum schneiden Methoden wie 'confiance minimale' und 'entropie' bei geringen Annotationskosten manchmal schlechter ab als 'random', obwohl sie komplexere Berechnungen verwenden?';'Section 5.2 discusses the different progressions of the curves. Why do methods like 'confiance minimale' and 'entropie' sometimes underperform compared to 'random' at low annotation costs, despite using more complex calculations?';'Methoden wie 'confiance minimale' und 'entropie' können bei geringen Annotationskosten aufgrund von Verzerrungen, die mit ihrer Abhängigkeit von Klassifikatorvorhersagen zusammenhängen, schlechter abschneiden als 'random'. Diese Vorhersagen sind bei begrenzten Trainingsdaten weniger zuverlässig. Die einfachere 'random'-Methode leidet anfänglich nicht unter diesen Verzerrungen.';"Methods like 'confiance minimale' and 'entropie' can underperform 'random' at low annotation costs due to biases related to their reliance on classifier predictions, which are less reliable with limited training data.  The simpler 'random' method doesn't suffer from these biases initially.';'Verzerrungen bei geringen Datenmengen';Bias with limited Data;Requires Paper Context;'## 5.2 Résultats

Les figures 5, 6, 7 et 8 présentent les courbes d’apprentissage sur nos différents jeux de données. La performance des classifieurs appris à chaque itération est donc exprimée en fonction du coût de l’annotation cumulé de l’ensemble . _T_ Dans les figures, ce coût est rapporté sur une échelle logarithmique qui permet de bien apprécier les différents cas (peu d’annotations vs. beaucoup d’annotations).

Plusieurs observations en ressortent. [...] Deuxièmement, on observe que les trois stratégies de la littérature offrent des performances moyennes, parfois peu éloignées de la stratégie random. Les stratégies de confiance minimale et entropie sont même parfois nettement en deçà du hasard (SenseEval-2), visiblement pénalisées par leurs biais discutés en section 3. Ce point est important à noter puisqu’il est souvent occulté par les évaluations ne prenant en compte que le nombre de séquences, comme nous l’avons déjà souligné pour le travail de (Settles & Craven, 2008)."
2015.jeptalnrecital-long.7.pdf-Figure3.png;'Welche Farbe hat die Linie, die 'Using attributes' in Abbildung (a) darstellt?';'What is the color of the line representing 'Using attributes' in Figure (a)?';Rot;Red;Rot;Red;Simple Retrieval;'
2015.jeptalnrecital-long.7.pdf-Figure3.png;Wie hoch ist der Wert der roten Linie bei 20 BURN_IN-Iterationen in Abbildung (a)?;What is the value of the red line at 20 BURN_IN iterations in Figure (a)?;Ungefähr 0,0016;Approximately 0.0016;0,0016;0.0016;Simple Retrieval;'
2015.jeptalnrecital-long.7.pdf-Figure3.png;In Abbildung (a) ist die Wahrscheinlichkeit bei Verwendung von Attributen bei 10 BURN_IN-Iterationen höher als bei 100 BURN_IN-Iterationen. Wie groß ist die Differenz zwischen diesen beiden Werten?;In Figure (a), the probability when using attributes is higher at 10 BURN_IN iterations than at 100 BURN_IN iterations. What is the difference between these two values?;Ungefähr 0,00135;Approximately 0.00135;0,00135;0.00135;Simple Calculation;'
2015.jeptalnrecital-long.7.pdf-Figure3.png;Welcher Graph, (a), (b), (c) oder (d), zeigt die größte prozentuale Veränderung zwischen dem Wert 'Mit Attributen' und dem Wert 'Ohne Attribute' bei 100 BURN_IN-Iterationen?;Which graph, (a), (b), (c), or (d), shows the largest percentage change between the 'Using attributes' value and the 'No attribute' value at 100 BURN_IN iterations?;Graph (c);Graph (c);(c);(c);Complex Calculation and Logical Reasoning;'
2015.jeptalnrecital-long.7.pdf-Figure3.png;'Wie wirkt sich laut der Studie die Einführung von Attributen nach 50% der Burn-in-Iterationen auf die Wahrscheinlichkeit von 'kill:dobj' in der Opferrolle aus, wie in Abbildung 3 dargestellt?';'According to the paper, how does the introduction of attributes at 50% of the burn-in iterations affect the probability of 'kill:dobj' in the victim role, as shown in Figure 3?';'Die Einführung von Attributen verringert die Wahrscheinlichkeit von 'kill:dobj' in der Opferrolle. Dies liegt daran, dass ohne Attribute 'Terroristen' oft mit Opfern verwechselt werden, da sie häufig Objekte von 'kill'-Handlungen sind. Die Attribute helfen, Täter von Opfern zu unterscheiden.';'The introduction of attributes decreases the probability of 'kill:dobj' in the victim role.  This is because without attributes 'terrorists' are often confused with victims, as they are frequently the objects of 'kill' actions.  The attributes help to distinguish perpetrators from victims.';Verringert;Decreases;Requires Paper Context;'On voit par exemple à la Figure 3, qui montre l’évolution des probabilités de certains éléments à mesure des itérations de burn in, que la probabilité de la relation 'kill:dobj' diminue dans le rôle correspondant aux victimes, de même que celle de l’entité 'terrorist' dans ce même rôle.'
2015.lilt-12.2.pdf-Figure5.png;'Welche Farbe hat die Linie für 'abstrakt'?';'What color is the line for 'abstract'?';Ziegelrot.;Brick red.;Ziegelrot;Brick red;Simple Retrieval;'
2015.lilt-12.2.pdf-Figure5.png;'Wie groß ist der Unterschied zwischen dem höchsten und dem niedrigsten Punkt der Linie für 'konkret'?';'What is the difference between the highest and lowest point of the line for 'concrete'?';Ungefähr 0,15.;Approximately 0.15.;0,15;0.15;Simple Calculation;'
2015.lilt-12.2.pdf-Figure5.png;'Ist der Wert für 'umgangssprachlich' im ersten Abschnitt höher oder niedriger als der Durchschnitt aller 'umgangssprachlichen' Werte im gesamten Diagramm? Begründe deine Antwort.';Is the value for 'colloquial' in the first section higher or lower than the average of all 'colloquial' values across the graph? Explain your reasoning.;Niedriger.;Lower.;Niedriger;Lower;Complex Calculation and Logical Reasoning;'
2015.lilt-12.2.pdf-Figure5.png;Welche zwei Linien zeigen die größte vertikale Veränderung zwischen dem ersten und dem dritten Abschnitt?;Which two lines show the greatest vertical change between the first and third sections?;Literarisch (blau) und abstrakt (rot).;Literary (blue) and abstract (red).;Literarisch/Abstrakt;Literary/Abstract;Complex Calculation and Logical Reasoning;'
2015.lilt-12.2.pdf-Figure5.png;'Maries Werte für 'abstrakt' und 'literarisch' sind im dritten Abschnitt höher als im ersten. Der Text erwähnt, dass sie sich in diesem Abschnitt an einen ehemaligen Liebhaber erinnert.  Welche emotionale Sprache verwendet sie, um diese Erinnerung auszudrücken (siehe Abbildung 5 und Textauszug)?';'Marie's values for 'abstract' and 'literary' are higher in the third section than in the first. The text mentions that in this section she recalls a former lover. What emotive language does she use to express this recollection (see Figure 5 and text excerpt)?';Marie verwendet eine sehr emotionale und poetische Sprache, um sich an einen Moment mit einem alten Geliebten zu erinnern. Sie beschreibt die Szene mit lebendigen Bildern und intensiven Gefühlen.;Marie uses highly emotive and poetic language to recall a moment with an old lover. She describes the scene with vivid imagery and intense feelings.;Emotionale/poetische Sprache;Emotive/poetic language;Requires Paper Context;"With Marie, too, we find some variation depending on the emotional register of the scene she is recalling or expressing (see Figure 5). In Marie’s first passage (5-11), she remembers in a relatively neutral, matter-of-fact tone some scenes from her aristocratic youth: “we stopped in the colonnade, / And went on in sunlight, into the Hofgarten, / And drank coffee, and talked for an hour.” In her third passage (35-41), she remembers a moment of greater emotional intensity with an old lover:

“Yet when we came back, late, from the Hyacinth garden, / Your arms full, and your hair wet, I could not / Speak, and my eyes failed, I was neither / Living nor dead, and I knew nothing, / Looking into the heart of light, the silence.”"
2015.lilt-12.6.pdf-Figure2.png;'Welche Farbe hat die gestrichelte Linie, die 'Zufall' darstellt?';'What is the color of the dashed line representing 'random'?';Rot.;Red.;Rot;Red;Simple Retrieval;'
2015.lilt-12.6.pdf-Figure2.png;Wie hoch ist die True-Positive-Rate der schwarzen Linie, wenn die False-Positive-Rate 0,2 beträgt?;What is the true positive rate of the black line when the false positive rate is 0.2?;Ungefähr 0.9.;Approximately 0.9.;0.9;0.9;Simple Retrieval;'
2015.lilt-12.6.pdf-Figure2.png;Wie viele Kurven im linken Diagramm haben bei einer Falsch-Positiv-Rate von 0,2 eine höhere Richtig-Positiv-Rate als Zufall?;How many curves in the left graph have a higher true positive rate than random at a false positive rate of 0.2?;8;8;8;8;Simple Calculation;'
2015.lilt-12.6.pdf-Figure2.png;Im rechten Diagramm: Ist die durchschnittliche Richtig-Positiv-Rate aller Kurven (ohne Zufall) bei einer Falsch-Positiv-Rate von 0,4 größer als 0,7?;In the right graph: Is the average true positive rate of all curves (excluding random) at a false positive rate of 0.4 greater than 0.7?;Ja.;Yes.;Ja;Yes;Complex Calculation and Logical Reasoning;'
2015.lilt-12.6.pdf-Figure2.png;'Der Text erwähnt, dass die Feature-Familien 6-9 nur eine geringe Verbesserung bringen. Welche visuellen Beweise in den ROC-Kurven unterstützen diese Behauptung, insbesondere in Bezug auf die 'Konfidenz des Modells'?';'The text mentions that feature families 6-9 provide negligible improvement. What visual evidence in the ROC curves supports this claim, specifically concerning the 'confidence of the model'?';Die ROC-Kurven für Feature-Sets einschließlich 6-9 liegen sehr nah an der Kurve für Feature-Set 1-5, insbesondere bei niedrigen Falsch-Positiv-Raten. Diese visuelle Nähe deutet auf eine minimale Verbesserung der Fähigkeit des Modells hin, positive Instanzen sicher zu klassifizieren.;The ROC curves for feature sets including 6-9 are very close to the curve for feature set 1-5, especially at low false positive rates. This visual proximity suggests minimal improvement in the model's ability to confidently classify positive instances.;Minimale Verbesserung;Minimal improvement;Requires Paper Context;'From the two ROC curves, we can observe that on the medium-size data set, the model achieves very good performance (large AUC areas) in all settings. In both figures, we can see that the use of feature families 6-9 barely improve the confidence of the model over the results of the first five. In the expriments reported below, we only use the feature families 1-5.'
2016.jeptalnrecital-jep.43.pdf-Figure5.png;Welche Farbe hat die Linie, die die präoperativen Daten darstellt?;What color is the line representing the pre-op data?;Schwarz;Black;Schwarz;Black;Simple Retrieval;'
2016.jeptalnrecital-jep.43.pdf-Figure5.png;Ist der Schalldruckpegel der präoperativen Daten bei 1000 Hz höher oder niedriger als bei 2000 Hz?;Is the sound pressure level of the pre-op data at 1000 Hz higher or lower than at 2000 Hz?;Höher;Higher;Höher;Higher;Simple Calculation;'
2016.jeptalnrecital-jep.43.pdf-Figure5.png;In welchem Frequenzbereich ist der Unterschied im Schalldruckpegel zwischen den prä- und postoperativen Daten am größten (z. B. 1000-2000 Hz, 2000-3000 Hz usw.)?;In what frequency range is the difference in sound pressure level between the pre-op and post-op data the greatest (e.g., 1000-2000 Hz, 2000-3000 Hz, etc.)?;4500-5500 Hz;4500-5500 Hz;4500-5500 Hz;4500-5500 Hz;Simple Calculation;'
2016.jeptalnrecital-jep.43.pdf-Figure5.png;Was ist der ungefähre durchschnittliche Schalldruckpegel der präoperativen Daten zwischen 2000 Hz und 4000 Hz in dB?;What is the approximate average sound pressure level of the pre-op data between 2000 Hz and 4000 Hz in dB?;Ungefähr 18 dB;Approximately 18 dB;18 dB;18 dB;Complex Calculation and Logical Reasoning;'
2016.jeptalnrecital-jep.43.pdf-Figure5.png;Der Patient berichtet von einer Verbesserung seiner Stimmqualität, insbesondere in den hohen Tönen. Welche Beobachtungen in Abbildung 5 könnten diese subjektive Einschätzung unterstützen, und welche zusätzlichen Faktoren, die im Text erwähnt werden, könnten ebenfalls zu dieser Verbesserung beitragen?;The patient reports an improvement in his voice quality, specifically in the high notes. What observations in Figure 5 could support this subjective assessment, and what additional factors mentioned in the text might also contribute to this improvement?;Die postoperative (rote) Linie liegt bei Frequenzen über etwa 5000 Hz etwas höher als die präoperative (schwarze) Linie, was der Verbesserung der hohen Töne entsprechen könnte. Der Text erwähnt auch eine verringerte supraglottische Verspannung und das Verschwinden von Sekreten und Entzündungen als weitere Faktoren.;The post-op (red) line is slightly higher than the pre-op (black) line at frequencies above approximately 5000 Hz, which could correspond to the improved high notes. The text also mentions reduced supra-glottic tightening and the disappearance of secretions and inflammation as contributing factors.;Höhere rote Linie über 5000 Hz, verringerte Verspannung, Verschwinden von Sekreten/Entzündungen;Higher red line above 5000 Hz, reduced tightening, disappearance of secretions/inflammation;Caption Question/Complex Calculation and Logical Reasoning;"FIGURE 5 : superposition des spectres à long terme, en pré-op. (noir) et post-op. (rouge)

En post-opératoire le patient signale une amélioration du timbre de sa voix qu’il qualifie de plus claire, et une plus grande aisance dans les aigus de sa voix chantée. L’examen laryngé montre une diminution du serrage supra-glottique au niveau des bandes ventriculaires en phonation et une disparition des sécrétions et de l’inflammation."
2016.jeptalnrecital-jep.49.pdf-Figure3.png;Welche Farbe repräsentiert die Datenreihe 'a=0.3'?;What color represents the data series labeled 'a=0.3'?;Grün;Green;Grün;Green;Simple Retrieval;'
2016.jeptalnrecital-jep.49.pdf-Figure3.png;Wie hoch sind die kumulierten Kosten für 'a=0.0' bei 200 User-Äußerungen?;What are the cumulative costs for 'a=0.0' at 200 user utterances?;Ungefähr 200;Approximately 200;200;200;Simple Retrieval;'
2016.jeptalnrecital-jep.49.pdf-Figure3.png;Wie hoch ist die Summe der kumulierten Kosten für 'a=0.3' und 'a=0.5' bei 700 User-Äußerungen?;What is the sum of the cumulative costs for 'a=0.3' and 'a=0.5' at 700 user utterances?;Ungefähr 1050 (500 für a=0.3 und 550 für a=0.5);Approximately 1050 (500 for a=0.3 and 550 for a=0.5);1050;1050;Simple Calculation;'
2016.jeptalnrecital-jep.49.pdf-Figure3.png;Bei wie vielen User-Äußerungen übersteigen die kumulierten Kosten von 'AskAnnotation' erstmals 1000?;At how many user utterances do the cumulative costs of 'AskAnnotation' first exceed 1000?;Ungefähr 580;Approximately 580;580;580;Simple Retrieval;'
2016.jeptalnrecital-jep.49.pdf-Figure3.png;Im Text wird ein Kompromiss zwischen Benutzeraufwand und Modelleffektivität erwähnt. Welche Strategie in Abbildung 3 scheint basierend auf dem bereitgestellten Text den besten Kompromiss zu bieten, indem sie die Kosten minimiert und gleichzeitig die kumulierten Kosten relativ niedrig hält, und warum?;The text mentions a trade-off between user effort and model effectiveness. Based on Figure 3 and the provided text, which strategy in the figure appears to offer the best balance, minimizing cost while maintaining reasonably low cumulative cost, and why?;Strategien mit a=0.3, 0.5 oder 0.7 bieten einen vernünftigen Kompromiss. 'AskAnnotation' hat die niedrigste Ineffizienz, aber die höchsten Kosten, während 'YesNoQuestions' niedrige Kosten, aber höhere Ineffizienz hat. Exp3-Strategien, insbesondere a=0.5, gleichen Kosten und Effektivität aus und bieten niedrigere kumulierte Kosten als 'AskAnnotation' bei moderater Leistung, wie aus dem Text um Abbildung 4 hervorgeht, wo die Rolle von Gamma beim Ausbalancieren dieses Kompromisses betont wird.;Strategies with a=0.3, 0.5, or 0.7 offer a reasonable trade-off. 'AskAnnotation' has the lowest inefficiency but highest cost, while 'YesNoQuestions' has low cost but higher inefficiency. Exp3 strategies, especially a=0.5, balance cost and effectiveness, providing lower cumulative costs than 'AskAnnotation' with moderate performance, as suggested by the text around Figure 4, where gamma's role in balancing this trade-off is emphasized.;a=0.3, 0.5, 0.7;a=0.3, 0.5, 0.7;Caption Question/Complex Calculation and Logical Reasoning;'Dans la figure 3 on compare l’effet de γ sur la stratégie apprise par Exp3 en terme d’effort utilisateur cumulé. Les stratégies AskAnnotation et YesNoQuestions (stratégies réalisant la même action à chaque tour) sont introduites ici à des fin de comparaison comme méthodes de référence. Nous considérons les performances pour γ 0, 0, 3, 0, 5, 0, 7, 1 . Nous pouvons observer que la stratégie _2 {_ _}_ **AskAnnotation est la plus coûteuse, suivie par YesNoQuestions. Faire varier le paramètre γ semble** donc avoir l’effet escompté sur l’apprentissage de la stratégie d’adaptation. Ainsi, plus γ est grand, moins le coût a un impact sur l’apprentissage. De ce fait, lorsque celui-ci est totalement ignoré dans la fonction de perte (γ = 1, 0), l’algorithme Exp3 a tendance à favoriser les actions les plus coûteuses car elles permettent de réduire significativement la mesure d’inefficacité du modèle. Ainsi, γ offre un moyen simple et direct pour régler le compromis entre l’effort de l’utilisateur et l’efficacité du modèle pour une application donnée.'
2018.lilt-16.1.pdf-Figure4.png;Welche Farben werden für die Linien im Diagramm verwendet?;What colors are used for the lines in the graph?;Rot und Gelb.;Red and Yellow.;Rot, Gelb;Red, Yellow;Simple Retrieval;'
2018.lilt-16.1.pdf-Figure4.png;Wie viele Linien kreuzen die 0,7-Marke auf der y-Achse?;How many lines cross the 0.7 mark on the y-axis?;Alle.;All of them.;Alle;All;Simple Calculation;'
2018.lilt-16.1.pdf-Figure4.png;Bei welchem Wert auf der x-Achse erreichen die gelben Linien ihren niedrigsten Punkt und beginnen wieder anzusteigen?;At what value on the x-axis do the yellow lines reach their lowest point and start rising again?;Ungefähr bei 15.;Around 15.;15;15;Simple Retrieval;'
2018.lilt-16.1.pdf-Figure4.png;'Die Abbildung 4 zeigt die Ergebnisse für LSTM (rot) und GRU (gelb) Architekturen. Welche Architektur erzielt im 'Long-Term Dependency' Test bessere Ergebnisse und warum?';'Figure 4 shows the results for LSTM (red) and GRU (yellow) architectures.  Which architecture performs better in the 'Long-Term Dependency' test and why?';LSTM schneidet besser ab. GRU zeigt zwar anfänglich eine höhere Genauigkeit, doch die Leistung fällt gegen Ende der Sequenz (um x = 18) deutlich ab. LSTM behält über den gesamten Zeitraum eine konsistentere, höhere Genauigkeit bei und zeigt somit eine bessere Handhabung von Langzeitabhängigkeiten.;LSTM performs better.  While GRU initially shows higher accuracy, its performance degrades significantly towards the end of the sequence (around x = 18). LSTM maintains a more consistent higher accuracy throughout, demonstrating better long-term dependency handling.;LSTM;LSTM;Caption Question/Complex Calculation and Logical Reasoning;'
2019.jeptalnrecital-deft.6.pdf-Figure3.png;Welche Farbe hat die Linie, die den MAP darstellt?;What color is the line representing MAP?;Rot;Red;Rot;Red;Simple Retrieval;'
2019.jeptalnrecital-deft.6.pdf-Figure3.png;Was ist der Unterschied zwischen den P@N-Werten bei 20 % und 50 %?;What is the difference between the P@N values at 20% and 50%?;Ungefähr 3;Approximately 3;3;3;Simple Calculation;'
2019.jeptalnrecital-deft.6.pdf-Figure3.png;Bei welchem Prozentsatz ist die Summe aus MAP und P@N am größten?;At what percentage is the sum of MAP and P@N the greatest?;100%;100%;100%;100%;Complex Calculation and Logical Reasoning;'
2019.jeptalnrecital-deft.6.pdf-Figure3.png;Ist der durchschnittliche P@N-Wert über alle Prozentsätze größer als der durchschnittliche MAP-Wert?;Is the average P@N value across all percentages greater than the average MAP value?;Ja;Yes;Ja;Yes;Complex Calculation and Logical Reasoning;'
2019.jeptalnrecital-deft.6.pdf-Figure3.png;In Abbildung 3 werden die MAP- und P@N-Werte für verschiedene Korpusgrößen dargestellt.  Welche Auswirkungen hat die Korpusgröße auf die Leistung des Autoencoders, wie in Abschnitt 3.1 und der Schlussfolgerung des Artikels beschrieben, und wie lässt sich diese Beobachtung mit den in Abbildung 3 dargestellten Trends in Beziehung setzen?;Figure 3 shows MAP and P@N values for different corpus sizes. How does corpus size affect autoencoder performance as discussed in section 3.1 and the conclusion of the paper, and how does this observation relate to the trends shown in Figure 3?;Ein größerer Trainingskorpus verbessert die Leistung des Autoencoders. Sowohl die MAP- als auch die P@N-Werte steigen in Abbildung 3 im Allgemeinen mit zunehmender Korpusgröße (Prozentsatz). Dies stimmt mit dem Text überein, in dem erwähnt wird, dass der kleine Korpus die Leistung beeinträchtigt.;A larger training corpus improves autoencoder performance. Both MAP and P@N values generally increase as the corpus size (percentage) increases in Figure 3. This aligns with the text, which mentions the small corpus hindering performance.;Verbessert die Leistung;Improves performance;Requires Paper Context;"Nous remarquons que la majorité des systèmes peinent à atteindre les 50% de MAP et de précision. Le modèle basé sur XGBoost donne les meilleurs résultats seul et gagne 3 points en étant associé avec l’auto-encodeur. Seul, ce dernier est assez médiocre, ce qui est lié à la petite taille du corpus d’apprentissage (Figure 3).

# 4 Conclusion

Dans cet article, nous avons présentés nos travaux réalisés dans le cadre de l’édition 2019 du Défi Fouille de Texte (DeFT) pour la tâche 1, qui consistait à retrouver les mots-clés les plus pertinents,

pour une paire de cas clinique/discussion donnée, dans une liste de mots-clés fournie.

Nous avons obtenu des résultats moyens en utilisant des méthodes classiques telles les méthodes à base de boosting et d’arbres de décision, ce qui nous laisse une nette marge de progression. Les méthodes neuronales ont elles démontrés de moins bons résultats, en partie dus à la taille du corpus qui ne permettaient pas un apprentissage optimal. Nous restons cependant, avec notre meilleur système, dans la moyenne des résultats, puisque sur 6 participants, nous nous situons au dessus de la moyenne (38,5%) et de la médiane (40,1%) avec notre système AE-XGBoost (40,4%)."
2019.jeptalnrecital-long.10.pdf-Figure2.png;'Welche Farbe repräsentiert die Datenreihe 'Égal'?';'Which color represents the 'Égal' data series?';'Die Datenreihe 'Égal' wird in Orange/Rot dargestellt.';'The 'Égal' data series is represented by orange/red.';Orange/Rot;Orange/Red;Simple Retrieval;'
2019.jeptalnrecital-long.10.pdf-Figure2.png;Wie hoch ist das Verhältnis des Wertes der dunkelblauen Linie bei x = -2 zu ihrem Wert bei x = 2?;What is the ratio of the value of the dark blue line at x = -2 to its value at x = 2?;Die dunkelblaue Linie (Inférieur) hat bei x = -2 einen Wert von ca. 0,4 und bei x = 2 einen Wert von ca. 0,55. Das Verhältnis beträgt daher ungefähr 0,4 / 0,55 = 0,73.;The dark blue line (Inférieur) has a value of approximately 0.4 at x = -2 and approximately 0.55 at x = 2. The ratio is approximately 0.4 / 0.55 = 0.73.;0,73;0.73;Simple Calculation;'
2019.jeptalnrecital-long.10.pdf-Figure2.png;Ist die Summe der Werte der gelben Linie bei x = -2 und x = 2 größer als der Wert der orangen Linie bei x = 1?;Is the sum of the values of the yellow line at x = -2 and x = 2 greater than the value of the orange line at x = 1?;Ja;Yes;Ja;Yes;Complex Calculation and Logical Reasoning;'
2019.jeptalnrecital-long.10.pdf-Figure2.png;Welche Datenreihe weist die größte absolute Differenz zwischen ihrem höchsten und niedrigsten Wert auf?;Which data series has the largest absolute difference between its highest and lowest values?;Die orange Linie (Égal) hat die größte absolute Differenz. Sie reicht von ca. 0,5 bis 0,8, eine absolute Differenz von ca. 0,3.;The orange line (Égal) has the largest absolute difference, ranging from approximately 0.5 to 0.8, a difference of approximately 0.3.;Orange (Égal);Orange (Égal);Complex Calculation and Logical Reasoning;'
2019.jeptalnrecital-long.10.pdf-Figure2.png;'Die Autoren erwähnen, dass die Ergebnisse 'weit entfernt von der idealen Situation' sind.  Wie hoch sind die Prozentsätze der Lernenden, die die Ausdrücke auf verschiedenen CEFR-Niveaus (Inférieur, Égal, Supérieur) kennen, im Vergleich zu einem hypothetischen Szenario, in dem Lernende unter dem Niveau des Ausdrucks ihn in 0 % der Fälle kennen, diejenigen auf dem gleichen Niveau in 100 % der Fälle und diejenigen darüber in 100 % der Fälle? Verwenden Sie Daten aus dem Text und Abbildung 2, um die Unterschiede zu erklären.';'The authors mention that the results are 'far from the ideal situation.'  What are the percentages of learners knowing the expressions at different CEFR levels (Inférieur, Égal, Supérieur) compared to a hypothetical scenario where learners below the expression's level know it 0% of the time, those at the same level know it 100% of the time, and those above know it 100% of the time? Use data from the text and Figure 2 to explain the differences.';Bei x=0 in Abbildung 2 liegen die Prozentsätze bei: Inférieur: 45,6%, Égal: 70% und Supérieur: 76%. Im idealen Szenario wären es 0%, 100% bzw. 100%. Die beobachteten Ergebnisse zeigen, dass Lernende unterhalb des Expressionsniveaus den Ausdruck immer noch zu einem erheblichen Teil (45,6%) kennen, während Lernende auf oder oberhalb des Zielniveaus keine 100%ige Beherrschung aufweisen.;At x=0 in Figure 2, the percentages are: Inférieur: 45.6%, Égal: 70%, and Supérieur: 76%.  The ideal scenario would be 0%, 100%, and 100% respectively. The observed results show that learners below the expression's level still know it a significant portion of the time (45.6%), while learners at or above the target level don't have 100% mastery.;45,6%/70%/76%;45.6%/70%/76%;Caption Question/Complex Calculation and Logical Reasoning;"FIGURE 2 – Graphique montrant l’annotation optimale sur la base de notre échantillon

Ces résultats paraissent acceptables, même s’ils sont loins de correspondre à la situation idéale décrite ci-dessus. Afin d’obtenir une comparaison plus réaliste, nous nous sommes demandés quels auraient été ces pourcentages si nous avions classés différemment nos expressions. La Figure 2 montre les pourcentages obtenus dans 5 configurations différentes. Celle de base (X = 0) correspond à l’annotation de PolylexFLE. Dans cette configuration, l’expression faire partie est donc classée comme B1. Nous avons ensuite imaginé deux configurations dans lesquelles les expressions auraient été classées un (X = -1), voire deux (X = -2) niveaux en-dessous de la valeur rapportée dans PolylexFLE : ainsi, l’EP faire partie y serait respectivement classée comme A2 ou A1. Il y a aussi deux configurations dans lesquelles les EP auraient été classées un (X = 1), voire deux (X = 2) niveaux au-dessous de la valeur rapportée dans PolylexFLE (cad. pour l’EP faire partie, comme B2 ou C1). Nous pouvons observer sur la Figure 2 que la configuration qui se rapproche le plus des pourcentages optimaux est celle où la difficulté des EP est d’un niveau inférieur à ceux décrits dans PolylexFLE, en particulier pour la classe “Égale”. Il est donc possible que les niveaux estimés dans PolylexFLE soient légèrement sur-évalués. Ce n’est pas totalement surprenant, puisque les expressions tirées de Beacco et ses collègues sont orientés vers la production, alors que notre ressource et notre expérience évaluent les connaissances en réception. Dès lors, le niveau de maîtrise d’une expression en production est logique supérieure à celui de sa maîtrise en réception. Une expérience de plus grande ampleur serait toutefois nécessaire pour confirmer ces résultats préliminaires."
2020.acl-demos.7.pdf-Figure3.png;'Welche Farbe hat die Linie für 'Economy (e.g. ~30.7% Recall)'?';'What color is the line for 'Economy (e.g. ~30.7% Recall)'?';Rot;Red;Rot;Red;Simple Retrieval;'
2020.acl-demos.7.pdf-Figure3.png;'Wie hoch ist der Unterschied im Recall-Wert zwischen 'Our Representation' und 'Enhanced Dependencies' bei 60 benötigten Mustern?';'What is the difference in Recall value between 'Our Representation' and 'Enhanced Dependencies' when 60 patterns are needed?';0,03;0.03;0.03;0.03;Simple Calculation;'
2020.acl-demos.7.pdf-Figure3.png;Wie viele Muster werden von jeder der drei Abhängigkeiten benötigt, um einen Recall von 0.30 zu erreichen?;How many patterns are needed by each of the three dependencies shown to achieve a recall of 0.30?;Basic Dependencies benötigt etwa 90 Muster, Enhanced Dependencies benötigt etwa 70 Muster und Our Representation benötigt etwa 50 Muster.;Basic Dependencies requires about 90 samples, Enhanced Dependencies requires about 70 samples, and Our Representation requires about 50 samples.;90/70/50;90/70/50;Simple Retrieval;'
2020.acl-demos.7.pdf-Figure3.png;Ist die Summe der benötigten Muster für 'Basic Dependencies' und 'Enhanced Dependencies', um einen Recall von 0.30 zu erreichen, größer als die Anzahl der Muster, die für 'Our Representation' benötigt werden, um einen Recall von 0.35 zu erreichen?;Is the sum of the patterns needed for 'Basic Dependencies' and 'Enhanced Dependencies' to reach a recall of 0.30 greater than the number of patterns needed for 'Our Representation' to reach a recall of 0.35?;Nein;No;Nein;No;Complex Calculation and Logical Reasoning;'
2020.acl-demos.7.pdf-Figure3.png;Welche Abhängigkeit im Diagramm benötigt die meisten Muster, um einen Recall von 0,30 zu erreichen, und wie viele Muster sind das?;Which dependency in the graph requires the most patterns to achieve a recall of 0.30, and how many patterns is that?;Basic Dependencies benötigt etwa 110 Muster.;Basic Dependencies requires approximately 110 patterns.;Basic Dependencies, 110;Basic Dependencies, 110;Simple Retrieval;'
2020.acl-main.119.pdf-Figure6.png;Wie hoch ist der SMATCH-Wert auf der y-Achse bei einer Beam-Größe von 1?;What is the SMATCH score on the y-axis when the beam size is 1?;Ungefähr 77,4%;Approximately 77.4%;77,4%;77.4%;Simple Retrieval;'
2020.acl-main.119.pdf-Figure6.png;Wie groß ist der Unterschied zwischen den SMATCH-Werten bei einer Beam-Größe von 1 und 2?;What is the difference between the SMATCH scores at beam size 1 and 2?;Ungefähr 2,6%;Approximately 2.6%;2,6%;2.6%;Simple Calculation;'
2020.acl-main.119.pdf-Figure6.png;Berechnen Sie den durchschnittlichen SMATCH-Wert für die Beam-Größen von 3 bis 7.;Calculate the average SMATCH score for beam sizes from 3 to 7.;Ungefähr 80,1%;Approximately 80.1%;80,1%;80.1%;Complex Calculation and Logical Reasoning;'
2020.acl-main.119.pdf-Figure6.png;Bei welcher Beam-Größe erreicht der SMATCH-Wert sein Minimum und Maximum?  Wie groß ist die Differenz zwischen diesen beiden Werten?;At which beam size does the SMATCH score reach its minimum and maximum? What is the difference between these two values?;Der minimale SMATCH-Wert liegt bei etwa 77,4% bei Beam-Größe 1, und der maximale bei etwa 80,2% bei den Beam-Größen 5, 7 und 8. Die Differenz zwischen diesen Werten beträgt etwa 2,8%.;The minimum SMATCH score is approximately 77.4% at beam size 1, and the maximum is approximately 80.2% at beam sizes 5, 7, and 8. The difference between these two values is approximately 2.8%;2,8%;2.8%;Complex Calculation and Logical Reasoning;'
2020.acl-main.119.pdf-Figure6.png;'Der Text erwähnt, dass eine Beam-Größe von 2 bereits 'die meisten Vorteile' bringt. Unter Berücksichtigung des Rechenaufwands von BERT, unterstützt Abbildung 6 die Verwendung einer kleineren Beam-Größe wie 2 in der Praxis, um Genauigkeit und Geschwindigkeit auszubalancieren? Begründen Sie Ihre Antwort anhand der Abbildung.';'The text mentions that a beam size of 2 already yields 'most of the benefits.' Considering the computational cost associated with BERT, does Figure 6 support using a smaller beam size like 2 in practical applications to balance accuracy and speed?  Justify your answer using the figure.';Ja, Abbildung 6 unterstützt diese Aussage. Der SMATCH-Wert bei Beam-Größe 2 liegt bei etwa 80%, während der maximal erreichte Wert nur bei etwa 80,2% liegt. Die marginale Verbesserung durch die Erhöhung der Beam-Größe über 2 hinaus rechtfertigt möglicherweise nicht den zusätzlichen Rechenaufwand, insbesondere bei zeitkritischen Anwendungen.;Yes, Figure 6 supports this assertion. The SMATCH score at beam size 2 is approximately 80%, while the maximum score achieved is only about 80.2%. The marginal improvement from increasing the beam size beyond 2 may not justify the additional computational cost, especially in time-sensitive applications.;Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.26.pdf-Figure2.png;Welche Form haben die Datenpunkte für Kleidungsstücke im oberen Diagramm?;What shape are the data points for Clothing in the top graph?;Kreise.;Circles.;Kreise;Circles;Caption Question/Simple Retrieval;'
2020.acl-main.26.pdf-Figure2.png;Was ist der Unterschied im BLEU4-Score zwischen Kleidung und Handys bei einem Bewertungsanteil von 20 %?;What is the difference in the BLEU4 score between Clothing and Cell Phones at a 20% proportion of reviews?;Ungefähr 0,01.;Approximately 0.01.;0,01;0.01;Caption Question/Simple Calculation;'
2020.acl-main.26.pdf-Figure2.png;Bei welchem Bewertungsanteil erreicht der ROUGE-L-Score für Kleidung seinen Höchstwert, und wie hoch ist dieser Wert?;At what proportion of reviews does the ROUGE-L score for Clothing reach its peak, and what is this value?;Bei einem Bewertungsanteil von etwa 60 % mit einem Wert von etwa 0,27.;At approximately 60% proportion of reviews, with a value of approximately 0.27.;60%;60%;Caption Question/Simple Retrieval;'
2020.acl-main.26.pdf-Figure2.png;Ist der durchschnittliche BLEU4-Score für Kleidung über alle Bewertungsanteile hinweg höher als der durchschnittliche BLEU4-Score für Handys?  Begründen Sie Ihre Antwort anhand des Diagramms.;Is the average BLEU4 score for Clothing across all proportions of reviews higher than the average BLEU4 score for Cell Phones? Justify your answer by referring to the graph.;Ja, der durchschnittliche BLEU4-Score für Kleidung ist höher. Die Linie für Kleidung liegt über den gesamten x-Achsenbereich konstant über der Linie für Handys.;Yes, the average BLEU4 score for Clothing is higher. The line for Clothing is consistently above the line for Cell Phones across the x-axis.;Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.26.pdf-Figure2.png;In Abschnitt 4.5 wird der Einfluss der Zusammensetzung des Trainingssatzes S auf die Performance des Generators analysiert.  Welche Instanzen werden in diesem Zusammenhang erwähnt, und wie wirkt sich deren Anteil auf die in Abbildung 2 dargestellte Performance im Hinblick auf BLEU4 und ROUGE-L aus?  Beziehen Sie Ihre Antwort explizit auf die Kurvenverläufe in der Abbildung.;Section 4.5 analyzes the influence of the training set S composition on the generator's performance. Which instances are mentioned in this context, and how does their proportion affect the performance shown in Figure 2 regarding BLEU4 and ROUGE-L?  Explicitly refer to the curves in the figure in your answer.;In Abschnitt 4.5 wird der Anteil der Review-Frage-Instanzen (qr) im Trainingssatz S diskutiert.  Mit zunehmendem Anteil von qr-Instanzen verbessert sich die Performance, gemessen an BLEU4 und ROUGE-L, wie der Aufwärtstrend der Linien in beiden Diagrammen zeigt. Diese Verbesserung setzt sich bis etwa 60 % fort, danach verringern sich die Zuwächse, was durch das Abflachen der Kurven belegt wird.;Section 4.5 discusses the proportion of review-question (qr) instances in the training set S. As the proportion of qr instances increases, performance, measured by both BLEU4 and ROUGE-L, improves, as seen by the upward trend of the lines in both graphs.  This improvement continues until around 60%, after which the gains diminish, as evidenced by the plateauing of the curves.;qr-Instanzen verbessern Performance bis 60%;qr instances improve performance until 60%;Requires Paper Context;"**4.5** **Analysis on Instances Composition**

The training instance set for the generator, i.e., S in Algorithm 1, is initialized with QA set and gradually adapted and augmented. Here, we investigate the effect of composition property of S on the gen_erator performance at different epochs. As shown_ in Fig 2, two product categories and two metrics are illustrated, with the gradually changed training instance set S. The proportion of review-question (qr) instances in S starts with 0, and significant performance improvement can be observed while the qr proportion gradually increases. The results stay stable until the qr proportion reach 80%."
2020.acl-main.31.pdf-Figure2.png;Welche Farbe hat die Linie, die TextING repräsentiert?;What color is the line representing TextING?;Blau;Blue;Blau;Blue;Simple Retrieval;'
2020.acl-main.31.pdf-Figure2.png;Wie hoch ist der Genauigkeitswert von TextGCN bei einem Trainingsanteil von 0.2?;What is the accuracy value of TextGCN at a training percentage of 0.2?;Ungefähr 0.68;Approximately 0.68;0.68;0.68;Simple Retrieval;'
2020.acl-main.31.pdf-Figure2.png;'Bei welchem Trainingsanteil erreicht der 'Gain' seinen niedrigsten Wert?';'At what training percentage does the 'Gain' reach its lowest value?';Bei einem Trainingsanteil von 1.;At a training percentage of 1.;1;1;Simple Retrieval;'
2020.acl-main.31.pdf-Figure2.png;Ist die Summe der Genauigkeit von TextING und TextGCN bei einem Trainingsanteil von 0.5 größer als 1,4?;Is the sum of the accuracy of TextING and TextGCN at a training percentage of 0.5 greater than 1.4?;Ja;Yes;Ja;Yes;Simple Calculation;'
2020.acl-main.31.pdf-Figure2.png;Die Bildunterschrift erwähnt, dass mit weniger Trainingsdaten mehr neue Wörter im Test vorkommen. Welche Zahlen aus Tabelle 1 im Papier unterstützen diese Aussage?;The caption mentions that with less training data, there are more new words in the test set. What numbers from Table 1 in the paper support this statement?;Die Daten aus Tabelle 1 unterstützen die Aussage, dass weniger Trainingsdaten zu mehr neuen Wörtern im Testdatensatz führen, wie der hohe Anteil an neuen Wörtern im MR-Datensatz (30,07 %) mit proportional den wenigsten Trainingsdaten zeigt.;The data from Table 1 supports the statement that less training data results in more new words in the test set, as shown by the high proportion of new words in the MR dataset (30.07%) with the least training data proportionally.;30.07%;30.07%;Requires Paper Context;"Dataset # Docs # Training # Test # Classes Max.Vocab Min.Vocab Avg.Vocab Prop.NW

MR 10,662 7,108 3,554 2 46 1 18.46 30.07% R8 7,674 5,485 2,189 8 291 4 41.25 2.60% R52 9,100 6,532 2,568 52 301 4 44.02 2.64% Ohsumed 7,400 3,357 4,043 23 197 11 79.49 8.46%"
2020.acl-main.31.pdf-Figure4.png;Welche Form haben die Datenpunkte in der Abbildung?;What shape are the data points in the figure?;Die Datenpunkte sind ungefüllte Quadrate.;The data points are unfilled squares.;Quadrate;Squares;Simple Retrieval;'
2020.acl-main.31.pdf-Figure4.png;Wie groß ist der Unterschied in der Genauigkeit von MR zwischen Interaktionsschritt 0 und Interaktionsschritt 2?;What is the difference in accuracy of MR between interaction step 0 and interaction step 2?;Der Unterschied in der Genauigkeit für MR zwischen Interaktionsschritt 0 und Schritt 2 beträgt etwa 0,011.;The difference in accuracy for MR between interaction step 0 and step 2 is approximately 0.011.;0.011;0.011;Simple Calculation;'
2020.acl-main.31.pdf-Figure4.png;Wie hoch ist die durchschnittliche Genauigkeit von MR und Ohsumed über alle Interaktionsschritte?;What is the average accuracy of MR and Ohsumed across all interaction steps?;Die durchschnittliche Genauigkeit für MR beträgt etwa 0,796 und für Ohsumed etwa 0,702.;The average accuracy for MR is approximately 0.796 and for Ohsumed is approximately 0.702.;0.796/0.702;0.796/0.702;Complex Calculation and Logical Reasoning;'
2020.acl-main.31.pdf-Figure4.png;Bei welchem Interaktionsschritt erreicht MR die geringste Genauigkeit, und bei welchem Interaktionsschritt erreicht Ohsumed die geringste Genauigkeit?;At which interaction step does MR achieve the lowest accuracy, and at which interaction step does Ohsumed achieve its lowest accuracy?;MR erreicht seine geringste Genauigkeit bei Interaktionsschritt 0. Ohsumed erreicht seine geringste Genauigkeit bei Interaktionsschritt 0.;MR achieves its lowest accuracy at interaction step 0. Ohsumed achieves its lowest accuracy at interaction step 0.;Schritt 0;Step 0;Simple Retrieval;'
2020.acl-main.31.pdf-Figure4.png;In Abbildung 4 wird die Genauigkeit von TextING bei verschiedenen Interaktionsschritten auf den Datensätzen MR und Ohsumed dargestellt. Vergleichen Sie diesen Trend mit den Ergebnissen in Tabelle 2 für TextING auf denselben Datensätzen. Gibt es Übereinstimmungen oder Abweichungen, und wie könnten diese erklärt werden?;Figure 4 shows the accuracy of TextING with varying interaction steps on the MR and Ohsumed datasets. Compare this trend with the results presented in Table 2 for TextING on the same datasets. Are there any consistencies or discrepancies, and how might these be explained?;"Tabelle 2 zeigt die aggregierte Leistung von TextING (79,82 % für MR und 70,42 % für Ohsumed), gemittelt über alle Interaktionsschritte. Abbildung 4 detailliert die Genauigkeit bei jedem Interaktionsschritt und bietet eine detailliertere Perspektive. Der Unterschied liegt in der Granularität der gemeldeten Leistung; Abbildung 4 ist detaillierter, Tabelle 2 ist eine Zusammenfassung.";"Table 2 presents the aggregated performance of TextING (79.82% for MR and 70.42% for Ohsumed), averaged across all interaction steps. Figure 4 details the accuracy at each interaction step, offering a more granular perspective.  The difference lies in the granularity of reported performance; Figure 4 is more detailed, Table 2 is a summary.";Tabelle 2: Aggregierte Leistung;Table 2: Aggregated Performance;Caption Question/Complex Calculation and Logical Reasoning;"Table 2: Test accuracy (%) of various models on four datasets. The mean ± standard deviation of our model is reported according to 10 times run. Note that some baseline results are from (Yao et al., 2019).

Model MR R8 R52 Ohsumed

CNN (Non-static) 77.75 ± 0.72 95.71 ± 0.52 87.59 ± 0.48 58.44 ± 1.06 RNN (Bi-LSTM) 77.68 ± 0.86 96.31 ± 0.33 90.54 ± 0.91 49.27 ± 1.07 fastText 75.14 ± 0.20 96.13 ± 0.21 92.81 ± 0.09 57.70 ± 0.49 SWEM 76.65 ± 0.63 95.32 ± 0.26 92.94 ± 0.24 63.12 ± 0.55 TextGCN 76.74 ± 0.20 97.07 ± 0.10 93.56 ± 0.18 68.36 ± 0.56

Huang et al. (2019)           - 97.80 ± 0.20 94.60 ± 0.30 69.40 ± 0.60

TextING 79.82 ± 0.20 98.04 ± 0.25 95.48 ± 0.19 70.42 ± 0.39 TextING-M 80.19 ± 0.31 98.13 ± 0.12 95.68 ± 0.35 70.84 ± 0.52"
2020.acl-main.59.pdf-Figure6.png;Welche Farbe repräsentiert den MADPL-Algorithmus?;What color represents the MADPL algorithm?;Lila;Purple;Lila;Purple;Simple Retrieval;'
2020.acl-main.59.pdf-Figure6.png;Welchen ungefähren Erfolgswert erreicht IterDPL in Epoche 100?;What approximate success rate does IterDPL achieve at epoch 100?;Ungefähr 0,47;Approximately 0.47;0,47;0.47;Simple Retrieval;'
2020.acl-main.59.pdf-Figure6.png;Bei welcher Epoche erreicht die Erfolgsrate von MADPL ungefähr 0,8?;At which epoch does the success rate of MADPL approximately reach 0.8?;Ungefähr bei Epoche 190;Around epoch 190;190;190;Simple Retrieval;'
2020.acl-main.59.pdf-Figure6.png;Welche zwei Algorithmen haben die größte Ähnlichkeit in ihrer Erfolgsratenentwicklung über die Epochen hinweg?;Which two algorithms have the most similar trend in their success rates over the epochs?;MADPL und CRL, aber nur bis etwa Epoche 100.;MADPL and CRL, but only up until about epoch 100.;MADPL, CRL;MADPL, CRL;Complex Calculation and Logical Reasoning;'
2020.acl-main.66.pdf-Figure4.png;'Welche Farbe hat die Linie, die 'Pinsker\'s' darstellt?';'What color is the line representing 'Pinsker's'?';Blau;Blue;Blau;Blue;Simple Retrieval;'
2020.acl-main.66.pdf-Figure4.png;Bei x=2, welcher Wert ist höher: der Wert der orangen Linie oder der Wert der grünen Linie?;At x=2, which value is higher: the value of the orange line or the value of the green line?;Orange;Orange;Orange;Orange;Simple Calculation;'
2020.acl-main.66.pdf-Figure4.png;Was ist die Summe der Werte aller drei Linien an der Stelle x=1?;What is the sum of the values of all three lines at x=1?;Ungefähr 4,6;Approximately 4,6;4,6;4.6;Complex Calculation and Logical Reasoning;'
2020.acl-main.66.pdf-Figure4.png;Ist die Differenz zwischen dem höchsten und dem niedrigsten Wert der blauen Linie größer als 2?;Is the difference between the highest and lowest value of the blue line greater than 2?;Nein;No;Nein;No;Simple Calculation;'
2020.acl-main.66.pdf-Figure4.png;Der Text erwähnt, dass die Verlustabschneidung die Schranken im Vergleich zur Pinsker-Ungleichung deutlich verbessern kann. Unterstützt Abbildung 4 diese Behauptung? Erklären Sie Ihre Antwort anhand des Verlaufs der Kurven.;The text mentions that loss truncation can significantly improve bounds over Pinsker's inequality. Does Figure 4 support this claim? Explain your answer by referencing the progression of the curves.;Ja, Abbildung 4 unterstützt diese Behauptung. Die orange Kurve ('Loss-truncated') liegt durchgehend unter der blauen Kurve ('Pinsker's'), was auf eine engere Schranke hindeutet. Dies veranschaulicht die durch Verlustabschneidung erzielte Verbesserung.;Yes, Figure 4 supports this claim. The orange curve ('Loss-truncated') is consistently below the blue curve ('Pinsker's'), indicating a tighter bound. This visually demonstrates the improvement achieved by loss truncation.;Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.66.pdf-Figure5.png;'Welche Form hat das Symbol für 'Samp.'?';'What shape is the symbol for 'Samp.'?';Ein Quadrat.;A square.;Quadrat;Square;Caption Question/Simple Retrival;'
2020.acl-main.66.pdf-Figure5.png;Welcher Methode ist der Datenpunkt mit dem höchsten HUSE-Q-Wert zugeordnet, und welcher Methode ist der Datenpunkt mit dem niedrigsten HUSE-D-Wert zugeordnet?;Which method corresponds to the data point with the highest HUSE-Q value, and which method corresponds to the data point with the lowest HUSE-D value?;'Trunc.+reject' hat den höchsten HUSE-Q-Wert, und 'Samp.' hat den niedrigsten HUSE-D-Wert.;'Trunc.+reject' has the highest HUSE-Q value, and 'Samp.' has the lowest HUSE-D value.;Trunc.+reject/Samp.;Trunc.+reject/Samp.;Caption Question/Simple Retrival;'
2020.acl-main.66.pdf-Figure5.png;'Ist die Summe der HUSE-D-Werte für 'top-k' und 'top-p' größer als 1,5?';'Is the sum of the HUSE-D values for 'top-k' and 'top-p' greater than 1.5?';Nein.;No.;Nein;No;Caption Question/Simple Calculation;'
2020.acl-main.66.pdf-Figure5.png;Die Abbildung zeigt, dass Loss Truncation mit Rejection Sampling im Vergleich zu anderen Methoden bessere Ergebnisse in Bezug auf Qualität und Unterscheidbarkeit erzielt. Erläutern Sie anhand des Artikels, warum Rejection Sampling den HUSE-Score verringert, obwohl es die Qualität der generierten Samples verbessert.;The figure shows that Loss Truncation with Rejection Sampling achieves better results in terms of quality and distinguishability compared to other methods. Based on the article, explain why Rejection Sampling decreases the overall HUSE score even though it improves the quality of the generated samples.;Rejection Sampling verbessert die Qualität (HUSE-Q), indem nur Samples mit hoher Konfidenz ausgewählt werden, verringert aber gleichzeitig die Diversität (HUSE-D). Da der HUSE-Score sowohl Qualität als auch Diversität berücksichtigt, überwiegt die Abnahme der Diversität die Verbesserung der Qualität, was zu einem niedrigeren HUSE-Score führt.;Rejection sampling improves quality (HUSE-Q) by selecting only high-confidence samples, but this reduces diversity (HUSE-D). Since HUSE considers both quality and diversity, the decrease in diversity outweighs the quality improvement, leading to a lower overall HUSE score.;Diversität sinkt;Diversity decreases;Requires Paper Context;'Comparing models with high sample quality, loss truncation with rejection sampling improves upon all baselines (including beam search) in terms of raw human quality evaluation (HUSE-Q), and we see that the Pareto frontier of truncation and rejection sampling (which can be achieved via ensembling) dominates the baselines on both quality and diversity (Figure 5). Rejection sampling decreases overall HUSE score because it is designed to only return high quality samples (i.e., high HUSE-Q): this comes at the cost of reduced diversity, so overall HUSE score suffers.'
2020.acl-main.76.pdf-Figure6.png;Welche Farbe hat die Linie 'biLMrrk'?;What color is the 'biLMrrk' line?;Cyan oder Hellblau.;Cyan or light blue.;Cyan;Cyan;Simple Retrieval;'
2020.acl-main.76.pdf-Figure6.png;Wie hoch ist der Wert für T-TAsts bei 20 Wörtern?;What is the value of T-TAsts at 20 words?;Ungefähr 2ms;Approximately 2ms;2ms;2ms;Simple Retrieval;'
2020.acl-main.76.pdf-Figure6.png;Bei welcher Wortanzahl schneiden sich die Linien für biLMsts und T-TArrk?;At what number of words do the lines for biLMsts and T-TArrk intersect?;Ungefähr 10 Wörter.;Approximately 10 words.;10;10;Simple Retrieval;'
2020.acl-main.76.pdf-Figure6.png;Wie groß ist der Unterschied in der benötigten Zeit zwischen biLMrrk und biLMsts bei 60 Wörtern (in ms)?;What is the difference in time taken between biLMrrk and biLMsts at 60 words (in ms)?;Unter 1ms.;Under 1ms.;<1ms;<1ms;Simple Calculation;'
2020.acl-main.76.pdf-Figure6.png;Anhang B.2 erwähnt die Ausführungszeiten in einer GPU-erweiterten Umgebung. Basierend auf Abbildung 6 und dem Text in Anhang B.2: Wie verhält sich die Steigerung der Ausführungszeit von biLM im Vergleich zu T-TA, wenn die Satzlänge von 20 auf 60 Wörter erhöht wird?;Appendix B.2 mentions runtimes in a GPU-augmented environment. Based on Figure 6 and the text in Appendix B.2: How does the increase in runtime for biLM compare to the increase in runtime for T-TA when the sentence length increases from 20 to 60 words?;Die Ausführungszeit von biLM steigt um ca. 21ms, während die Ausführungszeit von T-TA nur um ca. 1ms steigt. Der Anstieg bei biLM ist deutlich größer.;biLM's runtime increases by approximately 21ms, while T-TA's runtime increases by approximately 1ms. The increase for biLM is substantially larger.;biLM Anstieg größer;biLM increase larger;Caption Question/Complex Calculation and Logical Reasoning;'Additionally, we similarly measure the runtimes in a GPU-augmented environment (using GeForce GTX 1080 Ti). Figure 6 shows the average runtimes of the biLM and the T-TA for the number of words in a sentence. In our 20-word standard in the STS task, the T-TA takes approximately 2.51 ms, whereas biLM takes approximately 4.72 ms, showing that the T-TA is 1.88 times faster than the biLM. Compared to the CPU-only environment, the speed difference is significantly reduced due to the support offered by the GPU. Considering Figure 4, however, the CPU-only environment and GPUaugmented environment show a similar tendency: the longer the sentence is, the more significant the difference in the runtime between the T-TA and the biLM.'
2020.acl-main.92.pdf-Figure7.png;Welche Farbe hat die Linie, die MathQA-test repräsentiert?;What color is the line representing MathQA-test?;Die Linie, die MathQA-test repräsentiert, ist hellgrün.;The line representing MathQA-test is light green.;Hellgrün;Light green;Simple Retrieval;'
2020.acl-main.92.pdf-Figure7.png;Welche Linie hat bei 0,55 einen höheren Wert auf der y-Achse: ASDiv-test oder MathQA-test?;Which line has a higher value on the y-axis at 0.55: ASDiv-test or MathQA-test?;ASDiv-test hat bei 0,55 einen höheren Wert.;ASDiv-test has a higher value at 0.55.;ASDiv-test;ASDiv-test;Simple Calculation;'
2020.acl-main.92.pdf-Figure7.png;Was ist der Durchschnittswert aller vier Linien bei einem Lexikonnutzungswert von 0,7?;What is the average value of all four lines at a lexicon usage diversity of 0.7?;Der ungefähre Durchschnittswert bei 0,7 ist 4.;The approximate average value at 0.7 is 4.;4;4;Complex Calculation and Logical Reasoning;'
2020.acl-main.92.pdf-Figure7.png;Ist die Summe der Werte von ASDiv-test und ASDiv-A-test bei 0,6 größer als die Summe der Werte von MathQA-test und MathQA-C-test bei 0,6?;Is the sum of the values of ASDiv-test and ASDiv-A-test at 0.6 greater than the sum of the values of MathQA-test and MathQA-C-Test at 0.6?;Ja, die Summe von ASDiv-test und ASDiv-A-test bei 0,6 ist größer als die Summe von MathQA-test und MathQA-C-test bei 0,6.;Yes, the sum of ASDiv-test and ASDiv-A-test at 0.6 is greater than the sum of MathQA-test and MathQA-C-test at 0.6.;Ja;Yes;Complex Calculation and Logical Reasoning;'
2020.acl-main.92.pdf-Figure7.png;Inwiefern untermauert Abbildung 7 die im Text erwähnte Aussage, dass die CLD von MathQA im Testsatz im Vergleich zu anderen Korpora niedrig ist? Welche Auswirkungen könnte dieser Unterschied auf die Bewertung von MWP-Solvern haben?;How does Figure 7 support the statement in the text that the CLD of MathQA within the test set is low compared to other corpora? What implications might this difference have on the evaluation of MWP solvers?;Abbildung 7 zeigt, dass die mittlere CLD für MathQA-test (0,27) viel niedriger ist als für ASDiv-test und ASDiv-A-test (beide 0,57). Diese geringere Diversität innerhalb des MathQA-Testsatzes könnte die Leistung von MWP-Solvern aufblähen, da die Testaufgaben möglicherweise nicht repräsentativ für ein breiteres Spektrum von Aufgabentypen sind.;Figure 7 shows that the mean CLD for MathQA-test (0.27) is much lower than for ASDiv-test and ASDiv-A-test (both 0.57). This lower diversity within the MathQA test set might inflate the performance of MWP solvers, as the test problems may not be representative of a broader range of problem types.;0,27 vs. 0,57;0.27 vs. 0.57;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.94.pdf-Figure6.png;Welche Farbe hat die Linie für 'ja'?;What color is the line for 'ja'?;Die Linie für 'ja' ist rot gepunktet.;The line for 'ja' is dotted red.;Rot gepunktet;Dotted red;Simple Retrieval;'
2020.acl-main.94.pdf-Figure6.png;Ist der BLI (mrr) Wert für 'fr' bei Fenstergröße 7 im 'top500'-Diagramm höher als im 'bottom500'-Diagramm?;Is the BLI (mrr) value for 'fr' at window size 7 higher in the 'top500' graph than in the 'bottom500' graph?;Ja, der BLI (mrr) Wert für 'fr' bei Fenstergröße 7 ist im 'top500'-Diagramm höher.;Yes, the BLI (mrr) value for 'fr' at window size 7 is higher in the 'top500' graph.;Ja;Yes;Simple Calculation;'
2020.acl-main.94.pdf-Figure6.png;Was ist der durchschnittliche BLI (mrr) Wert für 'de' und 'ru' im 'top500'-Diagramm bei Fenstergröße 20?;What is the average BLI (mrr) value for 'de' and 'ru' in the 'top500' graph at window size 20?;Der durchschnittliche BLI (mrr) Wert für 'de' und 'ru' im 'top500'-Diagramm bei Fenstergröße 20 beträgt ca. 0,45.;The average BLI (mrr) value for 'de' and 'ru' in the 'top500' graph at window size 20 is approximately 0.45.;0.45;0.45;Simple Calculation;'
2020.acl-main.94.pdf-Figure6.png;Bei welcher Sprache ist im 'bottom500'-Diagramm der Unterschied im BLI (mrr) Wert zwischen den Fenstergrößen 2 und 20 am größten?;Which language in the 'bottom500' graph shows the largest difference in BLI (mrr) value between window sizes 2 and 20?;Die Sprache mit dem größten Unterschied im BLI (mrr) Wert zwischen den Fenstergrößen 2 und 20 im 'bottom500'-Diagramm ist 'fr'.;The language with the largest difference in BLI (mrr) value between window sizes 2 and 20 in the 'bottom500' graph is 'fr'.;fr;fr;Simple Calculation;'
2020.acl-main.94.pdf-Figure6.png;Wie verhält sich die BLI-Performance für die 500 seltensten Wörter im Japanischen im Vergleich zu anderen Sprachen bei verschiedenen Fenstergrößen (Abbildung 6), und welche Erklärung liefert die Studie dafür?;How does the BLI performance for the bottom 500 frequent words in Japanese compare to other languages across different window sizes (Figure 6), and what explanation does the study provide?;Die BLI-Werte für die 500 häufigsten Wörter im Japanischen (dargestellt durch die gepunktete rote Linie) sind durchweg niedriger als die der anderen Sprachen, insbesondere bei größeren Fenstergrößen. Die Studie vermutet, dass dies daran liegen könnte, dass seltene Wörter einen begrenzten Kontext haben, was Rauschen und Domänenunterschiede verstärkt und zu einer ungenauen Ausrichtung führt.;The BLI scores for the bottom 500 frequent words in Japanese (represented by the dotted red line) are consistently lower than those of other languages, especially at larger window sizes. The paper suggests this might be due to rare words having limited context, amplifying noise and domain differences, leading to inaccurate alignment.;Niedriger;Lower;Caption Question/Complex Calculation and Logical Reasoning;'
2007.sigdial-1.23.pdf-Figure5.png;Welche Beschriftung befindet sich unterhalb des linken Balkens?;What label is below the left bar?;real;real;real;real;Simple Retrieval;'
2007.sigdial-1.23.pdf-Figure5.png;Was ist die Summe der Prozentsätze von S_confirm im linken Stapel und S_other im rechten Stapel?;What is the sum of the percentages of S_confirm in the left stack and S_other in the right stack?;Ungefähr 65%;Approximately 65%;65%;65%;Simple Calculation;'
2007.sigdial-1.23.pdf-Figure5.png;Ist die Summe der Prozentsätze von S_requestinfo und S_confirm in beiden Stapeln größer als 50 %?;Is the sum of the percentages of S_requestinfo and S_confirm across both stacks greater than 50%?;Ja;Yes;Ja;Yes;Simple Calculation;'
2007.sigdial-1.23.pdf-Figure5.png;Der Text erwähnt eine Abschlussrate von 80,7 % für die Probanden. Stimmt der Anteil der S_inform-Dialoge im Diagramm mit dieser Erfolgsrate überein, wenn man bedenkt, dass S_inform den größten Anteil der Systemdialogakte bei den Probanden darstellt?;The text mentions a task completion rate of 80.7% for the subjects. Does the proportion of S_inform dialog acts shown in the diagram appear consistent with this success rate, considering that S_inform represents the largest proportion of system dialog acts for the subjects?;Das Diagramm zeigt, dass etwa 30% der Systemdialogakte bei den Probanden S_inform sind. Obwohl dies der größte Anteil ist, korreliert dies nicht direkt mit der Aufgabenerfüllungsrate von 80,7%. Der bereitgestellte Textauszug deutet auf eine komplexe Beziehung zwischen Dialogakten und Aufgabenerfüllung hin, nicht auf eine direkte Übereinstimmung.;The diagram shows approximately 30% of system dialog acts for subjects are S_inform.  While the largest proportion, this doesn't directly correlate with the 80.7% task completion rate. The provided text excerpt suggests a complex relationship between dialog acts and task completion, not a direct correspondence.;Nein;No;Requires Paper Context;'Using automatic indicators to estimate task completion as discussed in Section 5, we find that the completion rate for subjects is 80.7%, while for users it is only 67%.'
2007.sigdial-1.23.pdf-Figure6.png;'Welche Farbe repräsentiert die Datenreihe 'real'?';'What color represents the data series 'real'?';'Hellgrau repräsentiert die Datenreihe 'real'.';'Light gray represents the 'real' data series.';'Hellgrau';'Light gray';Simple Retrieval;'
2007.sigdial-1.23.pdf-Figure6.png;'Wie hoch ist der Wert für 'subject' bei 'rejection%'?';'What is the value for 'subject' at 'rejection%'?';'Der Wert für 'subject' bei 'rejection%' liegt bei etwa 1,05.';'The value for 'subject' at 'rejection%' is approximately 1.05.';'1,05';'1.05';Simple Retrieval;'
2007.sigdial-1.23.pdf-Figure6.png;'Wie hoch ist der Durchschnittswert für 'subject' über beide Kategorien ('rejection%' und 'confScore') hinweg?';'What is the average value for 'subject' across both categories ('rejection%' and 'confScore')?';'Der Durchschnittswert für 'subject' über beide Kategorien liegt bei etwa 1,075.';'The average value for 'subject' across both categories is approximately 1.075.';'1,075';'1.075';Simple Calculation;'
2007.sigdial-1.23.pdf-Figure6.png;Was ist die Differenz zwischen dem höchsten und dem niedrigsten Wert im Diagramm?;What is the difference between the highest and lowest values shown in the chart?;Die Differenz zwischen dem höchsten und dem niedrigsten Wert beträgt etwa 0,1.;The difference between the highest and lowest values is approximately 0.1.;'0,1';'0.1';Simple Calculation;'
2007.sigdial-1.23.pdf-Figure6.png;In Anbetracht der in Abbildung 6 dargestellten Werte und der im Artikel beschriebenen Gesamtabschlussraten, welche Schlussfolgerungen lassen sich über die beobachteten Trends der Spracherkennungsqualität ziehen, und was könnten diese Unterschiede für reale Umgebungen im Vergleich zu Laborbedingungen bedeuten?;Considering the values depicted in Figure 6 and the overall completion rates discussed in the paper, what conclusions can be drawn about the observed trends in speech recognition quality, and what might these differences imply about real-world vs. lab settings?;Abbildung 6 zeigt ähnliche Spracherkennungsqualität zwischen realen Benutzern und Probanden im Labor. Höhere Aufgabenerfüllungsraten für Probanden (80,7% vs. 67%) deuten jedoch darauf hin, dass andere Faktoren wie Umgebungsablenkungen und emotionaler Zustand die Leistung in der realen Welt stärker beeinflussen als im Labor.;Figure 6 indicates similar speech recognition quality between real users and subjects in lab settings. However, higher task completion rates for subjects (80.7% vs. 67%) suggest that other factors like environmental distractions and emotional state affect real-world performance more than lab settings.;Ähnliche Spracherkennungsqualität, aber höhere Aufgabenerfüllung im Labor.;Similar speech recognition quality, but higher task completion in lab.;Requires Paper Context;'Using automatic indicators to estimate task completion as discussed in Section 5, we find that the completion rate for subjects is 80.7%, while for users it is only 67%. There are also significantly more S other in dialogs with users than with subjects. We did not find any significant difference in the number of system requests (S requestinfo) or confirmations (S confirm). Figure 6 shows the results for speech recognition quality, using scaled mean values as in Figure 3. There are no statistically significant differences between the number of rejected user turns or the average confidence scores of the speech recognizer.'
2007.sigdial-1.32.pdf-Figure3.png;Welche Beschriftung steht in der Legende neben dem schwarzen Balken?;What label is next to the black bar in the legend?;Nicht dringend;Non-urgent;Nicht dringend;Non-urgent;Simple Retrieval;'
2007.sigdial-1.32.pdf-Figure3.png;Was ist die Differenz der Antwortzeiten zwischen dringenden und nicht dringenden Aufgaben bei Subjektpaar 3?;What is the difference in response times between urgent and non-urgent tasks for Subject Pair 3?;Ungefähr 0 Sekunden;Approximately 0 seconds;0;0;Simple Calculation;'
2007.sigdial-1.32.pdf-Figure3.png;Welches Subjektpaar hat die kürzeste durchschnittliche Antwortzeit (berechnet aus dringenden und nicht dringenden Aufgaben)?;Which subject pair has the shortest average response time (calculated from both urgent and non-urgent tasks)?;Subjektpaar 3;Subject Pair 3;Subjektpaar 3;Subject Pair 3;Complex Calculation and Logical Reasoning;'
2007.sigdial-1.32.pdf-Figure3.png;Ist die Summe der Antwortzeiten für dringende Aufgaben bei den Subjektpaaren 1 und 2 größer oder kleiner als die Summe der Antwortzeiten für nicht dringende Aufgaben bei den Subjektpaaren 4 und 5?;Is the sum of the response times for urgent tasks for Subject Pairs 1 and 2 greater or less than the sum of the response times for non-urgent tasks for Subject Pairs 4 and 5?;Größer als;Greater than;Größer;Greater;Complex Calculation and Logical Reasoning;'
2007.sigdial-1.32.pdf-Figure3.png;In der Studie von Tsimhoni et al. (2001) wurde eine durchschnittliche Reaktionszeit von 1,3 Sekunden festgestellt. Betrachtet man die Daten in Abbildung 3, welche mögliche Erklärung aus dem Text trifft am ehesten zu, warum die Reaktionszeiten in dieser Studie länger sind?;The study by Tsimhoni et al. (2001) found an average response time of 1.3 seconds. Looking at the data in Figure 3, which possible explanation offered in the text is most likely for why the response times in this study are longer?;Der Text deutet an, dass, obwohl die Beamten in ein Gespräch verwickelt waren und den visuellen Reizen möglicherweise nicht ihre volle Aufmerksamkeit schenkten, es wahrscheinlicher ist, dass sie sich an Gesprächskonventionen hielten und auf eine geeignete Pause warteten, bevor sie antworteten.;The paper suggests that while the officers being engaged in conversation and not paying close attention is a possibility, it's more likely they were adhering to conversational conventions, waiting for an appropriate pause before responding.;Gesprächskonventionen;Conversational conventions;Requires Paper Context;'Figure 3 shows the plot of average response times for different participants. The response times are slower (average around 2.8 seconds for all cases) than reported by Tsimhoni et al. (2001) (average 1.3 seconds), who investigated reading messages on a heads-up display while driving. A reasonable explanation for this is that in our experiment the officer was engaged in verbal communication with the dispatcher and did not pay as close attention to the messages as the participants in the study of Tsimhoni et al. Even more likely, the officer was complying with established conventions in human-human dialogue, and so waited for a suitable point in the interaction. This waiting for an opportunity to speak slowed down his/her response.'
2015.jeptalnrecital-demonstration.6.pdf-Figure1.png;Welche Kategorie enthält die meisten LOCATION-Entitäten?;Which category contains the most LOCATION entities?;'Die Kategorie '#To find' enthält die meisten LOCATION-Entitäten (246).';'The '#To find' category contains the most LOCATION entities (246).';#To find;#To find;Simple Retrieval;'
2015.jeptalnrecital-demonstration.6.pdf-Figure1.png;'Was ist die Summe der ORGANIZATION- und PERSON-Entitäten in der Kategorie '#Correct-Found'?';'What is the sum of ORGANIZATION and PERSON entities in the '#Correct-Found' category?';'Die Summe der ORGANIZATION- und PERSON-Entitäten in der Kategorie '#Correct-Found' beträgt 103.';'The sum of ORGANIZATION and PERSON entities in the '#Correct-Found' category is 103.';103;103;Simple Calculation;'
2015.jeptalnrecital-demonstration.6.pdf-Figure1.png;'Wie viele Entitäten gibt es insgesamt in der Kategorie '#Noise'?';'How many total entities are there in the '#Noise' category?';'Es gibt insgesamt 19 Entitäten in der Kategorie '#Noise'.';'There are 19 total entities in the '#Noise' category.';19;19;Simple Calculation;'
2015.jeptalnrecital-demonstration.6.pdf-Figure1.png;'Wie viel Prozent der gefundenen Entitäten sind in der Kategorie '#Correct-Found' im Vergleich zur Gesamtzahl der Entitäten?';'What percentage of the total entities found are in the '#Correct-Found' category?';'Ungefähr 45% der gefundenen Entitäten befinden sich in der Kategorie '#Correct-Found'.';'Approximately 45% of the total entities found are in the '#Correct-Found' category.';45%;45%;Complex Calculation and Logical Reasoning;'
2015.jeptalnrecital-demonstration.6.pdf-Figure1.png;'Abbildung 1 zeigt die Anzahl der korrekt gefundenen, nicht gefundenen und fälschlicherweise gefundenen Named Entities. Inwiefern deckt sich die Verteilung in der Abbildung mit der Aussage im Text, dass 'die Evaluierung eine gute Genauigkeit (F-Score von 94,90%) zeigt'?';'Figure 1 shows the quantities of correctly found, noise, and to-be-found named entities. How does the distribution in the figure align with the statement in the text that the 'evaluation shows a good accuracy (F-score of 94.90%)”?';'Die relativ hohe Anzahl korrekt gefundener Entitäten (340) im Vergleich zur geringen Anzahl an Noise-Entitäten (19) deutet auf eine hohe Präzision hin, was zu einem hohen F-Score beiträgt. Obwohl eine beträchtliche Anzahl von Entitäten 'To find' (397) verbleibt, ist der Unterschied zwischen 'Correct-Found' und 'Noise' signifikant genug, um den hohen F-Score von 94.90% zu rechtfertigen.';'The relatively large number of correctly found entities (340) compared to the small number of noise entities (19) indicates high precision, which contributes to a high F-score.  While a substantial number of entities remain 'To find' (397), the disparity between 'Correct-Found' and 'Noise' is significant enough to justify the high F-score of 94.90%.';Hohe Präzision;High Precision;Caption Question/Complex Calculation and Logical Reasoning;'
2015.jeptalnrecital-demonstration.6.pdf-Figure2.png;Welche Farbe steht für die Datenreihe 'LOCATION'?;What color represents the data series labeled 'LOCATION'?;Blau;Blue;Blau;Blue;Simple Retrieval;'
2015.jeptalnrecital-demonstration.6.pdf-Figure2.png;Was ist die Differenz zwischen den Werten für 'Precision' bei 'LOCATION' und 'ORGANIZATION'?;What is the difference between the 'Precision' values for 'LOCATION' and 'ORGANIZATION'?;37,63%;37.63%;37,63%;37.63%;Simple Calculation;'
2015.jeptalnrecital-demonstration.6.pdf-Figure2.png;Berechnen Sie den durchschnittlichen F-Score-Wert für alle drei Kategorien (Location, Organization, Person).;Calculate the average F-score value across all three categories (Location, Organization, Person).;76,92%;76.92%;76,92%;76.92%;Complex Calculation and Logical Reasoning;'
2015.jeptalnrecital-demonstration.6.pdf-Figure2.png;Ist die Summe der Werte für Precision und Recall für die Kategorie PERSON größer als der Wert für F-Score für die gleiche Kategorie?;Is the sum of the Precision and Recall values for the PERSON category greater than the F-score value for the same category?;Ja. Die Precision für Person beträgt 95,56% und der Recall 89,58%. Deren Summe (185,14%) ist größer als der F-Score von 92,47%.;Yes. Precision for Person is 95.56% and Recall is 89.58%. Their sum (185.14%) is greater than the F-score of 92.47%. ;Ja;Yes;Complex Calculation and Logical Reasoning;'
2015.jeptalnrecital-demonstration.6.pdf-Figure2.png;Der Artikel erwähnt die Evaluierung des Tools mit 1.060 Satzpaaren. Wie viele Named Entities wurden insgesamt in allen drei Kategorien korrekt identifiziert (laut Abbildung 1)?;The paper mentions evaluating the tool on 1,060 sentence pairs. How many named entities were correctly identified *in total* across all three categories (according to Figure 1)?;340;340;340;340;Requires Paper Context;'Our evaluation uses a test file of 1,060 pairs of French-Vietnamese sentences pairs and shows a good accuracy (F-score of 94.90%).'
2019.ccnlg-1.1.pdf-Figure13.png;Welches Spiel hat den niedrigsten Unvorhersehbarkeitswert?;Which game has the lowest unpredictability score?;HD-1;HD-1;HD-1;HD-1;Simple Retrieval;'
2019.ccnlg-1.1.pdf-Figure13.png;Was ist der Unterschied im Unvorhersehbarkeitswert zwischen dem Spiel mit der höchsten und dem Spiel mit der niedrigsten Punktzahl?;What is the difference in the unpredictability score between the highest and lowest scoring game?;Ungefähr 3;Approximately 3;3;3;Simple Calculation;'
2019.ccnlg-1.1.pdf-Figure13.png;Was ist der durchschnittliche Unvorhersehbarkeitswert der drei Spiele mit den höchsten Werten?;What is the average unpredictability score of the three highest-scoring games?;Ungefähr 5.;Approximately 5.;5;5;Complex Calculation and Logical Reasoning;'
2019.ccnlg-1.1.pdf-Figure13.png;Wie viele Spiele haben einen Unvorhersehbarkeitswert von über 3?;How many games have an unpredictability score above 3?;6;6;6;6;Simple Calculation;'
2019.ccnlg-1.1.pdf-Figure13.png;Stimmt die im Balkendiagramm dargestellte visuelle Differenz der Unvorhersehbarkeitswerte zwischen HD-1 und LM-5 mit der berechneten mittleren Differenz von 2,7463 im Tukey-HSD-Test (Tabelle 3) überein? Begründen Sie Ihre Antwort.;Does the visual difference in unpredictability scores between HD-1 and LM-5 shown in the bar chart seem consistent with the calculated mean difference of 2.7463 from the Tukey HSD test (Table 3)? Explain your reasoning.;Ja, die visuelle Differenz scheint mit der berechneten mittleren Differenz von 2,7463 übereinzustimmen. HD-1 erreicht etwa 2 Punkte, während LM-5 etwa 5 Punkte erreicht. Eine visuelle Differenz von etwa 3 stimmt mit 2,7463 überein, wenn man die Näherungswerte aus dem Diagramm und die Fehlerbalken berücksichtigt.;Yes, the visual difference appears consistent with the calculated mean difference of 2.7463. HD-1 scores around 2, while LM-5 scores around 5.  A visual difference of about 3 aligns with 2.7463 when considering approximations from the chart and the error bars.;Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;"**Group 1** **Group 2** **Meandiff**

HD-1 HD-5 2.6106 HD-1 LM-5 2.7463 HD-1 MCC-5 2.6875 HD-1 MCS-5 1.8875 HD-1 MCC-1 0.9375 HD-1 RA-1 0.9228 HD-1 RA-5 1.4208 HD-5 LM-1 -2.3397 HD-5 MCC-1 -1.6731 HD-5 MCS-1 -2.5342 LM-1 LM-5 2.4755 LM-1 MCC-1 0.6667 LM-1 MCC-5 2.4167 LM-1 MCS-5 1.6167 LM-5 MCC-1 -1.8088 LM-5 MCS-1 -2.6699 LM-5 RA-1 -1.8235 LM-5 RA-5 -1.3255 MCC-1 MCC-5 1.75 MCC-1 MCS-1 -0.8611 MCC-5 RA-1 -1.7647 MCC-5 RA-5 -1.2667 MCS-1 MCS-5 1.8111 MCS-1 RA-1 0.8464 MCS-1 RA-5 1.3444

Table 3: Surprise results for the post-hoc Tukey HSD test with p = 0.1, only significant results are shown."
2019.jeptalnrecital-court.15.pdf-Figure4.png;'Welcher Korpus hat den höchsten Balken für 'Corrigées'?';'Which corpus has the highest bar for 'Corrigées'?';Slovène;Slovène;Slovène;Slovène;Simple Retrieval;'
2019.jeptalnrecital-court.15.pdf-Figure4.png;'Was ist die Differenz zwischen dem Wert des grauen Balkens und dem Wert des blaugrünen Balkens für 'TPOS'?';'What is the difference between the value of the grey bar and the value of the teal bar for 'TPOS'?';3;3;3;3;Simple Calculation;'
2019.jeptalnrecital-court.15.pdf-Figure4.png;Wie hoch ist der Prozentsatz der korrigierten Vorhersagen für den Ark-Korpus?;What is the percentage of corrected predictions for the Ark corpus?;3;3;3;3;Simple Retrieval;'
2019.jeptalnrecital-court.15.pdf-Figure4.png;Ist der Durchschnittswert aller grauen Balken größer als der Durchschnittswert aller blaugrünen Balken?;Is the average value of all grey bars greater than the average value of all teal bars?;Nein;No;Nein;No;Complex Calculation and Logical Reasoning;'
2019.jeptalnrecital-court.15.pdf-Figure4.png;Abbildung 4 zeigt die Auswirkungen des Vortrainings auf die Vorhersagegenauigkeit. Welche spezifischen Probleme, die sich aus dem negativen Transfer ergeben, wurden im Zusammenhang mit großgeschriebenen Wörtern in Social-Media-Texten im Artikel beobachtet?;Figure 4 shows the impact of pre-training on prediction accuracy. According to the paper, what specific issues arising from negative transfer were observed in relation to capitalized words in social media text?;Das mit Standardsprache vortrainierte Modell, bei dem Eigennamen großgeschrieben werden, hat Schwierigkeiten, sich an soziale Medien anzupassen, wo die Großschreibung weniger konsistent ist.;The model, pre-trained on standard language where proper nouns are capitalized, struggles to adapt to social media where capitalization is less consistent.;Inkonsistente Großschreibung;Inconsistent capitalization;Requires Paper Context;"Pour mieux comprendre l’impact du pré-apprentissage, la figure 4 présente le pourcentage des prédictions corrigées et celles falsifiées en introduisant le pré-apprentissage du RNs sur le domaine source par rapport à l’initialisation aléatoire. Nous constatons que le pré-apprentissage améliore considérablement les prédictions. Cependant, les falsifications causées par le transfert négatif des régularités spécifiques aux corpus sources (Meftah et al., 2019) réduisent l’apport final du pré- apprentissage. Parmi les erreurs causées par le transfert négatif que nous avons constaté :

 1. Les mots avec une première lettre en majuscule; en effet, dans la forme standard des langues,"
2019.jeptalnrecital-tia.5.pdf-Figure3.png;Welche Beschriftung steht auf der y-Achse?;What is the label of the y-axis?;Entropie;Entropy;Entropie;Entropy;Simple Retrieval;'
2019.jeptalnrecital-tia.5.pdf-Figure3.png;Wie hoch ist der höchste Balken im Bot-Bereich? Geben Sie die Einheit an.;'What is the height of the tallest bar in the 'Bot' domain? State the unit.';Ungefähr 8 Entropie;Approximately 8 Entropy;8 Entropie;8 Entropy;Simple Retrieval;'
2019.jeptalnrecital-tia.5.pdf-Figure3.png;Ist die Summe der Höhen der beiden hellsten Balken im Agr-Bereich größer als die Summe der Höhen der beiden dunkelsten Balken im selben Bereich?;'Is the sum of the heights of the two lightest bars in the 'Agr' domain greater than the sum of the heights of the two darkest bars in the same domain?';Ja.;Yes.;Ja;Yes;Simple Calculation;'
2019.jeptalnrecital-tia.5.pdf-Figure3.png;Welcher Bereich hat den größten Höhenunterschied zwischen seinem hellsten und dunkelsten Balken, und wie groß ist dieser Unterschied? Geben Sie die Einheit an.;Which domain has the largest difference in height between its lightest and darkest bars, and what is that difference? State the unit.;Psy, mit einem Unterschied von ungefähr 2 Entropie.;Psy, with a difference of approximately 2 Entropy.;Psy, 2 Entropie;Psy, 2 Entropy;Complex Calculation and Logical Reasoning;'
2019.jeptalnrecital-tia.5.pdf-Figure3.png;Der Text erwähnt, dass die Entropiewerte für ER- und WS-Graphen sehr nahe beieinander liegen. In Abbildung 3, welcher Bereich weist die größte Abweichung zwischen den Entropiewerten seiner ER- und WS-Graphen auf? Quantifizieren Sie diese Differenz. Stellt diese Beobachtung die Behauptung in Frage, dass ER- und WS-Graphen ähnliche Entropiewerte aufweisen?;The text mentions that the entropy values for ER and WS graphs are very close. In Figure 3, which domain exhibits the *largest* discrepancy between the entropy values of its ER and WS graphs? Quantify this difference. Does this observation challenge the assertion that ER and WS graphs demonstrate similar entropy values?;'Der größte Unterschied ist in 'Cmp' zu beobachten, ungefähr 0,1 Entropie. Dieser kleine Unterschied unterstützt eher die Behauptung, dass ER und WS ähnliche Entropien haben, als dass er sie in Frage stellt.';'The largest difference is in 'Cmp', approximately 0.1 Entropy.  This small difference supports, rather than challenges, the assertion that ER and WS have similar entropies.';Cmp, 0.1 Entropie, Nein;Cmp, 0.1 Entropy, No;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.158.pdf-Figure5.png;Welches Modell wird durch die pink/magenta Farbe dargestellt?;Which model is represented by the pink/magenta color?;JRNN*;JRNN*;JRNN*;JRNN*;Caption Question/Simple Retrieval;'
2020.acl-main.158.pdf-Figure5.png;'Was ist der Unterschied im SG-Score zwischen GPT-2-XL* und GPT-2* für 'Agreement'?';'What is the difference in the SG score between GPT-2-XL* and GPT-2* for 'Agreement'?';Der Unterschied beträgt etwa 0,05.;The difference is approximately 0.05.;0.05;0.05;Caption Question/Simple Calculation;'
2020.acl-main.158.pdf-Figure5.png;'Ist der durchschnittliche SG-Score aller Modelle für 'Center Embedding' höher als 0,6?';'Is the average SG score of all models for 'Center Embedding' higher than 0.6?';'Ja, der durchschnittliche SG-Score für 'Center Embedding' scheint höher als 0,6 zu sein.';'Yes, the average SG score for 'Center Embedding' appears to be higher than 0.6.';Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.158.pdf-Figure5.png;'Welche zwei Modelle haben den höchsten SG-Score für 'Gross Syntactic State', und welches dieser beiden Modelle schneidet besser ab?';'Which two models have the highest SG score for 'Gross Syntactic State,' and which of these two performs better?';RNNG und ON-LSTM, sie scheinen exakt die gleiche Höhe zu haben.;RNNG and ON-LSTM, they seem to be exactly the same height.;RNNG & ON-LSTM, gleich;RNNG & ON-LSTM, same;Caption Question/Simple Retrieval;'
2020.acl-main.158.pdf-Figure5.png;Der Text erwähnt, dass vortrainierte Modelle im Allgemeinen gut abschneiden. Stimmt diese Aussage mit den Ergebnissen in Abbildung 5 überein, insbesondere im Vergleich zur Leistung der speziell trainierten Modelle?;The text mentions that pre-trained models generally perform well. Does this statement align with the results in Figure 5, especially compared to the performance of the custom-trained models?;Ja, die Abbildung unterstützt die Aussage. Die vortrainierten Modelle übertreffen die meisten der speziell trainierten Modelle durchweg in allen Schaltkreisen.;Yes, the figure supports the statement. The pre-trained models consistently outperform most custom-trained models across all circuits.;Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.169.pdf-Figure2.png;'Welche Farbe hat der Balken für 'power'?';'What color is the bar for 'power'?';Karmesinrot;Crimson;Karmesinrot;Crimson;Simple Retrieval;'
2020.acl-main.169.pdf-Figure2.png;'Wie viel Prozent höher ist der Balken für 'power' im Vergleich zum Balken für 'enron'?';'What percentage taller is the bar for 'power' compared to the bar for 'enron'?';Ungefähr 49%;Approximately 49%;49%;49%;Simple Calculation;'
2020.acl-main.169.pdf-Figure2.png;Ist die Summe der Wahrscheinlichkeiten aller Wörter im P0-Bucket größer als die Summe der Wahrscheinlichkeiten aller Wörter im P9-Bucket?;Is the sum of the probabilities of all words in the P0 bucket greater than the sum of the probabilities of all words in the P9 bucket?;Nein. Die Summe der Wahrscheinlichkeiten für Wörter im P9-Bucket ist größer.;No. The sum of probabilities for words in the P9 bucket is larger.;Nein;No;Complex Calculation and Logical Reasoning;'
2020.acl-main.169.pdf-Figure2.png;Die Autoren erwähnen, dass sie Sätze anhand von Höflichkeitsbewertungen in zehn Buckets (P0-P9) filtern. Abbildung 2 konzentriert sich auf P0 und P9. Welche Schlussfolgerung lässt sich anhand der Verteilung in Abbildung 2 und der Informationen im Text über die allgemeine Verteilung der Höflichkeit im Enron-E-Mail-Korpus ziehen? Welche zusätzlichen Erkenntnisse liefert die Verteilung der häufigsten Wörter in den Buckets P0 und P9 (Abbildung 2) im Vergleich zur Gesamtverteilung der Höflichkeitsbewertungen im Korpus?;The authors mention filtering sentences into ten buckets (P0-P9) based on politeness scores. Figure 2 focuses on P0 and P9. Examining the distribution in Figure 2 and considering the information in the text, what can be inferred about the general distribution of politeness in the Enron email corpus? What additional insights does the distribution of the most frequent words in buckets P0 and P9 (Figure 2) offer compared to the overall distribution of politeness scores in the corpus?;'Abbildung 2 deutet auf eine unterschiedliche Wortwahl in Bezug auf den Höflichkeitsgrad in den Enron-E-Mails hin. P9 (höflich) wird von Höflichkeitsmarkierungen (z. B. 'please', 'would') dominiert, während P0 (weniger höflich) geschäftsbezogene Begriffe (z. B. 'power', 'enron') enthält. Diese lexikalische Erkenntnis ist detaillierter als die bloße Kenntnis der Gesamtverteilung der Höflichkeitswerte und zeigt, *welche Wörter* am meisten zu jedem Level beitragen.';'Figure 2 suggests a distinct vocabulary usage correlated with politeness levels in the Enron emails. P9 (polite) is dominated by politeness markers (e.g., 'please', 'would'), while P0 (less polite) contains business-related terms (e.g., 'power', 'enron'). This lexical insight is more granular than simply knowing the overall politeness score distribution, revealing *which words* contribute most to each level.';Unterschiedliche Wortwahl je Höflichkeitsgrad;Distinct vocabulary per politeness level;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.197.pdf-Figure2.png;Welche Farbe repräsentiert die SMART-Daten im MNLI-Match-Diagramm für Genauigkeit?;What color represents the SMART data in the MNLI Match plot for Accuracy?;Orange;Orange;Orange;Orange;Simple Retrieval;'
2020.acl-main.197.pdf-Figure2.png;'Was ist der Unterschied in der Genauigkeit zwischen RoBERTa und SMART in MNLI Match für 'All'?';'What is the difference in accuracy between RoBERTa and SMART in MNLI Match for 'All'?';0,5%;0.5%;0.5%;0.5%;Simple Calculation;'
2020.acl-main.197.pdf-Figure2.png;Wie hoch ist die Summe der Genauigkeit von RoBERTa über alle Kategorien im MNLI-Mismatch-Plot?;What is the sum of the accuracy of RoBERTa across all categories in the MNLI Mismatch plot?;410,1%;410.1%;410.1%;410.1%;Complex Calculation and Logical Reasoning;'
2020.acl-main.197.pdf-Figure2.png;Ist die durchschnittliche KL-Divergenz von SMART im MNLI-Match-Plot höher oder niedriger als die durchschnittliche KL-Divergenz von RoBERTa im MNLI-Mismatch-Plot?;Is the average KL-Divergence of SMART in the MNLI Match plot higher or lower than the average KL-Divergence of RoBERTa in the MNLI Mismatch plot?;Niedriger.;Lower.;Niedriger;Lower;Complex Calculation and Logical Reasoning;'
2020.acl-main.197.pdf-Figure2.png;Inwiefern trägt laut dem Paper die Datenaugmentierung, wie sie in MT-DNN-SMART verwendet wird, zur beobachteten Genauigkeit von SMART in den MNLI-Match- und MNLI-Mismatch-Szenarien bei, insbesondere wenn der Grad der Übereinstimmung 3/2/0 beträgt? Analysieren Sie dies im Zusammenhang mit den in Abbildung 2 dargestellten KL-Divergenz-Ergebnissen.;According to the paper, how does data augmentation, as used in MT-DNN-SMART, contribute to the observed accuracy of SMART in both the MNLI Match and MNLI Mismatch scenarios, particularly when the degree of agreement is 3/2/0? Analyze this in relation to the KL-Divergence results displayed in Figure 2.;Datenaugmentation in MT-DNN-SMART verbessert die Genauigkeit und Robustheit des Modells, insbesondere in Szenarien mit Domänenverschiebung wie MNLI Mismatch, wo es eine Genauigkeit von 65,4 % im Vergleich zu 63,4 % von RoBERTa erreicht. Dies wird durch die überlegene Leistung von SMART bei der KL-Divergenz (0,66 für MNLI Match und 0,64 für Mismatch) im Vergleich zu RoBERTa (0,97 für MNLI Match und 0,94 für Mismatch) beim Umgang mit mehrdeutigen Stichproben belegt.;Data augmentation in MT-DNN-SMART enhances the model's accuracy and robustness, particularly in domain-shifting scenarios like MNLI Mismatch, where it achieves an accuracy of 65.4% compared to RoBERTa's 63.4%. This is evidenced by SMART's superior performance in KL-Divergence (0.66 for MNLI Match and 0.64 for Mismatch) compared to RoBERTa (0.97 for MNLI Match and 0.94 for Mismatch) when handling ambiguous samples.;Verbessert Genauigkeit/Robustheit;Enhances Accuracy/Robustness;Requires Paper Context;"To understand why SMART improves the performance, we analyze it on the ambiguous samples of MNLI dev set containing 3 classes, where each sample has 5 annotations. Based on the degree of agreement between these annotations, we divide the samples into 4 categories: 1) 5/0/0 all five annotations are the same; 2) 4/1/0 four annotations are the same; 3) 3/2/0 three annotations are the same and the other two annotations are the same; 4) 3/1/1 three annotations are the same and the other two annotations are different. Figure 2 summarizes the results in terms of both accuracy and KL-divergence: _−_ _n[1]_ �ni=1 �3j=1 _[p][j][(][x][i][) log(][f][j][(][x][i][))][.]_ For a given

sample xi, the KL-Divergence evaluates the similarity between the model prediction {fj(xi)}j[3]=1 and the annotation distribution _{pj(xi)}j[3]=1[.]_ We observe that SMARTRoBERTa outperforms RoBERTa across all the settings. Further, on high degree of ambiguity (low degree of agreement), SMARTRoBERTa obtains an even larger improvement showing its robustness to ambiguity."
2020.acl-main.199.pdf-Figure3.png;Welche Farbe hat der Balken für 'Recall'?;What color is the bar representing 'Recall'?;Orange;Orange;Orange;Orange;Caption Question/Simple Retrieval;'
2020.acl-main.199.pdf-Figure3.png;Wie groß ist die Differenz zwischen dem F1-Score von '2GNN' und dem Recall-Wert von 'Without Feas'?;What is the difference between the F1 Score of '2GNN' and the Recall value of 'Without Feas'?;Ungefähr 0.02;Approximately 0.02;0.02;0.02;Caption Question/Simple Calculation;'
2020.acl-main.199.pdf-Figure3.png;Ist die Summe der Werte für Precision und Recall von '2GNN+Res' größer als der doppelte F1-Score von '2GNN+Res'?;Is the sum of the values for Precision and Recall of '2GNN+Res' greater than twice the F1 score of '2GNN+Res'?;Ja.;Yes.;Ja;Yes;Caption Question/Simple Calculation;'
2020.acl-main.199.pdf-Figure3.png;Welches der Modelle '2GNN', '2GNN+Res' und '2GNN+SC+Res' weist die geringste Differenz zwischen dem höchsten und niedrigsten Wert über alle drei Metriken auf (F1-Score, Recall und Precision)?;Which of the models '2GNN', '2GNN+Res', and '2GNN+SC+Res' has the smallest difference between its maximum and minimum values across all three metrics (F1 Score, Recall, and Precision)?;2GNN+SC+Res;2GNN+SC+Res;2GNN+SC+Res;2GNN+SC+Res;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.199.pdf-Figure3.png;Der Artikel erwähnt einen Schwellenwert von 0,5 für die Vorhersage in der Testphase. Gibt es angesichts der in Abbildung 3 dargestellten Fehlerbalken Fälle, in denen die Anwendung dieses Schwellenwerts aufgrund überlappender Fehlerbereiche zwischen einem Modell mit und ohne SC-Schicht zu mehrdeutigen Klassifizierungen führen könnte? Wenn ja, welche Modellvergleiche zeigen diese Mehrdeutigkeit?;The paper mentions using a threshold of 0.5 for prediction in the test phase. Considering the error bars presented in Figure 3, are there any instances where applying this threshold might lead to ambiguous classifications due to overlapping error ranges between a model with and without the SC layer? If so, which model comparison(s) demonstrate this ambiguity?;'Basierend auf dem Balkendiagramm 'Ergebnisse im Bereich Wissenschaft (Eurovoc) mit Fehlerbalken' gibt es keine sichtbaren Überlappungen der Fehlerbalken zwischen den Modellen. Die Leistung jedes Modells, gemessen an F1-Score, Recall und Precision, ist unterschiedlich und ihre Fehlerbalken überschneiden sich nicht. Daher sollte die Anwendung des Schwellenwerts von 0,5 aufgrund von sich überlappenden Fehlerbereichen zwischen den Modellen in diesem speziellen Diagramm nicht zu mehrdeutigen Klassifizierungen führen.';"Based on the bar chart 'Results on Science (Eurovoc) domain with Error Bars,' there are no visible overlapping error bars among the models.
Each model's performance, in terms of F1 Score, Recall, and Precision, is distinct and their error bars do not overlap. Thus, applying the threshold of 0.5 should not lead to ambiguous classifications due to overlapping error ranges between the models in this particular chart.";Nein;No;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.201.pdf-Figure2.png;Welche Farbe repräsentiert die Datenreihe '+synthetic (train)'?;What color represents the data series '+synthetic (train)'?;Orange.;Orange.;Orange;Orange;Simple Retrieval;'
2020.acl-main.201.pdf-Figure2.png;Welcher Wert ist im ersten Diagramm (BLI-Genauigkeit für PROC) höher: der Wert für '+synthetic (train)' in DE oder der Wert für '+retrofit (train)' in DE?;In the first chart (BLI accuracy for PROC), which value is higher: the value for '+synthetic (train)' in DE or the value for '+retrofit (train)' in DE?;Der Wert für '+retrofit (train)' ist höher.;The value for '+retrofit (train)' is higher.;'+retrofit (train)';'+retrofit (train)';Simple Calculation;'
2020.acl-main.201.pdf-Figure2.png;Im ersten Diagramm (BLI-Genauigkeit für PROC): Ist die Summe der Werte für '+synthetic (train)' und '+retrofit (train)' für FR größer als der Wert für 'Original (train)' für FR?;In the first chart (BLI accuracy for PROC): Is the sum of the values for '+synthetic (train)' and '+retrofit (train)' for FR greater than the value for 'Original (train)' for FR?;Ja. Die kombinierte Höhe des orangefarbenen und des rosa Balkens ist größer als die Höhe des grauen Balkens.;Yes. The combined height of the orange and pink bars is greater than the height of the gray bar.;Ja;Yes;Simple Calculation;'
2020.acl-main.201.pdf-Figure2.png;Betrachten Sie das zweite Diagramm (BLI-Genauigkeit für CCA). Ist die Genauigkeit des 'Original (test)'-Datensatzes für IT höher oder niedriger als die Genauigkeit des '+synthetic (train)'-Datensatzes für dieselbe Sprache?;Consider the second chart (BLI accuracy for CCA). Is the accuracy of the 'Original (test)' dataset for IT higher or lower than the accuracy of the '+synthetic (train)' dataset for the same language?;Niedriger. Der hellgraue Balken ist kürzer als der orangefarbene Balken.;Lower. The light gray bar is shorter than the orange bar.;Niedriger;Lower;Simple Calculation;'
2020.acl-main.201.pdf-Figure2.png;Die Bildunterschrift erwähnt, dass das Hinzufügen eines synthetischen Wörterbuchs die Genauigkeit von Downstream-Modellen verbessert. Unterstützen die Diagramme diese Behauptung, indem sie die Leistung des '+synthetic'-Datensatzes im Vergleich zum 'Original'- und '+retrofit'-Datensatz für mindestens eine der Bewertungsmetriken zeigen?;The caption mentions that adding a synthetic dictionary improves the accuracy of downstream models. Do the charts support this claim by showing the performance of the '+synthetic' dataset compared to the 'Original' and '+retrofit' dataset for at least one of the evaluation metrics?;Ja. In vielen Fällen, über alle drei Diagramme hinweg, sind die orangenen Balken, die '+synthetic (train)' darstellen, höher als die grauen 'Original (train)'-Balken, aber sie übertreffen niemals die pinken '+retrofit (train)'-Balken.;Yes. In many cases, across all three graphs, the orange bars representing '+synthetic (train)' are higher than the gray 'Original (train)' bars but they never surpass the pink '+retrofit (train)' bars.;Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.201.pdf-Figure3.png;Welche Farbe repräsentiert die ursprünglichen Einbettungen in den Balkendiagrammen?;What color represents the original embeddings in the bar charts?;Grau;Gray;Grau;Gray;Simple Retrieval;'
2020.acl-main.201.pdf-Figure3.png;Was ist die Differenz zwischen dem Wert der grauen und dem Wert der rosa Balken für die Dokumentenklassifizierung mit PROC für die Sprache ES?;What is the difference between the value of the gray and the pink bars for document classification with PROC for the language ES?;Ungefähr 10;Approximately 10;10;10;Simple Calculation;'
2020.acl-main.201.pdf-Figure3.png;Ist der Durchschnittswert der grauen Balken in den Diagrammen zur Dokumentenklassifizierung höher oder niedriger als der Durchschnittswert der orangen Balken in denselben Diagrammen?;Is the average value of the gray bars across the document classification charts higher or lower than the average value of the orange bars in the same charts?;Niedriger;Lower;Niedriger;Lower;Complex Calculation and Logical Reasoning;'
2020.acl-main.201.pdf-Figure3.png;Welches CLWE-Verfahren (PROC, CCA oder RCSLS) erzielt im Durchschnitt die höchste Genauigkeit bei der Dokumentenklassifizierung über alle Sprachen hinweg?;Which CLWE method (PROC, CCA, or RCSLS) achieves the highest average accuracy in document classification across all languages?;PROC;PROC;PROC;PROC;Complex Calculation and Logical Reasoning;'
2020.acl-main.201.pdf-Figure3.png;Der Artikel erwähnt, dass das Nachrüsten mit dem Trainingswörterbuch Übersetzungspaare *außerhalb* des Wörterbuchs trennen kann. Betrachtet man die Ergebnisse für Japanisch (JA) in Abbildung 3, welche Aufgabe (Dokumentenklassifizierung oder Dependenz-Parsing) und welche CLWE-Methode (PROC, CCA oder RCSLS) scheinen am *negativsten* von dieser möglichen Trennung betroffen zu sein, wenn das kombinierte Wörterbuch (orange Balken) verwendet wird? Begründen Sie Ihre Argumentation anhand der in der Abbildung dargestellten Trends und Informationen aus dem Artikel.;The paper mentions that retrofitting to the training dictionary can separate translation pairs *outside* of the dictionary. Looking at the results for Japanese (JA) in Figure 3, which task (Document Classification or Dependency Parsing) and which CLWE method (PROC, CCA, or RCSLS) seem to be *most negatively* affected by this potential separation when using the combined dictionary (orange bars)? Explain your reasoning based on the trends shown in the figure and information from the paper.;Dependenz-Parsing mit CCA. Der orange Balken für JA im Dependenz-Parsing mit CCA ist deutlich niedriger als sowohl der graue (Original) als auch der rosa (+Retrofit) Balken, was auf einen negativen Einfluss durch das Hinzufügen des synthetischen Wörterbuchs hinweist. Dies stimmt mit der Erwähnung im Artikel überein, dass beim Nachrüsten möglicherweise Übersetzungspaare außerhalb des Trainingswörterbuchs getrennt werden, was sich negativ auf die Leistung auswirken kann.;Dependency parsing with CCA. The orange bar for JA in dependency parsing with CCA is significantly lower than both the gray (Original) and the pink (+Retrofit) bars, indicating a negative impact from the addition of the synthetic dictionary. This aligns with the mention in the article that retrofitting may separate translation pairs outside of the training dictionary, negatively impacting performance.;CCA, Dependenz-Parsing;CCA, Dependency Parsing;Requires Paper Context;"**3.1 Retrofitting to Synthetic Dictionary**

While retrofitting brings pairs in the training dictionary closer, the updates may also separate translation pairs outside of the dictionary because retrofitting ignores words outside the training dictionary. This can hurt both BLI test accuracy and downstream task accuracy. In contrast, projection-based methods underfit but can discover translation pairs outside the training dictionary. To keep the original CLWE’s correct translations, we retrofit to both the training dictionary and a synthetic dictionary induced from CLWE (orange, Figure 1)."
2020.acl-main.244.pdf-Figure3.png;Welches Modell hat den geringsten Genauigkeitsabfall?;Which model has the lowest accuracy drop?;ALBERT base;ALBERT base;ALBERT base;ALBERT base;Simple Retrieval;'
2020.acl-main.244.pdf-Figure3.png;Wie hoch ist der Genauigkeitsabfall von BERT large?;What is the accuracy drop of BERT large?;5%;5%;5%;5%;Simple Retrieval;'
2020.acl-main.244.pdf-Figure3.png;Was ist der durchschnittliche Genauigkeitsabfall aller in der Abbildung gezeigten Modelle?;What is the average accuracy drop of all models shown in the figure?;Ungefähr 4,83%;Approximately 4.83%;4.83%;4.83%;Complex Calculation and Logical Reasoning;'
2020.acl-main.244.pdf-Figure3.png;Welches Modell hat einen Genauigkeitsabfall, der am nächsten am durchschnittlichen Genauigkeitsabfall aller Modelle liegt?;Which model has an accuracy drop closest to the average accuracy drop of all models?;BERT large;BERT large;BERT large;BERT large;Complex Calculation and Logical Reasoning;'
2020.acl-main.244.pdf-Figure3.png;Stimmt es, dass größere Modelle im Gegensatz zur Computer Vision die IID/OOD-Generalisierungslücke nicht verbessern, wie in der Studie erwähnt? Welche Ergebnisse in Abbildung 3 stützen diese Aussage?;Is it true that, unlike in computer vision, larger models don't improve the IID/OOD generalization gap, as stated in the paper? Which results in Figure 3 support this statement?;Ja, größere Modelle verbessern die IID/OOD-Generalisierungslücke nicht. Sowohl BERT large als auch ALBERT large haben größere Genauigkeitsabfälle im Vergleich zu ihren Basis-Pendants. Dies widerspricht dem Trend in der Computer Vision, wo größere Modelle typischerweise besser abschneiden.;Yes, larger models do not improve the IID/OOD generalization gap. Both BERT large and ALBERT large have larger accuracy drops compared to their base counterparts. This contradicts the trend observed in computer vision, where larger models typically perform better.;Ja;Yes;Requires Paper Context;"**Bigger Models Are Not Always Better.** While larger models reduce the IID/OOD generalization gap in computer vision (Hendrycks and Dietterich, 2019; Xie and Yuille, 2020; Hendrycks et al., 2019d), we find the same does not hold in NLP. Figure 3 shows that larger BERT and ALBERT models do not reduce the generalization gap."
2020.acl-main.286.pdf-Figure5.png;Welcher Merkmalstyp erzielt die höchste Genauigkeit für Res Top1?;Which feature type achieves the highest accuracy for Res Top1?;Occ;Occ;Occ;Occ;Simple Retrieval;'
2020.acl-main.286.pdf-Figure5.png;Wie groß ist der Genauigkeitsunterschied zwischen Gyn Top1 und Res Top1 bei Verwendung von CHI?;What is the accuracy difference between Gyn Top1 and Res Top1 when using CHI?;Ungefähr 0.08;Approximately 0.08;0.08;0.08;Simple Calculation;'
2020.acl-main.286.pdf-Figure5.png;Wie hoch ist die durchschnittliche Genauigkeit für Res Top3 über alle Merkmalstypen?;What is the average accuracy for Res Top3 across all feature types?;Ungefähr 0.83;Approximately 0.83;0.83;0.83;Complex Calculation and Logical Reasoning;'
2020.acl-main.286.pdf-Figure5.png;Ist die durchschnittliche Genauigkeit von Gyn Top1 über alle Merkmalstypen hinweg höher als die von Res Top1? Begründen Sie Ihre Antwort anhand der im Diagramm dargestellten Werte.;Is the average accuracy of Gyn Top1 across all feature types higher than that of Res Top1? Justify your answer using the values shown in the chart.;Ja. Die durchschnittliche Genauigkeit für Gyn Top1 beträgt etwa 0.71, während die durchschnittliche Genauigkeit für Res Top1 etwa 0.63 beträgt. Daher hat Gyn Top1 eine höhere durchschnittliche Genauigkeit.;Yes. The average accuracy for Gyn Top1 is approximately 0.71, while the average accuracy for Res Top1 is approximately 0.63. Therefore, Gyn Top1 has a higher average accuracy.;Ja;Yes;Complex Calculation and Logical Reasoning;'
2020.acl-main.286.pdf-Figure5.png;In Abschnitt 4.2.5 wird die hohe Genauigkeit hervorgehoben, die durch die Mittelung aller Merkmale erreicht wird. In Anbetracht der Variabilität der einzelnen Feature-Leistungen (z. B. CHI vs. TF-IDF für Res Top1), welchen Vorteil könnte die Mittelung aller Features für die Verbesserung der diagnostischen Genauigkeit bieten, wie von den Autoren vorgeschlagen?;Section 4.2.5 highlights the high accuracy achieved when averaging all features. Considering the variability in individual feature performance (e.g., CHI vs. TF-IDF for Res Top1), what advantage might averaging all features offer for improving diagnostic accuracy, as suggested by the authors?;Die Mittelung aller Merkmale mildert die negativen Auswirkungen einzelner schlecht abschneidender Merkmale und erhöht die Gesamtstabilität. Die Kombination aller Merkmale bietet eine stabilere und repräsentativere diagnostische Genauigkeit.;Averaging all features mitigates the negative effects of individual poorly performing features and increases overall stability. The combination of all features offers more stable and representative diagnostic accuracy.;Stabilität;Stability;Requires Paper Context;'Figure 5 shows the accuracy performance using different types of features. We can see that in this evaluation, TFC, TF-IDF and the average of all features are likely to lead to higher accuracy compared to the other features where the accuracy of Top-3 prediction is over 88%.'
2020.acl-main.289.pdf-Figure4.png;Welche Metrik wird auf der x-Achse dargestellt?;What metric is represented on the x-axis?;F-Wert, Präzision und Rückruf;F-score, Precision, and Recall;F-Wert, Präzision, Rückruf;F-score, Precision, Recall;Simple Retrieval;'
2020.acl-main.289.pdf-Figure4.png;'Welcher Wert wird für RANKCP (top-1) bei der Metrik 'Precision' erreicht?';'What value is achieved by RANKCP (top-1) for the 'Precision' metric?';Ungefähr 0,675;Approximately 0.675;0,675;0.675;Simple Retrieval;'
2020.acl-main.289.pdf-Figure4.png;Wie hoch ist der durchschnittliche Wert über alle drei Metriken für RANKCP ohne Ranking?;What is the average value across all three metrics for RANKCP w/o Rank?;Ungefähr 0,63;Approximately 0.63;0,63;0.63;Complex Calculation and Logical Reasoning;'
2020.acl-main.289.pdf-Figure4.png;Bei welcher Metrik ist der Unterschied zwischen RANKCP und RANKCP (top-1) am größten?;For which metric is the difference between RANKCP and RANKCP (top-1) the greatest?;Rückruf;Recall;Rückruf;Recall;Complex Calculation and Logical Reasoning;'
2020.acl-main.289.pdf-Figure4.png;Abbildung 4 vergleicht RANKCP mit einer Variante ohne die Komponente zum Lernen und Ranking der Darstellung von Klauselpaaren. Wie wird diese Variante in der Arbeit bezeichnet, und welche Auswirkungen hat das Entfernen dieser Komponente laut der Arbeit auf den F1-Wert bei der Extraktion von Emotion-Ursache-Paaren (siehe Tabelle 2)?;Figure 4 compares RANKCP with a variant that removes the clause pair representation learning and ranking component. How is this variant referred to in the paper, and according to the paper, what is the impact of removing this component on the F1-score for emotion-cause pair extraction (refer to Table 2)?;'Die Variante wird als 'RANKCP w/o Rank' bezeichnet. Das Entfernen dieser Komponente reduziert den F1-Wert von 0.6610 auf 0.6562, eine Abnahme von 0.0048.';'The variant is referred to as 'RANKCP w/o Rank'. Removing this component reduces the F1-score from 0.6610 to 0.6562, a decrease of 0.0048.';'RANKCP w/o Rank';'RANKCP w/o Rank';Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.309.pdf-Figure3.png;Welche Beschriftung befindet sich unter dem zweiten Balkendiagramm von links?;What is the label below the second bar chart from the left?;Across a SRC;Across a SRC;Across a SRC;Across a SRC;Simple Retrieval;'
2020.acl-main.309.pdf-Figure3.png;'Wie hoch ist der orangefarbene Balken im Diagramm 'Across a PP' chart?';'What is the height of the orange bar in the 'Across a PP' chart?';98;98;98;98;Simple Retrieval;'
2020.acl-main.309.pdf-Figure3.png;'Was ist die Differenz zwischen dem höchsten und dem niedrigsten Wert im Diagramm 'Across an ORC' chart?';'What is the difference between the highest and lowest values in the 'Across an ORC' chart?';5;5;5;5;Simple Calculation;'
2020.acl-main.309.pdf-Figure3.png;'Ist der Durchschnittswert der Genauigkeit im Diagramm 'Across a PP' chart höher oder niedriger als im Diagramm 'Across a SRC' chart?';'Is the average accuracy in the 'Across a PP' chart higher or lower than in the 'Across a SRC' chart?';Niedriger;Lower;Niedriger;Lower;Complex Calculation and Logical Reasoning;'
2020.acl-main.309.pdf-Figure3.png;'Inwiefern korrelieren die Ergebnisse für Objektrelativsätze (ORC) in Abbildung 3 mit den Ergebnissen der erweiterten Trainingsdaten (Abbildung 2) und welche Auswirkungen hat dies auf die Generalisierbarkeit des Modells auf unbekannte ORC-Konstruktionen (unter Berücksichtigung der Einschränkungen von LSTM-LMs bei der Verarbeitung von ORCs, wie in Abschnitt 5 erläutert)? Konzentrieren Sie sich auf das Diagramm 'Across an ORC' in Abbildung 3.';Considering the limitations of LSTM-LMs in handling object relative clauses (ORCs) discussed in Section 5 and the results presented in Figure 2, how does the performance on ORCs in Figure 3 (specifically the 'Across an ORC' graph) compare to the augmented training data results for ORCs, and what implications does this have for the model's generalizability to unseen ORC constructions?;Abbildung 3 zeigt eine geringere Genauigkeit für ORCs im Vergleich zu anderen Konstruktionen, selbst mit den negativen Trainingsbeispielen. Während Abbildung 2 eine Verbesserung mit erweiterten Trainingsdaten zeigt, erreicht sie nicht das Niveau anderer Konstruktionen in Abbildung 3. Dies, kombiniert mit der Diskussion in Abschnitt 5 über LSTM-Einschränkungen bei ORCs, deutet auf eine eingeschränkte Verallgemeinerbarkeit auf ungesehene ORC-Konstruktionen aufgrund inhärenter architektonischer Einschränkungen hin, nicht nur aufgrund von Datenknappheit.;Figure 3 shows lower accuracy for ORCs compared to other constructions, even with the negative training examples. While Figure 2 shows improvement with augmented training data, it doesn't reach the level of other constructions in Figure 3.  This, combined with the Section 5 discussion on LSTM limitations with ORCs, suggests limited generalizability to unseen ORC constructions due to inherent architectural constraints, not just data scarcity.;Eingeschränkte Generalisierbarkeit;Limited generalizability;Requires Paper Context;"## 5 Limitations of LSTM-LMs

In Table 1, the accuracies on dependencies across an object RC are relatively low. The central question in this experiment is whether this low performance is due to the limitation of current architectures, or other factors such as frequency. We base our discussion on the contrast between object (7) and subject (8) RCs:

**Setup** We first inspect the frequencies of object and subject RCs in the training data, by parsing them with the state-of-the-art Berkeley neural parser (Kitaev and Klein, 2018). In total, while subject RCs occur 373,186 times, object RCs only occur 106,558 times. We create three additional training datasets by adding sentences involving object RCs to the original Wikipedia corpus (Section 2.2). To this end, we randomly pick up 30 million sentences from Wikipedia (not overlapped to any sentences in the original corpus), parse by the same parser, and filter sentences containing an object RC, amounting to 680,000 sentences. We create augmented training sets by adding a subset, or all of these sentences to the original training sentences. Among the test cases about object RCs we only report accuracies on subject-verb agreement, on which the portion for subject RCs also exists. This allows us to compare the difficulties of two types of RCs for the present models. We also evaluate on “animate only” subset, which has a correspondence to the test cases for subject RCs with only differences in word order and inflection (like (7) and (8); see footnote 9). Of particular interest to us is the accuracy on these animate cases. We expect that the main reason for lower performance for object RCs is due to frequency, and with our augmentation the accuracy will reach the same level as that for subject RCs.

**Results** However, for both all and animate cases, accuracies are below those for subject RCs (Figure 2). Although we see improvements from the original score (93.7), the highest average accuracy by the token-level margin loss on the “animate” subset is 97.1 (“with that”), not beyond 99%. This result indicates some architectural limitations of LSTM-LMs in handling object RCs robustly at a near perfect level. Answering why the accuracy does not reach (almost) 100%, perhaps with other empirical properties or inductive biases (Khandelwal et al., 2018; Ravfogel et al., 2019) is future work."
2020.acl-main.371.pdf-Figure1.png;Wie hoch ist der Prozentsatz des dritten Balkens von links?;What is the percentage value of the third bar from the left?;64,2%;64.2%;64,2%;64.2%;Simple Retrieval;'
2020.acl-main.371.pdf-Figure1.png;Was ist die Differenz zwischen dem Prozentsatz des ersten und des letzten Balkens?;What is the difference between the percentage of the first and the last bar?;31,2%;31.2%;31,2%;31.2%;Simple Calculation;'
2020.acl-main.371.pdf-Figure1.png;Wie hoch ist der durchschnittliche Prozentsatz der ersten vier Balken?;What is the average percentage of the first four bars?;57,8%;57.8%;57,8%;57.8%;Complex Calculation and Logical Reasoning;'
2020.acl-main.371.pdf-Figure1.png;Ist die Summe der Prozentsätze der Balken zwei und drei größer als der Prozentsatz des fünften Balkens?;Is the sum of the percentages of bars two and three greater than the percentage of fifth bar?;Ja;Yes;Ja;Yes;Complex Calculation and Logical Reasoning;'
2020.acl-main.371.pdf-Figure1.png;Abbildung 1 zeigt die Argumentationsabdeckung pro Anzahl der Schlüsselpunkte. Die Autoren erwähnen, dass 22,8 % der Argumente mehrdeutig sind. Wie lässt sich dieser Prozentsatz an mehrdeutigen Argumenten mit der im Text beschriebenen hohen Übereinstimmung der Annotatoren (Cohen's Kappa von 0,82 bei der Validierung durch Experten) in Einklang bringen? Welche Schlussfolgerungen lassen sich daraus für die Beziehung zwischen der Anzahl der Schlüsselpunkte und der Eindeutigkeit der Argumentzuordnung ziehen?;Figure 1 shows the argument coverage per number of key points. The paper mentions that 22.8% of the arguments are ambiguous. How does this percentage of ambiguous arguments reconcile with the high inter-annotator agreement (Cohen's Kappa of 0.82 in expert validation) mentioned in the text? What conclusions can be drawn about the relationship between the number of key points and the clarity of argument mapping?;Die 22,8 % mehrdeutigen Argumente entstanden während der anfänglichen Annotation, bei der die Annotatoren mehrere Schlüsselpunkte pro Argument auswählen konnten. Ein Argument wurde als mehrdeutig angesehen, wenn kein Schlüsselpunkt eine Übereinstimmung von 60 % erreichte. Der Cohen's Kappa von 0,82 bezieht sich auf den endgültigen, bereinigten Datensatz *nach* dem Entfernen dieser mehrdeutigen Argumente.;The 22.8% ambiguous arguments arose during initial annotation where annotators could select multiple key points per argument. An argument was deemed ambiguous if no key point reached 60% agreement.  The 0.82 Cohen's Kappa refers to the final, cleaned dataset *after* removing these ambiguous arguments.;Mehrdeutige Argumente entfernt;Ambiguous arguments removed;Requires Paper Context;'22.8% of the arguments are ambiguous. Annotations for these arguments are split over several possible key points, none reaching the 60% threshold. [...] We obtained a remarkably high Cohen’s Kappa of 0.82 (“almost perfect agreement”), validating the high quality of the dataset.'
2020.acl-main.372.pdf-Figure5.png;'Welche Farbe repräsentiert die Datenreihe 'post-filter'?';'Which color represents the data series 'post-filter'?';'Dunkelblau/Marineblau repräsentiert die Datenreihe 'post-filter'.';'Dark blue/navy represents the 'post-filter' data series.';'Dunkelblau';'Dark blue';Simple Retrieval;'
2020.acl-main.372.pdf-Figure5.png;'Wie hoch ist das Verhältnis zwischen der Anzahl der Beispiele mit einem Label 'pre-filter' und der Anzahl der Beispiele mit einem Label 'post-filter'?';'What is the ratio between the number of examples with one label for 'pre-filter' and the number of examples with one label for 'post-filter'?';Das Verhältnis beträgt etwa 8.000 / 46.000 oder ungefähr 0,17.;The ratio is approximately 8,000 / 46,000, which is about 0.17.;0,17;0.17;Simple Calculation;'
2020.acl-main.372.pdf-Figure5.png;Wie viel Prozent der gesamten Beispiele (pre-filter und post-filter zusammen) haben genau zwei Labels?;What percentage of the total examples (pre-filter and post-filter combined) have exactly two labels?;Ungefähr 24% der gesamten Beispiele haben genau zwei Labels.;Approximately 24% of the total examples have exactly two labels.;24%;24%;Simple Calculation;'
2020.acl-main.372.pdf-Figure5.png;'Ist die Summe der 'pre-filter'-Beispiele mit 0 oder 1 Label größer als die Anzahl der 'post-filter'-Beispiele mit 1 Label?';'Is the sum of the 'pre-filter' examples with 0 or 1 labels greater than the number of 'post-filter' examples with 1 label?';Nein.;No.;Nein;No;Simple Calculation;'
2020.acl-main.372.pdf-Figure5.png;Der Artikel erwähnt das Filtern von Labels basierend auf der Übereinstimmung der Bewerter. In Anbetracht dieses Filterprozesses, welcher ungefähre Prozentsatz der Beispiele aus dem ursprünglichen Datensatz (pre-filter) wurde im Trainingsdatensatz (post-filter) behalten?;The paper mentions filtering labels based on annotator agreement. Considering this filtering process, approximately what percentage of original examples from the original dataset (pre-filter) were retained in the training dataset (post-filter)?;Ungefähr 91% der ursprünglichen Beispiele wurden behalten.;Approximately 91% of the original examples were retained.;91%;91%;Caption Question/Simple Calculation;'
2020.acl-main.699.pdf-Figure8.png;Welches Jahr hat den höchsten oberen Whisker?;Which year has the highest upper whisker?;2015;2015;2015;2015;Simple Retrieval;
2020.acl-main.699.pdf-Figure8.png;Was ist der Unterschied im Wert des oberen Whiskers zwischen 2010 und 2019?;What is the difference in the value of the upper whisker between 2010 and 2019?;Ungefähr 2;Approximately 2;2;2;Simple Calculation;
2020.acl-main.699.pdf-Figure8.png;Wie viele Jahre haben einen Medianwert über 24?;How many years have a median value above 24?;3 (2014, 2016, 2018);3 (2014, 2016, 2018);3;3;Simple Calculation;
2020.acl-main.699.pdf-Figure8.png;Ist die Summe der Mediane von 2010 und 2011 größer als die Summe der Mediane von 2018 und 2019?;Is the sum of the medians of 2010 and 2011 greater than the sum of the medians of 2018 and 2019?;Nein;No;Nein;No;Simple Calculation;
2020.acl-main.699.pdf-Figure8.png;In Abschnitt B.1 wird erwähnt, dass einige Publikationen Zitate jünger als 3 Jahre aufweisen. Wie unterstützt oder widerlegt die in Abbildung 8 dargestellte Verteilung der Zitierungsalter diese Aussage? Achten Sie insbesondere auf die unteren Whisker.;Section B.1 mentions that some publications have citations younger than 3 years. How does the distribution of citation ages shown in Figure 8 support or refute this statement? Pay particular attention to the lower whiskers.;Die unteren Whisker vieler Jahre reichen recht nah an die Null heran, was auf Zitate mit einem Alter von weniger als 3 Jahren hinweist. Dies bestätigt die Aussage in Abschnitt B.1.;The lower whiskers of many years reach quite close to zero, which indicates citations with an age of less than 3 years. This confirms the statement in Section B.1.;Bestätigt;Confirms;Requires Paper Context;'Figure 8 shows the distribution of the oldest citation per paper in our dataset. [...] There are a few outliers, however: there are 15 papers in total which, according to our processing pipeline (cf. Sec. 2), do not include any citation older than 3 years. We manually check their original PDFs and find that one of these is a book review, three are extraction errors, and 11 actually do not contain any citation older than 3 years.'
W10-1203.pdf-Figure3.png;Welche Farbe stellt die Datenreihe 'raw' dar?;What color represents the 'raw' data series?;Beige oder hellgelb.;Beige or light yellow.;Beige;Beige;Simple Retrieval;'
W10-1203.pdf-Figure3.png;Wie hoch ist der Medianwert der MAP für das Abfragemodell 'and' mit der Normalisierung 'raw'?;What is the median MAP value for the 'and' query model with 'raw' normalization?;Ungefähr 0,08;Approximately 0.08;0,08;0.08;Simple Retrieval;'
W10-1203.pdf-Figure3.png;Welches Abfragemodell ('and', 'or', 'mlt') weist die größte Streuung (Differenz zwischen Maximum und Minimum) der MAP-Werte für die Normalisierung 'stem' auf?;Which query model ('and', 'or', 'mlt') shows the largest range (difference between maximum and minimum) of MAP values for the 'stem' normalization?;Das 'mlt'-Abfragemodell.;The 'mlt'-query model.;mlt;mlt;Simple Calculation;'
W10-1203.pdf-Figure3.png;Ist die Summe der Mediane der MAP-Werte für die Normalisierungen 'deplural' und 'stem' beim Abfragemodell 'or' größer als der höchste MAP-Wert für die Normalisierung 'raw' beim selben Abfragemodell?;Is the sum of the medians of MAP values for 'deplural' and 'stem' normalizations in the 'or' query model greater than the highest MAP value for the 'raw' normalization in the same query model?;Nein.;No.;Nein;No;Complex Calculation and Logical Reasoning;'
W10-1203.pdf-Figure3.png;Der Artikel erwähnt, dass die Unterschiede im MAP-Wert zwischen den Normalisierungstechniken im Allgemeinen innerhalb von 2% liegen. Betrachtet man die Interquartilbereiche der Boxplots für jedes Abfragemodell ('and', 'or', 'mlt'), bestätigen die visuellen Daten diese Aussage? Beschreiben Sie alle beobachteten Trends in Bezug auf die Effektivität der verschiedenen Normalisierungstechniken für die verschiedenen Abfragemodelle.;The paper states that differences in MAP values are generally within 2%. Analyzing the boxplot's interquartile ranges for each Query Model ('and', 'or', 'mlt'), does the visual data support this claim? Describe any observed trends related to the effectiveness of different normalization techniques across the query models.;Die Boxplot-Analyse bestätigt, dass die Unterschiede der MAP-Werte der Normalisierungstechniken ('raw', 'deplural', 'stem') innerhalb jedes Abfragemodells ('and', 'or', 'mlt') im Allgemeinen innerhalb von 2% liegen. Es zeigt auch, dass die 'raw'-Normalisierungstechnik in allen Abfragemodellen tendenziell eine etwas höhere Median-MAP aufweist.;The boxplot analysis confirms that the differences in MAP values of the normalization techniques ('raw', 'deplural', 'stem') within each query model ('and', 'or', 'mlt') are generally within 2%. It also shows that the 'raw' normalization technique tends to have a slightly higher median MAP across all query models.;Ja, raw höhere Median-MAP;Yes, raw higher median MAP;Requires Paper Context;'In general, the differences of MAP among three text normalization techniques are within 2%.'
W11-1415.pdf-Figure2.png;Was ist der höchste auf der y-Achse angezeigte Wert (Zugewiesene Punkte)?;What is the highest value displayed on the y-axis (Assigned Scores)?;100;100;100;100;Simple Retrieval;'
W11-1415.pdf-Figure2.png;Was ist die Differenz zwischen dem niedrigsten und dem höchsten auf der y-Achse angezeigten Wert?;What is the difference between the lowest and highest value displayed on the y-axis?;100;100;100;100;Simple Calculation;'
W11-1415.pdf-Figure2.png;Gibt es mehr Datenpunkte über oder unter dem Medianwert von 50? Begründen Sie Ihre Antwort anhand visueller Details im Diagramm.;Are there more data points above or below the median value of 50? Justify your answer by referring to visual details in the chart.;Es scheinen etwas mehr Datenpunkte oberhalb des Medians von 50 zu liegen. Obwohl die Verteilung relativ gleichmäßig ist, ist in der oberen Hälfte des Diagramms eine etwas höhere Punktdichte zu beobachten.;Slightly more data points appear above the median of 50. Although the distribution is relatively even, a slightly higher density can be observed in the upper half of the plot.;Mehr oberhalb;More above;Complex Calculation and Logical Reasoning;'
W11-1415.pdf-Figure2.png;Der Text erwähnt, dass einige Bewerter eine grobkörnigere Bewertungsstrategie verwendet haben (z. B. Vielfache von 10 oder 20). Welcher visuelle Hinweis im Diagramm stützt diese Aussage?;The text mentions that some annotators used a more coarse-grained scoring strategy (e.g., multiples of 10 or 20). What visual cue in the chart supports this statement?;In Abbildung 2 ist der visuelle Hinweis, der die Aussage über die Verwendung einer gröberen Bewertungsmethode durch die Bewerter stützt, das Vorhandensein vertikaler Punktcluster in regelmäßigen Abständen entlang der y-Achse. Diese Cluster, besonders auffällig bei Vielfachen von 10 oder 20, deuten darauf hin, dass einige Bewerter Bewertungen in diesen Schritten vergeben haben, anstatt einen feiner abgestuften Ansatz zu verwenden.;In Figure 2, the visual cue that supports the statement about annotators using a more coarse-grained scoring strategy is the presence of vertical clusters of points at regular intervals along the y-axis. These clusters, particularly noticeable at multiples of 10 or 20, indicate that some annotators assigned scores in these increments rather than using a more fine-grained approach.;Vertikale Cluster;Vertical clusters;Caption Question/Simple Retrieval;'
W12-0703.pdf-Figure6.png;Welcher Wert wird durch den Median des ersten Boxplots dargestellt (Anzahl der wiederholten Inferenzen = 1)?;What value is represented by the median of the first boxplot (number of repeated inferences = 1)?;Ungefähr 0.027;Approximately 0.027;0.027;0.027;Simple Retrieval;'
W12-0703.pdf-Figure6.png;Wie groß ist die Differenz zwischen dem höchsten und dem niedrigsten Wert im Boxplot für 20 wiederholte Inferenzen (inklusive Whisker)?;Wie groß ist die Differenz zwischen dem höchsten und dem niedrigsten Wert im Boxplot für 20 wiederholte Inferenzen (inklusive Whisker)?;Ungefähr 0,01;Approximately 0.01;0.01;0.01;Simple Calculation;'
W12-0703.pdf-Figure6.png;Ist die Summe der Mediane für 1 und 3 wiederholte Inferenzen größer als der Median für 5 wiederholte Inferenzen?;Is the sum of the medians for 1 and 3 repeated inferences greater than the median for 5 repeated inferences?;Ja.;Yes.;Ja;Yes;Simple Calculation;'
W12-0703.pdf-Figure6.png;Welcher Wert wird durch den höchsten und niedrigsten Mittelwert (schwarze Punkte) über alle Boxplots hinweg dargestellt und bei welcher Anzahl an Inferenzen treten diese jeweils auf?;What are the highest and lowest mean values (represented by black dots) across all boxplots, and how many inferences correspond to each of these values?;Der höchste Mittelwert liegt bei etwa 0,028 mit 1 wiederholter Inferenz. Der niedrigste Mittelwert liegt bei etwa 0,012 mit 20 wiederholten Inferenzen.;The highest mean value is approximately 0.028 with 1 repeated inference. The lowest mean value is approximately 0.012 with 20 repeated inferences.;"0.028/1;0.028/1";"0.012/20;0.012/20";Simple Retrieval;'
W12-0703.pdf-Figure6.png;Laut Abschnitt 5.3 führt eine höhere Anzahl von Inferenzläufen (r) zu einer Verringerung der Varianz und des Pk-Fehlers. In welchem Bereich von r ist die Verbesserung der Segmentierungsleistung am größten, und wo zeigen sich abnehmende Grenzerträge, wie in Abbildung 6 dargestellt?;According to section 5.3, increasing the number of inference runs (r) decreases both variance and Pk error.  Looking at Figure 6, between which values of r is the improvement in segmentation performance most significant, and where do diminishing returns become apparent?;Die deutlichste Verbesserung tritt zwischen r=1 und r=3 auf. Abnehmende Grenzerträge sind für Werte von r größer als 3 zu beobachten, mit relativ geringeren Abnahmen des Pk-Werts und der Varianz bei weiter steigendem r.;The most significant improvement occurs between r=1 and r=3. Diminishing returns are observed for values of r greater than 3, with relatively smaller decreases in the Pk value and variance as r increases further.;1-3;1-3;Requires Paper Context;'To decrease this variance, we assign the topic not only from a singe inference run, but repeat the inference calculations several times, denoted by the parameter r. Then the frequency of assigned topic IDs per token is counted across the r runs, and we assign the most frequent topic ID (frequency ties are broken randomly). The box plot for several evaluated values of r is shown in Figure 6. This log-scaled plot shows that both variance and Pk error rate can be substantially decreased. Already for r = 3, we observe a significant improvement in comparison to the default setting of _r = 1 and with increasing r values, the error rates_ are reduced even more: for r = 20, variance and error rates are is cut in less than half of their original values using this simple operation.'
W13-4011.pdf-Figure3.png;Wo befindet sich der Ausreißer im Boxplot?;Where is the outlier located in the boxplot?;Oberhalb des oberen Whisker.;Above the upper whisker.;Oberhalb;Above;Simple Retrieval;'
W13-4011.pdf-Figure3.png;Was ist der Interquartilsabstand (IQR)?;What is the interquartile range (IQR)?;Ungefähr 100 (300-200).;Approximately 100 (300-200).;100;100;Simple Calculation;'
W13-4011.pdf-Figure3.png;Ist der Abstand zwischen dem Ausreißer und dem oberen Whisker größer als der Interquartilsabstand?;Is the distance between the outlier and the upper whisker greater than the interquartile range?;Nein.;No.;Nein;No;Simple Calculation;'
W13-4011.pdf-Figure3.png;Um wie viel Prozent liegt der Median über dem unteren Whisker?;By what percentage is the median greater than the lower whisker?;Der Median liegt bei etwa 240 und der untere Whisker bei etwa 140. Die Differenz beträgt 100. 100/140 * 100% = ungefähr 71%.;The median is approximately 240 and the lower whisker is approximately 140. The difference is 100. 100/140 * 100% = approximately 71%. ;71%;71%;Simple Calculation;'
W13-4011.pdf-Figure3.png;'Der Text erwähnt 'einen schönen Schwung von Sprechern im Bereich von 200-300'. In welchem Bereich des Boxplots befinden sich diese Sprecher, und welche zwei Faktoren führen laut Text zu der großen Streuung der Daten, insbesondere im oberen Bereich?';'The text mentions 'a nice batch of speakers in the 200-300 range.' Where in the boxplot are these speakers located, and according to the text, what two factors contribute to the wide spread of the data, particularly in the higher range?';Diese Sprecher befinden sich innerhalb der Box des Boxplots, die den Interquartilsabstand (ca. 200-300) darstellt. Die große Streuung, insbesondere im oberen Bereich, wird auf zwei Faktoren zurückgeführt: 1) Einige Teilnehmer produzieren eine große Menge an Feedback-Äußerungen, insbesondere kurze Rückmeldungen wie 'mh' und 'ouais'. 2) Mindestens ein Ausreißer-Sprecher produzierte ein hohes Feedback-Volumen, weil er seltener am Wort war.;These speakers are located within the box of the boxplot, which represents the interquartile range (approximately 200-300). The wide spread, especially in the upper range, is attributed to two factors: 1) Some participants produce a high quantity of feedback items, especially light backchannels like 'mh' and 'ouais.' 2) At least one outlier speaker produced a high volume of feedback because they held the floor less often.;Box;Box;Caption Question/Complex Calculation and Logical Reasoning;'
W14-0201.pdf-Figure5.png;Welches Label steht unter dem zweitlinkesten Balken?;What label is under the second bar from the left?;Like;Like;Like;Like;Simple Retrieval;'
W14-0201.pdf-Figure5.png;Was ist der ungefähre Unterschied zwischen dem höchsten und dem niedrigsten Balkenwert?;What is the approximate difference between the highest and the lowest bar value?;Ungefähr 3,5;Approximately 3.5;3,5;3.5;Simple Calculation;'
W14-0201.pdf-Figure5.png;'Was ist die Summe der drei Balkenwerte von 'Like', 'Cog Dem' und 'Ann'?';What is the sum of the bar values for 'Like', 'Cog Dem', and 'Ann'?;Ungefähr 0,5;Approximately 0.5;0,5;0.5;Complex Calculation and Logical Reasoning;'
W14-0201.pdf-Figure5.png;Ist die Summe der positiven Balkenwerte größer als der Absolutwert der Summe der negativen Balkenwerte?;Is the sum of the positive bar values greater than the absolute value of the sum of the negative bar values?;Ja;Yes;Ja;Yes;Complex Calculation and Logical Reasoning;'
W14-0201.pdf-Figure5.png;Die Balken stellen die SASSI Usability-Werte dar. Der Text erwähnt, dass geringere Störbarkeit die Usability erhöht. Welche Dimension hat den niedrigsten Wert und wie steht dieser Wert im Einklang mit der Aussage im Text?;The bars represent SASSI usability scores. The text mentions that lower annoyance increases usability. Which dimension has the lowest value, and how does this value align with the statement in the text?;Störbarkeit (Ann) hat den niedrigsten Wert mit ungefähr -1,75. Dieser negative Wert stimmt mit der Aussage im Text überein, da ein weniger störendes System zu einer besseren Usability beiträgt. Ein negativer Wert steht für geringe Störbarkeit und wirkt sich daher positiv auf die Gesamt-Usability aus.;Annoyance (Ann) has the lowest value at approximately -1.75. This negative value aligns with the statement in the text, as a less annoying system contributes to better usability.  A negative value represents low annoyance, therefore positively affecting overall usability.;Ann;-1,75;Caption Question/Complex Calculation and Logical Reasoning;'
W14-33.pdf-Figure10.png;Welches Boxplot hat den kleinsten Interquartilsabstand?;Which boxplot has the smallest interquartile range?;DCU;DCU;DCU;DCU;Simple Retrieval;'
W14-33.pdf-Figure10.png;'Was ist der Unterschied zwischen den Medianwerten der Boxplots für 'uedin-h' und 'Shef'?';'What is the difference between the median values of the boxplots for 'uedin-h' and 'Shef'?';12;12;12;12;Simple Calculation;'
W14-33.pdf-Figure10.png;Wie viele Boxplots haben einen Medianwert größer als 6?;How many boxplots have a median value greater than 6?;7;7;7;7;Simple Calculation;'
W14-33.pdf-Figure10.png;Wie viele Boxplots liegen vollständig oberhalb der gestrichelten Linie bei Wert 8?;How many boxplots lie completely above the dashed line at value 8?;5;5;5;5;Simple Calculation;'
W14-33.pdf-Figure10.png;Abbildung 10 zeigt die Ergebnisse der Clusterbildung durch das TrueSkill-Modell. Das Paper erwähnt, dass gestrichelte Linien Systeme mit nicht überlappenden Rangbereichen trennen und die Daten in Cluster aufteilen. Wie viele Cluster gibt es laut Abbildung 10?;Figure 10 shows the results of clustering by the TrueSkill model. The paper mentions that dashed lines separate systems with non-overlapping rank ranges, splitting the data into clusters. According to Figure 10, how many clusters are there?;4;4;4;4;Caption Question/Simple Calculation;'
2015.jeptalnrecital-long.18.pdf-Figure5.png;Wie viele Spalten enthält die Matrix ganz links?;How many columns does the leftmost matrix have?;6;6;6;6;Simple Retrieval;
2015.jeptalnrecital-long.18.pdf-Figure5.png;Was ist die Differenz zwischen dem Wert in der zweiten Zeile und dritten Spalte der Matrix ganz links und dem Wert in der dritten Zeile und zweiten Spalte derselben Matrix?;What is the difference between the value in the second row and third column of the leftmost matrix and the value in the third row and second column of the same matrix?;0,79;0.79;0,79;0.79;Simple Calculation;
2015.jeptalnrecital-long.18.pdf-Figure5.png;Was ist der Durchschnitt aller Werte in der Matrix ganz rechts, die größer als 94 sind?;What is the average of all values in the rightmost matrix that are greater than 94?;94,92;94.92;94,92;94.92;Complex Calculation and Logical Reasoning;
2015.jeptalnrecital-long.18.pdf-Figure5.png;Ist die Summe der Werte in der zweiten Zeile der Matrix ganz links größer als die Summe der Werte in der dritten Zeile der Matrix in der Mitte?;Is the sum of the values in the second row of the leftmost matrix greater than the sum of the values in the third row of the matrix in the middle?;Ja;Yes;Ja;Yes;Complex Calculation and Logical Reasoning;
2015.jeptalnrecital-long.18.pdf-Figure5.png;'In Abbildung 5 werden vier Methoden zur Verwendung von Motiven als Merkmale verglichen. Benötigt man zusätzliche Informationen aus dem Paper, um zu verstehen, welche Methode 'poids : répet. du 2ème ordre' darstellt und wie sie sich von den anderen unterscheidet?';'Figure 5 compares four methods of using motifs as features. Do you need additional information from the paper to understand what the method 'poids : répet. du 2ème ordre' represents and how it differs from the others?';'Ja, die Bildunterschrift und der Titel erklären 'poids : répet. du 2ème ordre' nicht vollständig. Das Paper stellt klar, dass es sich um 'maximale Wiederholungen, gewichtet nach Wiederholungen zweiter Ordnung' handelt, und unterscheidet sie von maximalen Wiederholungen, N-Grammen und maximalen Wiederholungen, gewichtet nach Länge.';'Yes, the figure caption and title don't fully explain 'poids : répet. du 2ème ordre.' The paper clarifies that it refers to 'maximal repetitions weighted by second-order repetitions,' distinguishing it from maximal repetitions, n-grams, and maximal repetitions weighted by length.';Ja;Yes;Requires Paper Context;'Chaque Ri est une répétition maximale utilisée comme trait et S est l’ensemble des textes des auteurs analysés. Avec S = {S0, . . ., Sn−1}, R l’ensemble des répétitions maximales calculées à partir de S et R[2] l’ensemble des répétitions maximales calculées à partir de R, chaque répétition maximale dans R est pondérée à partir de l’ensemble des répétitions maximales de R[2].'
2015.jeptalnrecital-long.18.pdf-Figure7.png;Welche Zahl steht in der zweiten Zeile von oben und der zweiten Spalte von links in der ersten Matrix?;What number is in the second row from the top and the second column from the left in the first matrix?;80,35;80.35;80,35;80.35;Simple Retrieval;'
2015.jeptalnrecital-long.18.pdf-Figure7.png;Was ist die Differenz zwischen dem Wert in der Zelle in der dritten Zeile von oben und der vierten Spalte von links und dem Wert in der fünften Zeile von oben und der ersten Spalte von links in der zweiten Matrix?;What is the difference between the value in the cell in the third row from the top and the fourth column from the left and the value in the fifth row from the top and the first column from the left in the second matrix?;15,28;15.28;15,28;15.28;Simple Calculation;'
2015.jeptalnrecital-long.18.pdf-Figure7.png;Was ist der Durchschnitt aller Werte in der vierten Matrix?;What is the average of all values in the fourth matrix?;79,68;79.68;79,68;79.68;Complex Calculation and Logical Reasoning;'
2015.jeptalnrecital-long.18.pdf-Figure7.png;Ist der höchste Wert in der ersten Matrix größer als der höchste Wert in der dritten Matrix?;Is the highest value in the first matrix greater than the highest value in the third matrix?;Nein, 81.58 < 81.68;No, 81.58 < 81.68;Nein;No;Simple Calculation;'
2015.jeptalnrecital-long.18.pdf-Figure7.png;Die Tabelle 4 zeigt, dass 'motifs2nd' im Durchschnitt am besten abschneidet. Betrachtet man die entsprechende Heatmap in Abbildung 7, welcher Trend lässt sich hinsichtlich der Performance in Bezug auf die minimale und maximale Länge der Wiederholungen erkennen? Begründen Sie Ihre Antwort anhand der Schattierung in der Heatmap.;Table 4 shows that 'motifs2nd' performs best on average. Looking at the corresponding heatmap in Figure 7, what trend can be observed regarding performance in relation to the minimum and maximum length of repetitions? Justify your answer based on the shading in the heatmap.;Die Heatmap für 'motifs2nd' (ganz rechts) zeigt die höchste Leistung (dunkelste Schattierung) um eine maximale Länge von 5. Eine Erhöhung der Mindestlänge verbessert im Allgemeinen die Leistung, aber der Einfluss der maximalen Länge ist weniger eindeutig. Der höchste Wert (83,39) liegt bei min=4 und max=5, während die Werte für max=6 durchweg niedriger sind. Eine Erhöhung der maximalen Länge führt nicht immer zu einer Leistungssteigerung.;The heatmap for 'motifs2nd' (rightmost) shows the highest performance (darkest shading) around a maximum length of 5.  Increasing minimum length generally improves performance, but the influence of maximum length is less clear.  The highest value (83.39) is at min=4 and max=5, while values for max=6 are consistently lower.  Increasing maximum length does not always improve performance.;max=5 am besten;max=5 best;Complex Calculation and Logical Reasoning;'
S19-2112.pdf-Figure2.png;Welche Beschriftung befindet sich in der unteren linken Ecke des Diagramms?;What label is in the bottom left corner of the diagram?;OTH, GRP;OTH, GRP;OTH, GRP;OTH, GRP;Simple Retrieval;'
S19-2112.pdf-Figure2.png;Wie hoch ist die Differenz zwischen den Werten für die korrekte Klassifizierung von GRP und IND?;What is the difference between the values for the correct classification of GRP and IND?;17;17;17;17;Simple Calculation;'
S19-2112.pdf-Figure2.png;Wie hoch ist der Durchschnittswert der Zellen in der mittleren Reihe (gerundet auf eine ganze Zahl)?;What is the average value of the cells in the middle row (rounded to the nearest whole number)?;33;33;33;33;Simple Calculation;'
S19-2112.pdf-Figure2.png;Wie viel Prozent der IND-Tweets wurden korrekt klassifiziert?;What percentage of IND tweets were classified correctly?;71%;71%;71%;71%;Simple Retrieval;'
S19-2112.pdf-Figure2.png;Der Artikel erwähnt, dass es Menschen schwerfällt, zwischen GRP und OTH zu unterscheiden. Welcher Wert in der Konfusionsmatrix verdeutlicht diese Schwierigkeit und warum?;The paper mentions that humans struggle to differentiate between GRP and OTH. Which value in the confusion matrix highlights this difficulty, and why?;Der Wert 16 in der unteren linken Zelle der Matrix verdeutlicht diese Schwierigkeit. Er repräsentiert die Anzahl der OTH-Tweets, die fälschlicherweise als GRP klassifiziert wurden, und zeigt die Überschneidung zwischen diesen Kategorien, die sie selbst für Menschen schwer zu unterscheiden macht.;The value 16 in the bottom left cell of the matrix highlights this difficulty. It represents the number of OTH tweets misclassified as GRP, indicating the overlap between these categories that makes them difficult to distinguish, even for humans.;16;16;Requires Paper Context;'Figure 2 shows the confusion matrix for the best performing system. As can be seen, most tweets of GRP and IND are classified correctly, whereas almost half of the OTH tweets are incorrectly recognized as GRP. On the one hand, the rare class occurence in the training seems to obstruct the classifier in learning. On the other hand, it was challenging for us as humans to differentiate between the classes GRP and OTH in the data set: For instance ”Liberals are mentally ill!” is labeled as GRP, whereas ”@USER republicans/conservatives are the most disgusting people” has label OTH.'
S19-2116.pdf-Figure4.png;Welche Beschriftung befindet sich in der linken unteren Ecke der Matrix?;What label is located in the bottom left corner of the matrix?;UNT, TIN;UNT, TIN;UNT, TIN;UNT, TIN;Simple Retrieval;
S19-2116.pdf-Figure4.png;Was ist die Summe der beiden Zahlen in der unteren Zeile?;What is the sum of the two numbers in the bottom row?;27;27;27;27;Simple Calculation;
S19-2116.pdf-Figure4.png;Was ist die Summe aller Werte in der Konfusionsmatrix?;What is the sum of all the values in the confusion matrix?;240;240;240;240;Simple Calculation;
S19-2116.pdf-Figure4.png;Wie viel größer ist der Wert in der oberen linken Ecke im Vergleich zur oberen rechten Ecke?;How much larger is the value in the top left corner compared to the top right corner?;209;209;209;209;Simple Calculation;
S19-2116.pdf-Figure4.png;In Abschnitt 4.2 wird der Einfluss von Satzstrukturen auf die Erkennung von zielgerichteter beleidigender Sprache erläutert. Anhand der Konfusionsmatrix: Welcher Zusammenhang könnte zwischen der hohen Anzahl korrekt klassifizierter TIN-Tweets und den in 4.2 genannten Satzmerkmalen bestehen?;Section 4.2 discusses the impact of sentence structures on identifying targeted offensive language. Considering the confusion matrix: What connection could exist between the high number of correctly classified TIN tweets and the sentence features mentioned in 4.2?;'Die hohe Anzahl (211) korrekt klassifizierter TIN-Tweets deutet darauf hin, dass die in 4.2 erwähnten Satzmerkmale (Pronomen der dritten Person, '@'-Erwähnungen und Hashtags) in TIN-Tweets häufig vorkommen und von der MSOC-Methode effektiv zur Identifizierung genutzt werden.';'The high number (211) of correctly classified TIN tweets suggests that the sentence features mentioned in 4.2 (third-person pronouns, '@' mentions, and hashtags) are prevalent in TIN tweets and effectively used by the MSOC method for identification.';Häufigkeit Satzmerkmale;Prevalent sentence features;Requires Paper Context;'The behavior of MSOC method defeats RNN method from all aspects (see Table 3 and Figure 3, 4) when categorizing the types of offense. This is because usually targeted offensive language have different sentence structure with untargetted ones, this make it a really high accuracy approach to categorize offensive type. In details, a target sentence always contains third-person pronouns like him her it them. And in most target tweets, the sentence has some special punctuation like @ and also related to some hot topics #.'
S19-2127.pdf-Figure2.png;Was ist die Beschriftung der vertikalen Achse?;What is the label of the vertical axis?;Wahres Label;True label;Wahres Label;True label;Simple Retrieval;'
S19-2127.pdf-Figure2.png;Was ist die Summe der Werte in der ersten Zeile?;What is the sum of the values in the first row?;620;620;620;620;Simple Calculation;'
S19-2127.pdf-Figure2.png;Wie hoch ist der Prozentsatz der korrekt vorhergesagten OFF-Labels im Vergleich zu allen wahren OFF-Labels?;What is the percentage of correctly predicted OFF labels compared to all true OFF labels?;67,08%;67.08%;67,08%;67.08%;Simple Retrieval;'
S19-2127.pdf-Figure2.png;Ist die Summe der falsch positiven und falsch negativen Vorhersagen größer als die Summe der richtig positiven und richtig negativen Vorhersagen?;Is the sum of the false positive and false negative predictions greater than the sum of the true positive and true negative predictions?;Nein. 139 ist kleiner als 721.;No. 139 is less than 721.;Nein;No;Simple Calculation;'
S19-2127.pdf-Figure2.png;'Der Artikel erwähnt Schwierigkeiten bei der Erkennung indirekter Beleidigungen. In welchem Feld der Konfusionsmatrix in Abbildung 2 würden sich fälschlicherweise als 'NICHT BELEIDIGEND' klassifizierte indirekte Beleidigungen befinden? Erläutern Sie Ihre Argumentation.';'The paper mentions difficulties in detecting indirect insults. Which cell of the confusion matrix in Figure 2 would likely contain misclassified indirect insults where the model incorrectly predicted 'NOT OFFENSIVE'? Explain your reasoning.';Falsch negative, was der unteren linken Zelle der Konfusionsmatrix entspricht. Indirekte Beleidigungen sind wirklich beleidigend (OFF). Wenn sie falsch als NICHT BELEIDIGEND klassifiziert werden, sind sie falsch negativ.;False negatives, which corresponds to the bottom-left cell of the confusion matrix.  Indirect insults are truly offensive (OFF). If misclassified as NOT OFFENSIVE, then they are false negatives.;Falsch negativ;False negative;Requires Paper Context;"On the contrary, our approach falls short when confronted with indirect insults.

“@USER @USER Im sure the air that he is breathing is also bad.”

Our model wrongly predicts a non-offensive tweet in this instance."
S19-2133.pdf-Figure3.png;Welche Beschriftung befindet sich in der unteren linken Ecke der Konfusionsmatrix?;What label is located in the bottom left corner of the confusion matrix?;OTH, GRP;OTH, GRP;OTH, GRP;OTH, GRP;Simple Retrieval;'
S19-2133.pdf-Figure3.png;Was ist die Summe der Werte in der ersten Zeile der Konfusionsmatrix?;What is the sum of the values in the first row of the confusion matrix?;78;78;78;78;Simple Calculation;'
S19-2133.pdf-Figure3.png;Wie hoch ist das Verhältnis des größten zum kleinsten Wert in der Konfusionsmatrix?;What is the ratio of the largest to the smallest value in the confusion matrix?;3,76;3.76;3,76;3.76;Simple Calculation;'
S19-2133.pdf-Figure3.png;Ist die Summe der Werte in der mittleren Spalte größer als die Summe der Werte in der ersten Zeile der Konfusionsmatrix?;Is the sum of the values in the middle column greater than the sum of the values in the first row of the confusion matrix?;Ja, 126 > 78;Yes, 126 > 78;Ja;Yes;Simple Calculation;'
S19-2133.pdf-Figure3.png;Betrachtet man den F1-Makrowert des BiLSTM für Teilaufgabe C und die Konfusionsmatrix in Abbildung 3, welcher Klassifizierungsfehler (GRP, IND oder OTH) scheint für das BiLSTM-Modell am häufigsten vorzukommen, und was könnte dies über seine Leistung aussagen?;Considering the BiLSTM F1 macro score for Sub-task C and analyzing the confusion matrix in Figure 3, which classification error (GRP, IND, or OTH) seems most prevalent for the BiLSTM model, and what might this suggest about its performance?;Der häufigste Klassifizierungsfehler ist, dass GRP als IND (44 Instanzen) falsch klassifiziert wird. Dies deutet darauf hin, dass das BiLSTM-Modell Schwierigkeiten hat, zwischen diesen beiden Kategorien zu unterscheiden, möglicherweise aufgrund ähnlicher zugrunde liegender Merkmale oder Kontexte.;The most prevalent classification error is GRP being misclassified as IND (44 instances). This suggests the BiLSTM model has difficulty distinguishing between these two categories, possibly due to similar underlying characteristics or contexts.;GRP als IND;GRP as IND;Complex Calculation and Logical Reasoning;'
S19-2136.pdf-Figure1.png;Welche Beschriftung befindet sich links neben dem dunkelsten Quadrat?;What label is to the left of the darkest square?;TIN;TIN;TIN;TIN;Simple Retrieval;'
S19-2136.pdf-Figure1.png;Was ist die Summe der Werte in der oberen Zeile?;What is the sum of the values in the top row?;213;213;213;213;Simple Calculation;'
S19-2136.pdf-Figure1.png;Ist die Summe der Werte in der Hauptdiagonale größer als die Summe der Werte in der Nebendiagonale?;Is the sum of the values in the main diagonal greater than the sum of the values in the anti-diagonal?;Ja, 210 > 30;Yes, 210 > 30;Ja;Yes;Simple Calculation;'
S19-2136.pdf-Figure1.png;Wie ist das Verhältnis des zweitgrößten Wertes zum kleinsten Wert?;What is the ratio of the second largest value to the smallest value?;17/13 (oder ungefähr 1,31);17/13 (or approximately 1.31);17/13;17/13;Simple Calculation;'
S19-2136.pdf-Figure1.png;In Abschnitt 6 wird die höhere Präzision für gezielte Bedrohungen und die etwas höhere Anzahl falsch negativer Ergebnisse im Vergleich zu falsch positiven Ergebnissen (wie in Abbildung 1 dargestellt) erörtert. Erklären Sie, wie diese Beobachtungen mit der Leistung von Modell A auf den in Tabelle 4 dargestellten Testdaten zusammenhängen. Stimmt die visuelle Darstellung in der Konfusionsmatrix mit den numerischen Ergebnissen überein?;Section 6 discusses the higher precision for targeted threats and the slightly higher false negatives compared to false positives (as shown in Figure 1). Explain how these observations relate to the performance of Model A on the test data presented in Table 4. Does the visual representation in the confusion matrix align with the numerical results?;Die Konfusionsmatrix bestätigt visuell die höhere Präzision für gezielte Bedrohungen (TIN). Das große dunkle Quadrat (196) veranschaulicht dies. Falsch negative (13) sind etwas höher als falsch positive (17). Tabelle 4 zeigt eine TIN-Präzision von 0,9378 und einen UNT-Recall von 0,5185, was diese Beobachtungen unterstützt. Die visuelle Darstellung stimmt mit den numerischen Daten überein.;The confusion matrix visually confirms the higher precision for targeted threats (TIN). The large dark square (196) demonstrates this.  False negatives (13) are slightly higher than false positives (17). Table 4 shows a TIN precision of 0.9289 and a UNT recall of 0.5185, supporting these observations. The visual representation aligns with the numerical data.;Stimmt überein;Aligns;Requires Paper Context;"**Targeted** **Untargeted** **Dataset** **Models**

**Macro** **Precision** **Recall** **F1** **Precision** **Recall** **F1** **F1 score**



**XGBoost (SMOTE)** 0.9004 **0.9765** 0.9369 0.4444 0.1481 0.2222 0.57958 **TEST** **Model A** **0.9378** 0.9202 0.9289 0.4516 **0.5185** **0.4828** **0.70583**

**Model B** 0.9079 0.9718 **0.9388** **0.5000** 0.2222 0.3077 0.62323

Table 4: Sub-Task B: Best ensemble model results. We reproduce XGBoost results from Table 3 for comparison.

In order to further understand the results on the test set, we investigate the predictions made by our models across the two sub-tasks. For the purpose, we provide simple visualizations of the confusion matrices of predictions acquired by our best models as released by organizers. **Sub-Task B. Figure 1 shows that our model has** higher precision for the targeted threats, which is also clear from Table 4 presented earlier. Figure 1 also shows that our model has slightly higher false negatives as compared to false positives. In other words, the chances of our model mislabeling a targeted tweet as untargeted is slightly higher as compared to predicting an untargeted tweet as _targeted._"
S19-2140.pdf-Figure3.png;Welche Beschriftung befindet sich auf der vertikalen Achse?;What is the label of the vertical axis?;Wahre Beschriftung;True label;Wahre Beschriftung;True label;Simple Retrieval;'
S19-2140.pdf-Figure3.png;'Wie hoch ist der Wert in der Zelle, die 'NOT' (wahre Beschriftung) und 'OFF' (vorhergesagte Beschriftung) entspricht?';'What is the value in the cell corresponding to 'NOT' (true label) and 'OFF' (predicted label)?';18;18;18;18;Simple Retrieval;'
S19-2140.pdf-Figure3.png;Was ist die Summe der Werte in der ersten Zeile der Konfusionsmatrix?;What is the sum of the values in the first row of the confusion matrix?;620;620;620;620;Simple Calculation;'
S19-2140.pdf-Figure3.png;'Ist die Summe der Werte in den Zellen mit 'NOT' als wahre Beschriftung größer als die Summe der Werte in den Zellen mit 'OFF' als wahre Beschriftung?';'Is the sum of the values in the cells with 'NOT' as the true label greater than the sum of the values in the cells with 'OFF' as the true label?';Ja, 620 > 240;Yes, 620 > 240;Ja;Yes;Simple Calculation;'
S19-2140.pdf-Figure3.png;Der Artikel erwähnt eine große Anzahl falsch-negativer Ergebnisse. Welche Werte in der Konfusionsmatrix tragen zu dieser Beobachtung bei und wie hängt dies mit der im Text beschriebenen Gesamtperformance des Modells zusammen?;The paper mentions a large amount of false negatives.  Which specific values in the confusion matrix contribute to this observation, and how does this relate to the model's overall performance as described in the text?;'Der Wert 209 stellt falsch-negative Ergebnisse dar (wahre Beschriftung 'OFF', vorhergesagt 'NOT'). Dies stimmt mit der Erwähnung im Artikel über die schlechte Leistung (93./103) und die Tendenz zur Vorhersage von 'NOT' überein.';'The value 209 represents false negatives (true label 'OFF', predicted 'NOT'). This aligns with the paper's mention of poor performance (93rd/103) and a bias towards predicting 'NOT'.';209;209;Requires Paper Context;"The confusion matrix of UTFPR-Reuse in Figure 3 shows that the main reason behind this poor showing was the large amount of false negatives predicted.

As it can be noticed, our system did not perform very well, placing 93rd out of 103 teams."
U15-1009.pdf-Figure1.png;Welches Label steht neben dem ersten Dreieck in der obersten Reihe?;What label is next to the first triangle in the top row?;20 Dimensionen;20 dimensions;20 Dimensionen;20 dimensions;Simple Retrieval;'
U15-1009.pdf-Figure1.png;Wie viele Dreiecke gibt es insgesamt in der Abbildung?;How many triangles are there in total in the figure?;12;12;12;12;Simple Calculation;'
U15-1009.pdf-Figure1.png;Ist der mittlere Abschnitt des Dreiecks für den Bericht über häusliche Gewalt bei 20 Dimensionen heller oder dunkler als der entsprechende Abschnitt bei 300 Dimensionen?;Is the middle section of the Domestic Violence report triangle at 20 dimensions lighter or darker than the corresponding section at 300 dimensions?;Dunkler;Darker;Dunkler;Darker;Simple Calculation;'
U15-1009.pdf-Figure1.png;Vergleichen Sie die Dreiecke für den Bericht über Geburtshelferinnen bei 20, 50, 100 und 300 Dimensionen. Welches dieser Dreiecke weist die deutlichsten horizontalen und vertikalen Streifen auf, die ein Gittermuster bilden, insbesondere im oberen Teil des Dreiecks?;Compare the Midwives report triangles at 20, 50, 100, and 300 dimensions. Which of these triangles shows the most distinct horizontal and vertical stripes forming a grid pattern, particularly in the upper portion of the triangle?;Das Dreieck bei 20 Dimensionen.;The triangle at 20 dimensions.;20 Dimensionen;20 dimensions;Simple Retrieval;'
U15-1009.pdf-Figure1.png;'Der Text erwähnt 'Motive' in den Lex-Plots. Im Zusammenhang mit dem Bericht über häusliche Gewalt werden helle Streifen, die das Diagramm durchkreuzen, als ein solches Motiv genannt.  Anhand des Plots mit 300 Dimensionen und des entsprechenden Textabschnitts, erklären Sie, wie die Satzlänge die Darstellung im Lex-Plot beeinflusst und welche Einschränkung der Methode dadurch hervorgehoben wird.';'The text mentions 'motifs' in the Lex plots. Regarding the Domestic Violence report, pale stripes crisscrossing the plot are mentioned as one such motif. Using the 300-dimension plot and the corresponding text section, explain how sentence length affects the visualization in the Lex plot and what limitation of the method this highlights.';Im Bericht über häusliche Gewalt führen längere Sätze im 300-Dimensionen-Plot zu dichteren und breiteren Streifen, während kürzere Sätze schmalere und weniger ausgeprägte Streifen erzeugen. Dies zeigt, dass die Methode empfindlich auf Satzlängen reagiert und die Konsistenz der Ergebnisse sowie die Vergleichbarkeit der Kohäsionsmuster zwischen Texten mit unterschiedlichen Satzlängen beeinträchtigt werden können.;In the domestic violence report, longer sentences in the 300-dimension plot lead to denser and wider stripes, while shorter sentences produce narrower and less pronounced stripes. This shows that the method is sensitive to sentence length and the consistency of the results, as well as the comparability of cohesion patterns between texts with different sentence lengths, can be affected.;Satzlänge beeinflusst Streifendichte;Sentence length affects stripe density;Requires Paper Context;'Although these may present at first glance as problematic low cohesion, on closer inspection, they are actually false alarms—or at least, examples of when lexical cohesion alone cannot always tell the whole cohesion story. Almost all are quite short sentences: for example, sentence 27 reads ‘It must not be accepted or excused’. Shorter sentences obviously provide fewer opportunities for content words to occur, which in turn provides fewer opportunities for lexical repetition—though other forms of cohesion may be present, such as the co-reference occurring in sentence 27 with the word ‘it’. This highlights a limitation of the method, which we may need to address in future iterations of Lex by normalising for sentence length. Nevertheless, these short sentences are justifiably detected by the algorithm as having little to no semantic similarity to other sentences in the text, and are represented prominently in the visualisation at 300 dimensions, so we have included them in our definition of a motif for the purposes of this exercise.'
W15-29.pdf-Figure7.png;Welche Kategorie nimmt die größte Fläche im Baumdiagramm ein?;Which category occupies the largest area in the treemap?;levity;levity;levity;levity;Simple Retrieval;'
W15-29.pdf-Figure7.png;'Um wie viel größer ist der Wert von 'alarm' als der Wert von 'pitfall'?';'How much greater is the value of 'alarm' than the value of 'pitfall'?';2;2;2;2;Simple Calculation;'
W15-29.pdf-Figure7.png;Was ist die Summe der Werte der beiden kleinsten Kategorien im Baumdiagramm?;What is the sum of the values of the two smallest categories in the treemap?;455;455;455;455;Complex Calculation and Logical Reasoning;'
W15-29.pdf-Figure7.png;'Ist die Summe der Werte von 'alarm' und 'pitfall' größer als die Summe der Werte von 'levity' und 'revenge'?';'Is the sum of the values of 'alarm' and 'pitfall' greater than the sum of the values of 'levity' and 'revenge'?';Ja;Yes;Ja;Yes;Complex Calculation and Logical Reasoning;'
W15-29.pdf-Figure7.png;Abbildung 7 zeigt die Kategorien mit einer Überraschungs- und Negativitätsdichte von jeweils über 0,4. Wie viele Tweets wurden in jeder Kategorie erfasst?;Figure 7 shows the categories with surprise and negative densities each greater than 0.4. How many tweets are included in each category?;Alarm: 669, Pitfall: 667, Untimeliness: 135, Hinterhalt: 530, Defiance: 715, Levity: 320, Revenge: 919;Alarm: 669, Pitfall: 667, Untimeliness: 135, Ambush: 530, Defiance: 715, Levity: 320, Revenge: 919;669, 667, 135, 530, 715, 320, 919;669, 667, 135, 530, 715, 320, 919;Caption Question/Simple Retrival;'
W15-4627.pdf-Figure3.png;'Welche Farbe stellt die Korrektheit in der Geschichte 'becauseNS' dar?';'What color represents correctness in the 'becauseNS' story?';Dunkelgrau.;Dark gray.;Dunkelgrau;Dark gray;Simple Retrieval;'
W15-4627.pdf-Figure3.png;'Ist der Balken für 'Präferenz' in der Geschichte 'Original' höher oder niedriger als der Balken für 'Korrektheit'?';'Is the bar for 'preference' in the 'original' story taller or shorter than the bar for 'correctness'?';Höher.;Taller.;Höher;Taller;Simple Calculation;'
W15-4627.pdf-Figure3.png;Wie hoch ist die durchschnittliche Bewertung für Korrektheit und Präferenz über alle Geschichten hinweg?;What is the average rating for correctness and preference across all stories?;'Korrektheit: Ungefähr 2,5. Präferenz: Ungefähr 3,7';'Correctness: Approximately 2.5. Preference: Approximately 3.7';2,5 / 3,7;2.5 / 3.7;Complex Calculation and Logical Reasoning;'
W15-4627.pdf-Figure3.png;Welche Geschichte hat die größte Differenz zwischen Korrektheits- und Präferenzbewertung?;Which story has the largest difference between its correctness and preference ratings?;est;est;est;est;Simple Calculation;'
W15-4627.pdf-Figure3.png;'Die Studie vergleicht verschiedene Sätze mit 'in order to' im Kontext der Geschichte.  Wie beurteilten die Teilnehmer die Korrektheit und Präferenz von Sätzen, die zusätzliche Informationen enthielten, die im Originalsatz nicht vorhanden waren (z. B. 'in order to block it' im 'Protestbeispiel') im Vergleich zu einfacheren Sätzen?';'The study compares different sentences using 'in order to' within the context of the story. How did participants rate the correctness and preference of sentences that contained additional information not present in the original sentence (such as 'in order to block it' in the 'protest' example) compared to simpler sentences?';Teilnehmer bewerteten Sätze, die zusätzliche Informationen wie „um es zu blockieren“ im Beispiel „Protest“ enthielten, als weniger korrekt und weniger bevorzugt im Vergleich zu einfacheren Sätzen. Dies wird durch die niedrigeren Korrektheits- und Präferenzwerte für solche Sätze im Vergleich zu den ursprünglichen und weniger komplexen Varianten deutlich.;'Participants rated sentences that contained additional information like 'in order to block it' in the 'protest' example as less correct and less preferred compared to simpler sentences. This is evident from the lower correctness and preference scores for such sentences compared to the original and less complex variations.';Weniger korrekt und bevorzugt;Less correct and preferred;Requires Paper Context;'We had 7 participants analyze each of the 16 story segments. All participants were native English speakers. Table 8 shows the means and standard deviations for correctness and preference rankings in the first experiment. We find that averaged across all stories, there is a clear order for correctness and preference: original, soSN, becauseNS, becauseSN, NS, EST, N. We performed an ANOVA on preference and found that story has no significant effect on the results (F(1, 15) = 0.18, p = 1.00), indicating that all stories are well-formed and there are no outliers in the story selection. On the other hand, realization does have a significant effect on preference (F(1, 6) = 33.74, p = 0.00). This supports our hypothesis that the realizations are distinct from each other and there are preferences amongst them. Fig. 3 shows the average correctness and preference for all stories.'
W16-1003.pdf-Figure4.png;Welche Zahl steht in der 13. Zeile (Bend) und 20. Spalte (Pickup & Throw)?;What number is in the box at the 13th row (Bend) and 20th column (Pickup & Throw)?;22;22;22;22;Simple Retrieval;'
W16-1003.pdf-Figure4.png;Was ist die Summe der Zahlen in der 17. Zeile (Tennis Swing)?;What is the sum of the numbers in the boxes of the 17th row (Tennis Swing)?;93;93;93;93;Simple Calculation;'
W16-1003.pdf-Figure4.png;'Welche Aktion wird am häufigsten mit 'Hand clap' verwechselt und mit welcher Aktion wird 'Two hand wave' am häufigsten verwechselt?';'Which action is most often confused with 'Hand clap', and which action is most often confused with 'Two hand wave'?';''Hand clap' wird am häufigsten mit 'Two hand wave' verwechselt (10 Instanzen) und 'Two hand wave' wird am häufigsten mit 'Hand clap' verwechselt (10 Instanzen).';''Hand clap' is most often confused with 'Two hand wave' (10 instances), and 'Two hand wave' is most often confused with 'Hand clap' (10 instances).';Hand clap/Two hand wave;Hand clap/Two hand wave;Simple Calculation;'
W16-1003.pdf-Figure4.png;Ist die Summe der Werte in der Diagonalen größer oder kleiner als die Summe aller anderen Werte in der Matrix?;Is the sum of the values on the diagonal greater or less than the sum of all other values in the matrix?;Größer.;Bigger.;Größer;Bigger;Complex Calculation and Logical Reasoning;'
W16-1003.pdf-Figure4.png;'Der Text erwähnt, dass 'Pickup & Throw' oft mit 'Bend' verwechselt wird. Stimmt diese Aussage mit den Werten in der Konfusionsmatrix überein? Begründen Sie Ihre Antwort.';'The text mentions that 'Pickup & Throw' is often confused with 'Bend'. Does this statement agree with the values in the confusion matrix? Justify your answer.';'Ja, die Aussage stimmt mit der Konfusionsmatrix überein. Die Zelle, die 'Pickup & Throw' (Zeile 20) und 'Bend' (Spalte 13) entspricht, hat den Wert 22. Dies ist der höchste Wert in dieser Zeile (ohne das Diagonalelement, das korrekte Klassifizierungen darstellt), was darauf hinweist, dass 'Bend' die Aktion ist, die am häufigsten vorhergesagt wird, wenn die wahre Aktion 'Pickup & Throw' ist.';'Yes, the statement agrees with the confusion matrix. The cell corresponding to 'Pickup & Throw' (row 20) and 'Bend' (column 13) has the value 22. This is the highest value in that row (excluding the diagonal element, which represents correct classifications), indicating 'Bend' is the action most frequently predicted when the true action is 'Pickup & Throw'.';Ja;Yes;Caption Question/Complex Calculation and Logical Reasoning;'
W16-2001.pdf-Figure5.png;Welche Farbe repräsentiert den niedrigsten Wert auf der Farbskala des linken Diagramms?;What color represents the lowest value on the color scale of the left plot?;Hellgelb/Creme repräsentiert den niedrigsten Wert.;Light yellow/cream represents the lowest value.;Hellgelb/Creme;Light yellow/cream;Simple Retrieval;'
W16-2001.pdf-Figure5.png;Was ist die Differenz zwischen dem höchsten und dem niedrigsten Wert auf der Farbskala des rechten Diagramms?;What is the difference between the highest and lowest value on the color scale of the right plot?;Die Differenz beträgt 3,2.;The difference is 3.2.;3.2;3.2;Simple Calculation;'
W16-2001.pdf-Figure5.png;Vergleichen Sie die Farbverläufe in den Blöcken beider Diagramme. Beschreiben Sie die Unterschiede im Hinblick auf die Abgrenzung und den Übergang der Farben.;Compare the color transitions within the blocks of both plots. Describe the differences in terms of distinctness and transition between colors.;Das linke Diagramm weist schärfere, deutlichere Blöcke mit relativ einheitlicher Farbe auf. Das rechte Diagramm weist weniger deutliche Blöcke mit weicheren Übergängen zwischen den Farben auf.;The left plot has sharper, more distinct blocks of relatively uniform color. The right plot has less distinct blocks with smoother transitions between colors.;Scharf vs. weich;Sharp vs. smooth;Simple Retrieval;'
W16-2001.pdf-Figure5.png;Der Artikel erwähnt, dass die Daten von Gauthier et al. (2007) stammen und 3 Sprecher jeweils 160 Instanzen jeder der vier Tonkategorien produzierten. Wie korreliert diese Information mit den 480 Instanzen pro Ton, die in der Bildunterschrift genannt werden, und wie spiegelt sich dies in der visuellen Struktur der Konfusionsmatrizen wider, insbesondere in Bezug auf Größe und Anordnung der Farbblöcke?;The paper mentions using data from Gauthier et al. (2007), with 3 speakers producing 160 instances of each of the four tone categories. How does this information relate to the 480 instances per tone mentioned in the caption, and how is this reflected in the visual structure of the confusion matrices, particularly the size and arrangement of the color blocks?;Die Daten von Gauthier et al. (2007) umfassen 3 Sprecher, die jeweils 160 Instanzen für jede der vier Tonkategorien produzieren, was insgesamt 480 Instanzen pro Ton ergibt. In den Verwechslungsmatrizen zeigen die vier Blöcke entlang der Diagonalen diese Struktur, wobei die SAX-MINDIST-Distanzmatrix deutlichere Farbblöcke aufweist als die f0-Euklidische-Distanzmatrix und somit eine bessere Trennung und Clusterbildung der Töne darstellt.;Die Daten von Gauthier et al. (2007) umfassen 3 Sprecher, die jeweils 160 Instanzen für jede der vier Tonkategorien produzieren, was zu insgesamt 480 Instanzen pro Ton führt. In den Verwechslungsmatrizen zeigen die vier Blöcke entlang der Diagonale diese Struktur, wobei die SAX-MINDIST-Distanzmatrix deutlichere Farbblöcke aufweist als die f0-Euklidischen-Distanzmatrix und so eine bessere Trennung und Clusterung der Töne darstellt.;4 Blöcke;4 blocks;Caption Question/Complex Calculation and Logical Reasoning;"Our evaluation data set of Mandarin tones is drawn from the (Gauthier et al., 2007) data used for unsupervised learning of Mandarin tones with the Self-Organizing Map. This data set contains lab speech (480*4=1920 tones, three speakers each produced 160 instances of each of the four tone categories), where all possible tone combinations are permuted with the original intention to study the variability of tone shapes in running speech.
Figure 5: SAX-MINDIST(left) and f0-Euclidean (right) Distance matrix of 1920 Mandarin tones sorted by tone category. Tones are ordered by tone categories along the x- and y-axis. Origin at top left corner (i.e., on both axis data points are ordered by 480 instances of tone 1, tone 2, tone 3, and tone 4 when moving away from origin)."
W16-2302.pdf-Figure10.png;Welche Metrik wird in der ersten Zeile der en-cs-Matrix durch ein hellgrünes Kästchen dargestellt?;Which metric is represented by a light green square in the first row of the en-cs matrix?;keine;no one;keine;None;Simple Retrieval;'
W16-2302.pdf-Figure10.png;Wie viele dunkelgrüne Quadrate gibt es in der en-de-Matrix?;How many dark green squares are there in the en-de matrix?;14;14;14;14;Simple Calculation;'
W16-2302.pdf-Figure10.png;Welche Metriken schneiden in der en-ro Matrix besser ab als MPEDA (dargestellt durch grüne Kästchen)?;Which metrics outperform MPEDA (represented by green squares) in the en-ro matrix?;chrF3, chrF2, BEER, chrF1;chrF3, chrF2, BEER, chrF1;chrF3, chrF2, BEER, chrF1;chrF3, chrF2, BEER, chrF1;Simple Retrieval;'
W16-2302.pdf-Figure10.png;In welchen Matrizen schneidet BEER besser ab als alle anderen Metriken außer einer (dargestellt durch grüne Kästchen in der BEER Zeile)?;In which matrices does BEER outperform all other metrics except one (represented by green squares in the BEER row)?;en-pl and en-de;en-pl and en-de;en-pl, en-de;en-pl, en-de;Simple Calculation;'
W16-2302.pdf-Figure10.png;Die Bildunterschrift erwähnt die Berechnung der Pearson-Korrelation zwischen HUME-Bewertungen und Metrik-Werten für die Bewertung von Segmentmetriken. Tabelle 11 im Text zeigt die Pearson-Korrelation von Segmentmetriken mit der HUME-Bewertungsvariante. Welche Metriken schneiden bei der en-cs-Bewertung in Tabelle 11 besser ab als in der entsprechenden Matrix in Abbildung 10?;The caption mentions calculating the Pearson correlation between HUME scores and metric scores for evaluating segment-level metrics. Table 11 in the text shows the Pearson correlation of segment-level metrics with the HUME assessment variant. Which metrics perform better for the en-cs evaluation shown in Table 11 compared to their performance in the corresponding matrix in Figure 10?;In der en-cs-Evaluierung zeigt Tabelle 11, dass die Metriken chrF2, BEER und chrF1 eine höhere Pearson-Korrelation mit den HUME-Werten aufweisen. Diese Metriken schneiden auch in der entsprechenden Matrix in Abbildung 10 gut ab, wo chrF3, chrF2 und chrF1 für ihre Effektivität hervorgehoben werden.;In the en-cs evaluation, Table 11 shows that the metrics chrF2, BEER, and chrF1 have a higher Pearson correlation with the HUME scores. These metrics also perform well in the corresponding matrix in Figure 10, where chrF3, chrF2, and chrF1 are noted for their effectiveness.;chrF2, BEER, chrF1;chrF2, BEER, chrF1;Requires Paper Context;"**Direction** **en-cs** **en-de** **en-ro** **en-pl**

**Human Gold** HUME HUME HUME HUME _n_ 339 330 349 345

**Correlation** _r_ _r_ _r_ _r_

CHRF3 **.544** **.480** **.639** .413 CHRF2 .537 **.479** .634 **.417** BEER .516 **.480** .620 **.435** CHRF1 .506 **.467** .611 **.427** MPEDA .468 **.478** .595 **.425** WORDF3 .413 .425 .587 .383 WORDF2 .408 .424 .583 .383 WORDF1 .392 .415 .569 .381 SENTBLEU .349 .377 .550 .328

**himl-2015**

Table 11: Pearson correlation of segment-level metric scores with HUME human assessment variant.

Figure 10: HUME segment-level metric significance test results (himl2015): Green cells denote a significant win for the metric in a given row over the metric in a given column according to Williams test for difference in dependent correlation; Winning metrics are those not significantly outperformed by any other (en-cs: CHRF3; en-de: BEER, CHRF3, CHRF2, MPEDA, CHRF1; en-pl: BEER, CHRF1, MPEDA, CHRF2; en-ro: CHRF3)."
W16-2302.pdf-Figure2.png;Ist die Anzahl der dunkelgrünen Kästchen in der ersten 'ru-en newstest2016'-Matrix größer als die Anzahl der hellgrünen Kästchen in derselben Matrix?;Is the number of dark green boxes in the first 'ru-en newstest2016' matrix greater than the number of light green boxes in the same matrix?;Ja.;Yes.;Ja;Yes;Simple Calculation;'
W16-2302.pdf-Figure2.png;'Wie viele Metriken in der 'RR' Matrix für 'ru-en newstest2016' schneiden im Vergleich zu 'mosesBLEU' signifikant besser ab (dunkelgrüne Kästchen)?';'How many metrics in the 'RR' matrix for 'ru-en newstest2016' perform significantly better than 'mosesBLEU' (dark green boxes)?';Sechs.;Six.;6;Six;Simple Calculation;'
W16-25.pdf-Figure5.png;Welche morphologische Flexionskategorie im linken Bereich hat den höchsten Wert für S₂?;Which morphological inflection category in the leftmost panel has the highest value for S₂?;Commom capitals.;Commom capitals.;Common capitals;Common capitals;Simple Retrieval;'
W16-25.pdf-Figure5.png;'Was ist die Differenz zwischen dem Wert von S₂ und S₅ für die Kategorie 'Adj. to adverb' im linken Bereich?';'What is the difference between the value of S₂ and S₅ for the 'Adj. to adverb' category in the leftmost panel?';'Die Differenz zwischen den Werten von S₂ (0.19) und S₅ (0.33) für die Kategorie 'Adj. to adverb' im linken Bereich ist 0.14.';'The difference between the values of S₂ (0.19) and S₅ (0.33) for the 'Adj. to adverb' category in the leftmost panel is 0.14.';0.14;0.14;Simple Calculation;'
W16-25.pdf-Figure5.png;'Was ist die Summe der Werte für S₂, S₅ und S₁₀  für die Kategorie 'Common capitals' im linken Bereich?';'What is the sum of the values for S₂, S₅, and S₁₀ for the 'Common capitals' category in the leftmost panel?';'Die Summe der Werte für S₂, S₅ und S₁₀ für die Kategorie 'Common capitals' im linken Bereich ist 2.73 (0.92 + 0.90 + 0.91).';'The sum of the values for S₂, S₅, and S₁₀ for the 'Common capitals' category in the leftmost panel is 2.73 (0.92 + 0.90 + 0.91).';2.73;2.73;Complex Calculation and Logical Reasoning;'
W16-25.pdf-Figure5.png;'Im linken Bereich, ist die Summe der Werte für S₂ und S₅ für 'Base to gerund' größer als der Wert von S₁₀ für 'Singular to plural'?';'In the leftmost panel, is the sum of the values for S₂ and S₅ for 'Base to gerund' greater than the value of S₁₀ for 'Singular to plural'?';'Ja, die Summe von S₂ (0.57) und S₅ (0.66) für 'Base to gerund' ist 1.23, was größer ist als der Wert von S₁₀ (0.81) für 'Singular to plural'.';'Yes, the sum of S₂ (0.57) and S₅ (0.66) for 'Base to gerund' is 1.23, which is greater than the value of S₁₀ (0.81) for 'Singular to plural'.';Ja;Yes;Complex Calculation and Logical Reasoning;'
W16-25.pdf-Figure5.png;'Der Text erwähnt einen leichten Genauigkeitsvorteil von S₅ im ADD-Verfahren. Unterstützt die visuelle Darstellung in Abbildung 5 diese Behauptung für die Kategorie 'Adj. to comparative' in allen drei Bereichen, und wenn ja, wie deutlich ist dieser Unterschied visuell?';'According to the text, S₅ shows a slight advantage in overall accuracy for ADD. Focusing on the 'Adj. to comparative' category, does the visual representation in Figure 5 support this claim across all three panels, and if so, how pronounced is this difference visually?';'Für 'Adj. to comparative' ist S₅ nicht durchgängig höher als S₂ oder S₁₀ in allen drei Bereichen. Obwohl der Text einen leichten Gesamtvorteil für S₅ im ADD-Verfahren erwähnt, spiegelt diese spezielle Kategorie in Abbildung 5 diesen Trend visuell nicht stark wider.';'For 'Adj. to comparative', S₅ is not consistently higher than S₂ or S₁₀ across all three panels. While the text mentions a slight overall advantage for S₅ in ADD, this particular category in Figure 5 does not strongly reflect this trend visually.';Nein;No;Caption Question/Complex Calculation and Logical Reasoning;'Yet the breakdown of the results by category (Figure 5) shows that the similarity in average performance across the spaces obscures differences across categories: _s2 performed much better than s10 in some of the_ morphological inflection categories (e.g., .7 compared to .44 for the base-to-third-person relation),'
W16-2503.pdf-Figure4.png;Welche Beziehung wird in der zweiten Zeile von oben dargestellt?;Which relationship is represented in the second row from the top?;All capitals.;All capitals.;All capitals;All capitals;Simple Retrieval;'
W16-2503.pdf-Figure4.png;'Was ist der Wert für 'Common Capitals' bei Verwendung der 'Add'-Methode?';'What is the value for 'Common Capitals' when using the 'Add' method?';0.90;0.90;0.90;0.90;Simple Retrieval;'
W16-2503.pdf-Figure4.png;'Wie hoch ist die Genauigkeit der 'Multipy'-Funktion für 'Adj. to comparative' und wie viel höher ist diese im Vergleich zur 'Vanilla'-Funktion?';'What is the accuracy of the 'Multiply' function for 'Adj. to comparative', and how much higher is it compared to the 'Vanilla' function?';'Die Genauigkeit der 'Multiply'-Funktion für 'Adj. to comparative' beträgt 0.86. Sie ist 0.86 höher als die der 'Vanilla'-Funktion, die eine Genauigkeit von 0.00 hat.';'The accuracy of the 'Multiply' function for 'Adj. to comparative' is 0.86.  It is 0.86 higher than the 'Vanilla' function which has an accuracy of 0.00.';0.86;0.86;Simple Calculation;'
W16-2503.pdf-Figure4.png;'Welcher der aufgeführten Analogiefunktionen erreicht für 'Nationalities' die höchste Genauigkeit und welche Funktion die niedrigste?  Wie groß ist der Unterschied zwischen diesen beiden Werten?';'Which of the listed analogy functions achieves the highest accuracy for 'Nationalities', and which function achieves the lowest? What is the difference between these two values?';'Die höchste Genauigkeit für 'Nationalities' wird von Reversed (Only-b) mit 0,97 erreicht. Die niedrigste wird von Add-opposite mit 0.00 erreicht. Die Differenz beträgt 0,97.';'The highest accuracy for 'Nationalities' is achieved by Reversed (Only-b) with 0.97. The lowest is achieved by Add-opposite with 0.00. The difference is 0.97.';0.97;0.97;Simple Calculation;'
W16-2503.pdf-Figure4.png;Für welche Analogieaufgabe erreicht die ONLY-B-Baseline laut Abbildung 4 die höchste Genauigkeit, und wie hoch ist der numerische Wert dieser Genauigkeit? Warum könnte diese Baseline bei dieser Aufgabe so gut abschneiden (unter Berücksichtigung der Diskussion über die Nachbarschaftsstruktur im bereitgestellten Text)?;According to Figure 4, for which analogy task does the ONLY-B baseline achieve the highest accuracy and what is the numerical value of that accuracy? Why might this baseline perform so well for this task (consider the discussion on neighborhood structure in the provided text)?;'ONLY-B erreicht die höchste Genauigkeit für die Aufgabe 'Singular to plural' mit 0,70. Der Text erklärt, dass Pluralformen von Wörtern (z. B. screaming) im Vektorraum tendenziell nahe an ihren Singularformen (scream) liegen. Das bedeutet, dass die Suche nach dem nächsten Nachbarn der Singularform (b in der Notation des Papers) wahrscheinlich die Pluralform (b*) findet, wodurch die ONLY-B-Baseline für Pluralanalogien sehr effektiv ist, obwohl sie die Offset-Berechnung vollständig ignoriert.';'ONLY-B achieves the highest accuracy for the 'Singular to plural' task at 0.70. The text explains that plural forms of words (e.g., screaming) tend to be close in vector space to their singular forms (scream). This means that just looking for the nearest neighbor of the singular form (b in the notation of the paper) is likely to find the plural form (b*), making the ONLY-B baseline very effective for plural analogies, even though it ignores the offset calculation entirely.';0.70;0.70;Caption Question/Complex Calculation and Logical Reasoning;'The central role of cosine similarity in this method raises the concern that the method does not only evaluate the consistency of the offsets _a[∗]_ _a and b[∗]_ _b but also the neighborhood struc-_ _−_ _−_ ture of x = a[∗] _a+b. For instance, if a[∗]_ and a are _−_ very similar to each other (as scream and scream_ing are likely to be) the nearest word to x may sim-_ ply be the nearest neighbor of b. If in a given set of analogies the nearest neighbor of b tends to be _b[∗], then, the method may give the correct answer_ regardless of the consistency of the offsets (Figure 2).'
W16-4804.pdf-Figure5.png;Welche Beschriftung auf der y-Achse entspricht dem dunkelgrünsten Kästchen in der ersten Konfusionsmatrix (LR)?;Which label on the y-axis corresponds to the darkest green square in the first confusion matrix (LR)?;hr;hr;hr;hr;Simple Retrieval;'
W16-4804.pdf-Figure5.png;Wie hoch ist der Wert des dunkelgrünsten Quadrats in der zweiten Konfusionsmatrix (NN)?;What is the value of the darkest green square in the second confusion matrix (NN)?;90;90;90;90;Simple Retrieval;'
W16-4804.pdf-Figure5.png;In der ersten Konfusionsmatrix (LR), ist der Wert des Quadrats, das hr (Gold) und bs (Vorhersage) entspricht, größer als der Wert des Quadrats, das bs (Gold) und hr (Vorhersage) entspricht?;In the first confusion matrix (LR), is the value of the square corresponding to hr (Gold) and bs (Predicted) greater than the value of the square corresponding to bs (Gold) and hr (Predicted)?;Nein;No;Nein;No;Simple Calculation;'
W16-4804.pdf-Figure5.png;'In der dritten Konfusionsmatrix (2-Stufen), wie viele Instanzen wurden fälschlicherweise als 'pt-PT' vorhergesagt, obwohl sie eigentlich 'pt-BR' waren?';'In the third confusion matrix (2-stage), how many instances were incorrectly predicted as 'pt-PT' when they were actually 'pt-BR'?';10;10;10;10;Simple Retrieval;'
W16-4804.pdf-Figure5.png;'In Abschnitt 4.4 wird die Leistung der drei Ansätze (LR, NN, 2-Stufen) für Aufgabe 1 auf den Out-of-Domain-Testdatensätzen (B1 und B2) diskutiert. Betrachtet man die Konfusionsmatrizen in Abbildung 5 für den B2-Datensatz, welcher Ansatz scheint die beste Leistung für 'pt-BR' in Bezug auf Präzision zu erzielen, und welche Beobachtung in den Matrizen stützt diese Schlussfolgerung?';'Section 4.4 discusses the performance of the three approaches (LR, NN, 2-stage) for Task 1 on the out-of-domain test sets (B1 and B2). Looking at the confusion matrices in Figure 5 for the B2 dataset, which approach appears to achieve the best performance for 'pt-BR' in terms of precision, and what observation in the matrices supports this conclusion?';'Der LR-Ansatz scheint die beste Präzision für 'pt-BR' im B2-Datensatz zu haben. Dies wird durch die Beobachtung gestützt, dass das entsprechende Quadrat in der LR-Konfusionsmatrix für 'pt-BR' (Gold) und 'pt-BR' (Vorhergesagt) einen dunkleren Grünton im Vergleich zum gleichen Quadrat in den NN- und 2-Stufen-Matrizen aufweist. Obwohl keine genauen Werte angegeben sind, impliziert der dunklere Farbton einen höheren Anteil korrekter 'pt-BR'-Vorhersagen. Diese visuelle Beobachtung stimmt mit dem Text in Abschnitt 4.4 überein, der besagt, dass LR die beste Leistung auf den Datensätzen B1 und B2 erzielt.';'The LR approach appears to have the best precision for 'pt-BR' on the B2 dataset. This is supported by the observation that the corresponding square in the LR confusion matrix for 'pt-BR' (Gold) and 'pt-BR' (Predicted) has a darker shade of green compared to the same square in the NN and 2-stage matrices.  Although precise values aren't given, the darker shade implies a higher proportion of correct 'pt-BR' predictions. This visual observation is consistent with the text in Section 4.4, which states that LR performs best on B1 and B2 datasets.';LR;LR;Requires Paper Context;'GW/LT3 ranked first in the out-of-domain evaluation (test sets B1&B2) and third for in-domain test set A. As shown in Table 1, the LR classifier yields the best performance on the B1 and B2 test sets, with an accuracy of 92.0% and 87.8%, respectively. It is narrowly beaten by the cascaded approach on test set A (88.7%). The state-of-the-art performance on the B1 and B2 test sets may indicate that adequate preprocessing is a prerequisite when dealing with noisy social media data. Both the normalization steps and the aggressive filtering of code-switched tweets based on language family detection may have been effective for improving performance over competing systems.'
W16-4821.pdf-Figure2.png;Welche Farbe hat das Quadrat in der Matrix, das dem wahren Label 'msa' und dem vorhergesagten Label 'msa' entspricht?;What color is the square in the matrix corresponding to the true label 'msa' and the predicted label 'msa'?;Das Quadrat, das dem wahren Label 'msa' und dem vorhergesagten Label 'msa' entspricht, ist dunkelviolett/schwarz.;The square corresponding to true label 'msa' and predicted label 'msa' is dark purple/black.;Dunkelviolett/Schwarz;Dark purple/black;Simple Retrieval;'
W16-4821.pdf-Figure2.png;Wie verhält sich der Wert im Quadrat für das wahre Label 'glf' und das vorhergesagte Label 'glf' im Vergleich zum Wert im Quadrat für das wahre Label 'egy' und das vorhergesagte Label 'egy'?;How does the value in the square for true label 'glf' and predicted label 'glf' compare to the value in the square for true label 'egy' and predicted label 'egy'?;Der Wert im Feld 'glf'-'glf' ist niedriger als der Wert im Feld 'egy'-'egy'.;The value in the field 'glf' is lower than the value in the field 'egy'.;Niedriger;Lower;Simple Calculation;'
W16-4821.pdf-Figure2.png;Ist die Summe der Werte in den Quadraten, bei denen das vorhergesagte Label 'nor' ist, größer als 0,2?;Is the sum of the values in the squares where the predicted label is 'nor' greater than 0.2?;Ja;Yes;Ja;Yes;Complex Calculation and Logical Reasoning;'
W16-4821.pdf-Figure2.png;Welche zwei wahren Labels werden am häufigsten miteinander verwechselt, gemessen an der Farbintensität des entsprechenden Quadrats in der Matrix?;Which two true labels are most often confused with each other, judging by the color intensity of the corresponding square in the matrix?;'glf' (wahres Label) und 'egy' (vorhergesagtes Label) werden am häufigsten verwechselt.;'glf' (true label) and 'egy' (predicted label) are most often confused.;glf/egy;glf/egy;Simple Retrieval;'
W16-4821.pdf-Figure2.png;Die Verwendung zusätzlicher Trainingsdaten reduzierte die Verwechslung in den meisten Fällen. Welche Dialekte bilden die Ausnahme von dieser Regel, und wie wird dies visuell in Abbildung 2 dargestellt?;The paper states that using extra training data reduced the classification confusion in most cases. Which dialects are the exception to this rule, and how is this reflected visually in Figure 2?;Levantinisches Arabisch (LAV) ist die Ausnahme. Nach dem Hinzufügen von Trainingsdaten wird es häufiger mit Golfarabisch (GLF) verwechselt. Dies wird in Abbildung 2 durch die relativ hohe Intensität des Quadrats dargestellt, bei dem das wahre Label 'lav' und das vorhergesagte Label 'glf' ist.;Levantine Arabic (LAV) is the exception.  It becomes more confused with Gulf Arabic (GLF) after adding training data. This is shown in Figure 2 by the relatively high intensity of the square where the true label is 'lav' and the predicted label is 'glf'.;LAV/GLF;LAV/GLF;Requires Paper Context;'As shown in Figure 2 and Figure 3, the system misclassified all Arabic varieties with each other with different confusion degrees. Gulf Arabic is the most variety for which most mistakes are made, while MSA is the one that is most accurately recognized. Comparing between Figure 2 and Figure 3 shows that using extra training data has reduced the classification confusion in most cases, except for Levantine Arabic which is more confused with Gulf Arabic. This causes the number of correctly classified Levantine instances to decrease. It is also noticeable that there are more instances of all Arabic dialects confused with MSA.'
W16-4824.pdf-Figure3.png;Welche Farbe hat das Feld in der Konfusionsmatrix, das die wahre Bezeichnung 'msa' und die vorhergesagte Bezeichnung 'msa' darstellt?;What color is the square in the confusion matrix representing the true label 'msa' and the predicted label 'msa'?;Schwarz;Black;Schwarz;Black;Simple Retrieval;'
W16-4824.pdf-Figure3.png;Wie verhält sich der Wert im Feld für die wahre Bezeichnung 'egy' und die vorhergesagte Bezeichnung 'egy' zum Wert im Feld für die wahre Bezeichnung 'nor' und die vorhergesagte Bezeichnung 'nor'?;Wie verhält sich der Wert im Feld für die wahre Bezeichnung 'egy' und die vorhergesagte Bezeichnung 'egy' zum Wert im Feld für die wahre Bezeichnung 'nor' und die vorhergesagte Bezeichnung 'nor'?;Der Wert für 'egy'-'egy' ist höher als der Wert für 'nor'-'nor'. Dies ist an der dunkleren blauen Farbe des 'egy'-'egy'-Feldes im Vergleich zur helleren magentafarbenen Farbe des 'nor'-'nor'-Feldes zu erkennen.;The value for 'egy'-'egy' is higher than the value for 'nor'-'nor'. This is evident from the darker blue color of the 'egy'-'egy' square compared to the lighter magenta color of the 'nor'-'nor' square.;Höher;Higher;Simple Calculation;'
W16-4824.pdf-Figure3.png;Welche vorhergesagte Bezeichnung hat den höchsten Wert für die wahre Bezeichnung 'glf', und wie hoch ist dieser Wert ungefähr (auf der Grundlage des Farbbalkens)?;Which predicted label has the highest value for the true label 'glf', and approximately what is that value (based on the color bar)?;Der höchste Wert für die wahre Bezeichnung 'glf' liegt bei der vorhergesagten Bezeichnung 'glf'. Die Farbe deutet darauf hin, dass der Wert ungefähr 0.35 beträgt.;The highest value for the true label 'glf' is for the predicted label 'glf'. The color suggests the value is approximately 0.35.;glf, 0.35;glf, 0.35;Simple Retrieval;'
W16-4824.pdf-Figure3.png;Wenn Sie die Werte der Felder addieren, bei denen die wahre Bezeichnung 'lav' ist, welchen ungefähren Wert erhalten Sie dann?;If you sum the values of the squares where the true label is 'lav', what approximate value do you get?;Durch Untersuchen der Farbintensität entsprechend den Werten auf dem Farbbalken und Schätzen des Wertes jedes Feldes in der Zeile 'lav' ergibt sich als Summe ungefähr 0,1 + 0,15 + 0,35 + 0,08 + 0,12 = 0,8;By examining the color intensity according to the values on the color bar and estimating the value of each field in the row 'lav', the sum is approximately 0.1 + 0.15 + 0.35 + 0.08 + 0.12 = 0.8;0.8;0.8;Complex Calculation and Logical Reasoning;'
W16-4824.pdf-Figure3.png;Der Text erwähnt, dass nordafrikanische und levantinische Dialekte die größte Verwechslungsgefahr aufweisen, häufig mit ägyptischem und Golfarabisch. Welche spezifischen Fehlklassifikationen in Abbildung 3 (Konfusionsmatrix) stützen diese Aussage, und wie hoch sind ihre ungefähren Werte? Nennen Sie mindestens zwei Beispiele.;The paper mentions that North-African and Levantine dialects exhibit the highest degree of confusion, often with Egyptian and Gulf Arabic. Looking at Figure 3 (confusion matrix), which specific misclassifications support this statement, and what are their approximate values? Provide at least two examples.;"Die Konfusionsmatrix unterstützt die Aussage mit folgenden Beispielen:

1. Nordafrikanisch/Levantinisch (lav) wird fälschlicherweise als Golfarabisch (glf) klassifiziert: Ungefähr 0,3
2. Nordafrikanisch/Levantinisch (lav) wird fälschlicherweise als Ägyptisch (egy) klassifiziert: Ungefähr 0,2";"The confusion matrix supports the statement with the following examples:

1. North African/Levantine (lav) is incorrectly classified as Gulf Arabic (glf): Approximately 0.3
2. North African/Levantine (lav) is incorrectly classified as Egyptian (egy): Approximately 0.2";lav-glf (0.3), lav-egy (0.2);lav-glf (0.3), lav-egy (0.2);Caption Question/Complex Calculation and Logical Reasoning;'
W19-5211.pdf-Figure12.png;'Welcher Wert befindet sich in der Zelle in Zeile 'layer 2' und Spalte 'bin 9'?';'What value is in the cell located in row 'layer 2' and column 'bin 9'?';1.000;1.000;1.000;1.000;Simple Retrieval;'
W19-5211.pdf-Figure12.png;'Was ist die Differenz zwischen dem Wert in der Zelle in Zeile 'layer 4' und Spalte 'bin 3' und dem Wert in Zeile 'layer 4' und Spalte 'bin 4'?';'What is the difference between the value in the cell at row 'layer 4' and column 'bin 3' and the value at row 'layer 4' and column 'bin 4'?';0,32;0.32;0,32;0.32;Simple Calculation;'
W19-5211.pdf-Figure12.png;'Was ist der Durchschnitt der Werte in Spalte 'bin 7'?';'What is the average of the values in column 'bin 7'?';0,969;0.969;0,969;0.969;Complex Calculation and Logical Reasoning;'
W19-5211.pdf-Figure12.png;'Ist die Summe der Werte in 'layer 5' größer als die Summe der Werte in 'layer 6'? Begründe deine Antwort anhand der Farbintensität innerhalb der Heatmap.';'Is the sum of the values in 'layer 5' greater than the sum of the values in 'layer 6'? Justify your answer based on the color intensity within the heatmap.';Ja. Die Summe der Werte in Schicht 5 beträgt 5,345 und die Summe der Werte in Schicht 6 beträgt 5,145. Schicht 5 hat intensivere Farben (mehr Rot/Orange) als Schicht 6 (mehr Blau/Hellrot).;Yes. The sum of the values in Layer 5 is 5.345 and the sum of the values in Layer 6 is 5.145. Layer 5 has more intense colors (more red/orange) than Layer 6 (more blue/light red).;Ja;Yes;Complex Calculation and Logical Reasoning;'
W19-5211.pdf-Figure12.png;In Abschnitt A.3 des Papers wird erwähnt, dass die Genauigkeit der Klassifizierung für seltene Subwörter niedrig ist. Betrachtet man Abbildung 12, welche Frequenzbereiche (Bins) scheinen am stärksten von Datenknappheit betroffen zu sein, und wie lässt sich dies anhand der Farbintensität in der Heatmap visuell erkennen?;Section A.3 of the paper mentions that the classification accuracy is notably low for infrequent sub-words. Looking at Figure 12, which frequency bins appear to be most affected by data sparsity, and how can this be visually observed based on the color intensity in the heatmap?;Die Bins 1-4 scheinen am stärksten von Datenknappheit betroffen zu sein, was durch die kühleren Farben (blau/hellrot) in diesen Bins im Vergleich zu den wärmeren Farben (dunkelrot) in den Bins 5-10 angezeigt wird.;Bins 1-4 appear most affected by data sparsity, shown by the cooler colors (blue/light red) in those bins compared to the warmer colors (darker red) in bins 5-10.;Bins 1-4;Bins 1-4;Requires Paper Context;'While classification accuracy is notably low for infrequent sub-words, this can be attributed to the limited occurrence of the corresponding transformer states in the classifier’s training data. Evaluation for EN DE models is _→_ done on newstest2014, while newstest2017 is used for EN RU models. Figures 8-15 present results _→_ for the frequency-based classification. Accuracy scores conditioned on POS tags are visualized in Figures 16-23.'
W19-5211.pdf-Figure13.png;Welche Farbe repräsentiert den höchsten Wert in der Heatmap?;Which color represents the highest value in the heatmap?;Dunkelrot repräsentiert den höchsten Wert.;Dark red represents the highest value.;Dunkelrot;Dark red;Simple Retrieval;'
W19-5211.pdf-Figure13.png;Wie hoch ist der Wert in der Zelle, die der 4. Schicht und dem 6. Bin entspricht?;What is the value in the cell corresponding to layer 4 and bin 6?;0,259;0.259;0,259;0.259;Simple Retrieval;'
W19-5211.pdf-Figure13.png;Ist die Summe der Werte in der ersten Zeile größer als die Summe der Werte in der zweiten Zeile?;Is the sum of the values in the first row greater than the sum of the values in the second row?;Ja, die Summe der Werte in der ersten Zeile (ungefähr 8,575) ist größer als die Summe der Werte in der zweiten Zeile (ungefähr 7,873).;Yes, the sum of the values in the first row (approximately 8.575) is greater than the sum of the values in the second row (approximately 7.873).;Ja;Yes;Complex Calculation and Logical Reasoning;'
W19-5211.pdf-Figure13.png;Wie hoch ist die durchschnittliche Genauigkeit für Schicht 3 über alle Bins?;What is the average accuracy for layer 3 across all bins?;Die durchschnittliche Genauigkeit für Schicht 3 beträgt ungefähr 0,555.;The average accuracy for layer 3 is approximately 0.555.;0,555;0.555;Complex Calculation and Logical Reasoning;'
W19-5211.pdf-Figure13.png;In der Arbeit wird die Untersuchung der Aktivierungsmuster von lexikalischen Shortcut-Gates erwähnt. In Anbetracht der Werte in Schicht 6 der Konfusionsmatrix (Abbildung 13), wie könnten diese Aktivierungsmuster die Leistung in den höheren Frequenzbereichen (Bins 8, 9 und 10) beeinflussen?;The paper mentions investigating the activation patterns of lexical shortcut gates. Considering the values in layer 6 of the confusion matrix (Figure 13), how might these activation patterns be influencing the performance in the higher frequency bins (bins 8, 9, and 10)?;Schicht 6 zeigt eine hohe Genauigkeit in den höheren Frequenzbereichen (8, 9 und 10).  Das Paper gibt an, dass keine erkennbaren Muster in den Aktivierungen der lexikalischen Shortcut-Gates gefunden wurden und dass sie lexikalischen und versteckten Merkmalen gleichermaßen Priorität einräumen. Dies deutet darauf hin, dass sie nicht speziell zur verbesserten Leistung in höheren Frequenzbereichen beitragen. Die hohe Genauigkeit könnte auf andere Faktoren zurückzuführen sein, wie z. B. die Leichtigkeit, häufige Wörter zu klassifizieren, oder die allgemeine Fähigkeit des Modells, gängige Muster zu lernen.;Layer 6 shows high accuracy in the higher frequency bins (8, 9, and 10).  The paper states that there were no discernable patterns found in the activations of the lexical shortcut gates, and that they prioritize lexical and hidden features equally. This suggests they don't specifically contribute to the improved performance in higher frequency bins.  The high accuracy may be due to other factors, such as the ease of classifying frequent words or the model's general ability to learn common patterns.;Keine Muster gefunden;No patterns found;Requires Paper Context;"We also investigated the activation patterns of the lexical shortcut gates. However, despite their essential status for the successful training of transformer variants equipped with lexical connections, we were unable to discern any distinct patterns in the activations of the individual gates, which


tend to prioritize lexical and hidden features to an equal degree regardless of training progress or (sub-)word characteristics."
W19-5211.pdf-Figure16.png;Welches Label befindet sich in der untersten Zeile der Matrix?;What label is in the bottom row of the matrix?;layer 6;layer 6;layer 6;layer 6;Simple Retrieval;'
W19-5211.pdf-Figure16.png;Was ist der Wert in der Zelle ganz rechts in der obersten Zeile?;What is the value in the rightmost cell of the top row?;1.000;1.000;1.000;1.000;Simple Retrieval;'
W19-5211.pdf-Figure16.png;Ist der Wert für Layer 3 und NOUNS größer oder kleiner als der Wert für Layer 5 und VERBS?;Is the value for Layer 3 and NOUNS greater or less than the value for Layer 5 and VERBS?;Größer. 0.967 > 0.925;Greater. 0.967 > 0.925;Größer;Greater;Simple Calculation;'
W19-5211.pdf-Figure16.png;'Wie hoch ist die durchschnittliche POS-Klassifikationsgenauigkeit für 'Layer 4' über alle Wortarten?';'What is the average POS classification accuracy for 'Layer 4' across all parts of speech?';0.975;0.975;0.975;0.975;Complex Calculation and Logical Reasoning;'
W19-5211.pdf-Figure16.png;In Abbildung 16 wird eine hohe Genauigkeit für die meisten Wortarten-Tags dargestellt. Warum analysieren die Autoren zusätzlich die frequenzbasierte Klassifikationsgenauigkeit (Abbildungen 8-15) für EN → DE- und EN → RU-Modelle?;Figure 16 shows high accuracy for most part-of-speech tags. Why do the authors additionally analyze frequency-based classification accuracy (Figures 8-15) for EN → DE and EN → RU models?;Die Autoren wollten ein umfassenderes Verständnis der Modellleistung gewinnen, insbesondere im Hinblick auf die Leistung bei seltenen Subwörtern, die möglicherweise nur begrenzt in den Trainingsdaten vorkommen.;The authors wanted to gain a more comprehensive understanding of the model's performance, especially on infrequent sub-words which might have limited occurrences in the training data.;Umfassenderes Verständnis;More comprehensive understanding;Requires Paper Context;"Accuracy scores conditioned on POS tags are visualized in Figures 16-23.

...While classification accuracy is notably low for infrequent sub-words, this can be attributed to the limited occurrence of the corresponding transformer states in the classifier’s training data."
W10-3302.pdf-Figure6.png;Wie viel mal höher ist der höchste hellgelbe Balken im Vergleich zum niedrigsten?;How many times taller is the tallest light yellow bar compared to the shortest?;Ungefähr 75 mal höher.;Approximately 75 times taller.;75;75;Simple Calculation;'
W10-3302.pdf-Figure6.png;Bei welcher Tiefe erreicht die Anzahl der Kategorien (hellgelbe Balken) ihren Höhepunkt?;At what depth do the number of categories (light yellow bars) reach their peak?;Tiefe 5.;Depth 5.;5;5;Simple Retrieval;'
W10-3302.pdf-Figure6.png;'Ist die 'parent-child precision' (pinkfarbene Linie) höher als die 'ancestor-descendant precision' (dunkelblaue Linie) an irgendeinem Punkt?';'Is the 'parent-child precision' (pink line) higher than the 'ancestor-descendant precision' (dark blue line) at any point?';Ja;Yes;Ja;Yes;Simple Calculation;'
W10-3302.pdf-Figure6.png;'Die Autoren geben an, dass die durchschnittliche 'ancestor-descendant precision' 82,6 % beträgt, nachdem die Kategorien der Tiefe 1 ausgeschlossen wurden.  Welche Schlussfolgerung lässt sich aus dieser Zahl und dem in Abbildung 6 dargestellten Trend in Bezug auf die Zuverlässigkeit der konstruierten Hierarchie in größeren Tiefen ziehen?';'The authors state that the average 'ancestor-descendant precision' is 82.6% after excluding depth 1 categories. What can be inferred from this number and the trend shown in Figure 6 regarding the reliability of the constructed hierarchy at greater depths?';'Die Zuverlässigkeit der konstruierten Hierarchie nimmt mit zunehmender Tiefe ab. Obwohl die durchschnittliche 'ancestor-descendant precision' 82,6 % beträgt, deutet der Abwärtstrend in Abbildung 6 darauf hin, dass längere Ketten von Ist-a-Beziehungen mit zunehmender Tiefe weniger zuverlässig werden.';The reliability of the constructed hierarchy decreases at greater depths.  While the average ancestor-descendant precision is 82.6%, the downward trend in Figure 6 suggests that longer chains of is-a relationships become less reliable with increasing depth.;Abnehmende Zuverlässigkeit;Decreasing Reliability;Caption Question/Complex Calculation and Logical Reasoning;'
2016.jeptalnrecital-recital.8.pdf-Figure2.png;Welches Label gehört zum größten Kreissegment?;Which label corresponds to the largest pie slice?;ponctuation multiple;ponctuation multiple;ponctuation multiple;ponctuation multiple;Simple Retrieval;'
2016.jeptalnrecital-recital.8.pdf-Figure2.png;Was ist die Summe der Prozentwerte der beiden kleinsten Kreissegmente?;What is the sum of the percentages of the two smallest pie slices?;3%;3%;3%;3%;Simple Calculation;'
2016.jeptalnrecital-recital.8.pdf-Figure2.png;'Ist der kombinierte Prozentwert von 'émoticônes' und 'caractères \'écho\'' größer als der Prozentwert von 'argot Internet'?';'Is the combined percentage of 'émoticônes' and 'caractères \'écho\'' greater than the percentage of 'argot Internet'?';Nein, 3% ist weniger als 27%.;No, 3% is less than 27%.;Nein;No;Simple Calculation;'
2016.jeptalnrecital-recital.8.pdf-Figure2.png;Um wie viel Prozentpunkte ist das größte Segment größer als das zweitgrößte Segment?;By how many percentage points is the largest slice larger than the second largest slice?;41%;41%;41;41;Simple Calculation;'
2016.jeptalnrecital-recital.8.pdf-Figure2.png;Der Text erwähnt, dass 1% der Äußerungen im Korpus mehrere Satzzeichen enthalten und durchschnittlich 0,04 Marker pro Äußerung vorkommen.  Wenn 'ponctuation multiple' 68% dieser Marker ausmacht, wie viele 'ponctuation multiple' Marker gibt es durchschnittlich in einer Äußerung, die mindestens ein solches enthält?;The text mentions that 1% of the utterances in the corpus contain multiple punctuation marks, and there's an average of 0.04 markers per utterance. If 'ponctuation multiple' represents 68% of these markers, how many 'ponctuation multiple' markers are there on average in an utterance containing at least one?;0.0272;0.0272;0.0272;0.0272;Caption Question/Complex Calculation and Logical Reasoning;"FIGURE 2 : Répartition des principaux phénomènes lexicaux parmi ceux détectés.

La seconde forme la plus fréquente de caractères “écho” de notre corpus est l’onomatopée “pff” (157 occurrences). On la retrouve sous une trentaine de formes différentes (« Pfff », « ppffff », « pfffffffffffffffffffffffffffffffffffffffff », etc.), dont l’intensité nous renseigne sur le degré émotionnel que l’utilisateur souhaite communiquer, phénomène retrouvé dans d’autres termes : « merciiiiiiiiiiii», « mmddddr ». Il est à noter que ces répétitions de caractères se trouvent souvent sur des interjections qui peuvent être porteuses d’OPRO assez précises, comme « pfff » et « zut », exprimant une réaction négative ou étant porteuse d’ironie (“pffffffffffffffffffff mon dieu il est beau le progrés”).

Notre corpus contient 3 892 occurrences d’émoticônes soit moins de 0,001% d’émoticônes par énoncé utilisateur non vide et couvre 3% des émoticônes présents dans la liste de référence. L’usage des émoticônes semble donc marginal dans ce corpus mais leur étude reste importante pour notre objectif final d’analyse des opinions et des phénomènes reliés aux opinions de l’utilisateur. Les émoticônes “standard” comme :), ;) et :( sont les plus populaires chez les utilisateurs de _l’agent_ _virtuel_ _Laura (« :)» 34% d’émoticônes, « ;) » 10% ; « :( » 9%). Notons également l’utilisation assez_ fréquente de l’émoticône <3 par les utilisateurs de l’agent virtuel _Laura (7%). Cette émoticône est_ un marqueur de familiarité et hors du contexte de la relation “client-conseiller” attendue (“tu devrais changer de coupe de cheveux <3”). Nous trouvons aussi l’aspect “hors contexte” dans des énoncés utilisateurs ouvertement agressifs tels que décrits par (De angeli, Carpenter, 2005).

En nous reposant sur la typologie de la relation entre les émoticônes et le contenu verbal de (Marcoccia, Gauducheau, 2007), nous avons procédé à une analyse plus approfondie de l’usage des émoticônes pour identifier différents types de relations entre le contenu textuel et les émoticônes présents dans notre corpus : information redondante (« ok merci beaucoup et bonne journée Laura :-) »); aide à la compréhension (« Bonjour, j'aimerai savoir comment payer ma facture sur internet :) ») ; atténuation (« Laura !!! fait un effort ma poulette !!!! :) »); ironie («c 'était pourtant clair :-) » ; familiarité: « vous avez qulle age ? :) »). La prise en compte du contexte de plusieurs énoncés d’un dialogue peut permettre la désambiguïsation du sens des émoticônes, ce que ne permet pas une approche utilisant des « sacs de mots » (Ferrari, et al., 2008).

4% d’énoncés utilisateur contiennent au moins un marqueur, y compris l’argot Internet. Il est possible que la rareté des phénomènes décrits ci-dessus renforce leur significativité dans un énoncé. Bien que marginale, la présence de ces phénomènes scripturaux dans notre corpus souligne l’appartenance de ce dernier au langage Web. Nous avons recours à ces phénomènes lors de la conception de nos règles décrites dans la Section 5.

### 4.2 Lexique d’émotion dans le corpus

Les OPRO envers l’interaction peuvent aussi être exprimées expressément dans le texte rédigé par l’utilisateur. Pour pouvoir les détecter nous avons choisi d’utiliser un dictionnaire d’OPRO. Parmi ceux disponibles en langue française, nous avons choisi d’utiliser la version française du dictionnaire pour LIWC (Piolat, Booth, Chung, et al., 2011) qui contient des radicaux de mots classés par catégories thématiques. La version française de dictionnaire LIWC comporte"
2020.acl-main.427.pdf-Figure4.png;Welche Aktion wird im inneren Kreis durch das größte Segment dargestellt?;Which action is represented by the largest segment in the inner circle?;BUILD;BUILD;BUILD;BUILD;Simple Retrieval;'
2020.acl-main.427.pdf-Figure4.png;Abbildung 4 zeigt die Häufigkeit von OTHERACTION. In Anbetracht der Erörterung der Grammabdeckung in Abschnitt 3.2.2, wie könnten sich die Einschränkungen der Grammatik auf die beobachteten Häufigkeiten in den verschiedenen Datenerhebungsschemata auswirken, und welche Strategien könnten die Grammatikvollständigkeit in zukünftigen Arbeiten verbessern?;Figure 4 shows the frequency of OTHERACTION. Considering the discussion of grammar coverage in Section 3.2.2, how might the limitations of the grammar influence the observed frequencies in the different data collection schemes, and what strategies could improve grammar completeness in future work?;Die Beschränkungen der Grammatik führen dazu, dass ein erheblicher Teil (etwa 14%) der Befehle in beiden Datenerhebungsschemata als OTHERACTION klassifiziert wird. Dies deutet darauf hin, dass die Grammatik nicht das gesamte Spektrum der Benutzeranweisungen abdeckt. Um die Vollständigkeit zu verbessern, könnten zukünftige Arbeiten die OTHERACTION-Befehle analysieren, wiederkehrende Muster identifizieren und diese in eine erweiterte Grammatik integrieren, indem neue Aktionsprimitive hinzugefügt oder bestehende verfeinert werden.;The grammar's limitations lead to a significant portion (around 14%) of commands being classified as OTHERACTION in both data collection schemes. This suggests the grammar doesn't encompass the full spectrum of user instructions. To improve completeness, future work could analyze the OTHERACTION commands, identify recurring patterns, and integrate these into an expanded grammar by adding new action primitives or refining existing ones.;Einschränkungen der Grammatik;Grammar limitations;Requires Paper Context;'**3.2.2** **Grammar coverage** Some crowd-sourced commands describe an action that is outside the scope of the grammar. To account for this, users of the annotation tool are able to mark that a sentence is a command to perform an action that is not covered by our grammar yet. The resulting trees are labeled as OTHERACTION, and their frequency in each dataset in shown in Figure 4. Annotators still have the option to label other nodes in the tree, such as the action’s LOCA TION or REFERENCE OBJECT. In both the prompts and interactive data, OTHERACTION amounted to approximately 14% of the data.'
2020.acl-main.678.pdf-Figure4.png;Welches Segment ist am größten und wie viel Prozent macht es aus?;Which segment is the largest and what percentage does it represent?;'Das größte Segment ist 'Typical Time' und repräsentiert 52%.';'The largest segment is 'Typical Time', representing 52%.';Typical Time, 52%;Typical Time, 52%;Simple Retrieval;'
2020.acl-main.678.pdf-Figure4.png;'Was ist die Summe der Prozentsätze der Segmente 'Duration' und 'Frequency'?';'What is the sum of the percentages of the 'Duration' and 'Frequency' segments?';'Die Summe der Prozentsätze der Segmente 'Duration' und 'Frequency' beträgt 8%.';'The sum of the percentages of the 'Duration' and 'Frequency' segments is 8%.';8%;8%;Simple Calculation;'
2020.acl-main.678.pdf-Figure4.png;'Um wie viel Prozent ist das Segment 'Typical Time' größer als die Summe der drei kleinsten Segmente?';'By what percentage is the 'Typical Time' segment larger than the sum of the three smallest segments?';''Typical Time' (52%) ist 30 Prozentpunkte größer als die Summe der drei kleinsten Segmente (Combined 2%, Frequency 6% und Duration 14% = 22%). Dies bedeutet, dass 'Typical Time' etwa 136% größer ist als die Summe der drei kleinsten Segmente.';''Typical Time' (52%) is 30 percentage points larger than the sum of the three smallest segments (Combined 2%, Frequency 6%, and Duration 14% = 22%).  This translates to 'Typical Time' being approximately 136% larger than the sum of the three smallest segments.';136%;136%;Complex Calculation and Logical Reasoning;'
2020.acl-main.678.pdf-Figure4.png;Der Artikel erwähnt 'Duration Upper-bound' als eine Hilfsdimension. Wie wird dieses Konzept im Artikel erläutert und wie trägt es zu einem differenzierteren Verständnis von 'Duration' bei, wie es in Abbildung 4 dargestellt ist?;The paper mentions 'Duration Upper-bound' as an auxiliary dimension. How is this concept explained in the paper and how does it contribute to a more nuanced understanding of 'Duration' as represented in Figure 4?;'Duration Upper-bound' stellt einen maximalen Zeitrahmen für Ereignisse dar, deren genaue Dauer unbekannt ist. Es ergänzt 'Duration', das bekannte Dauern darstellt. Abbildung 4 zeigt zwar die Verteilung jeder Dimension, stellt aber deren Beziehung nicht visuell dar.;'Duration Upper-bound' represents a maximum time frame for events with unknown exact durations, complementing 'Duration', which represents known durations. While Figure 4 shows the distribution of each dimension, it doesn't visually depict their relationship.;Ergänzt 'Duration';Complements 'Duration';Requires Paper Context;"Figure 3: Examples of the extraction process for each temporal dimensions. The temporal arguments are marked orange and the result of the extraction are tuples of the form (event,value,dimension).

help the prediction of other dimensions. The auxiliary dimensions we define here are event Duration _Upper-bound and event Relative Hierarchy. The_ former represents values that are upper-bounds to an event’s duration but not necessarily the exact duration. The latter consists of two sub-relations, namely temporal ordering and duration inclusion of event-pairs.

**3.3** **Cheap Supervision from Patterns**

...

**Duration Upper-bound.** Many temporal arguments describe the duration upper-bound instead of the exact duration value. For example, as described in (Gusev et al., 2011), “did [activity] yesterday” indicates something that happened within a day. We extend the set of patterns to include “in [temporal expression]” or keywords such as “next” (e.g., “the next day”), “last” (e.g., “last week”), “previous” (e.g., “previous month”), or “recent” (e.g., “recent years”). We normalize the values into the same label set of the nine unit words as the duration dimension."
2020.acl-main.709.pdf-Figure2.png;'Wie hoch ist der Prozentsatz von 'Splitting + Paraphrase' im Kreisdiagramm 'Newsela-Auto'?';'What is the percentage of 'Splitting + Paraphrase' in the 'Newsela-Auto' pie chart?';33%;33%;33%;33%;Simple Retrieval;'
2020.acl-main.709.pdf-Figure2.png;'Was ist die Summe der Prozentsätze von 'Deletion' und 'Not Simpler' im Kreisdiagramm 'Newsela-Auto'?';'What is the sum of the percentages of 'Deletion' and 'Not Simpler' in the 'Newsela-Auto' pie chart?';17%;17%;17%;17%;Simple Calculation;'
2020.acl-main.709.pdf-Figure2.png;'Welches Kreisdiagramm zeigt den größten Unterschied zwischen 'Paraphrase' und 'Splitting + Paraphrase': 'Newsela (Old)', 'Newsela-Auto', 'WIKI-Auto' oder 'Wikipedia (Old)'?  Wie groß ist dieser Unterschied?';'Which pie chart shows the largest difference between 'Paraphrase' and 'Splitting + Paraphrase': 'Newsela (Old)', 'Newsela-Auto', 'WIKI-Auto', or 'Wikipedia (Old)'? What is this difference?';Newsela (Old) hat den größten Unterschied mit 22%.;Newsela (Old) has the largest difference at 22%.;Newsela (Old), 22%;Newsela (Old), 22%;Complex Calculation and Logical Reasoning;'
2020.acl-main.709.pdf-Figure2.png;'Welches Kreisdiagramm hat den höchsten kumulierten Prozentsatz für Kategorien, die 'Paraphrase' enthalten ('Paraphrase', 'Deletion + Paraphrase', 'Splitting + Paraphrase')?';'Which pie chart has the highest combined percentage for categories including 'Paraphrase' ('Paraphrase', 'Deletion + Paraphrase', 'Splitting + Paraphrase')?';Newsela (Old) hat den höchsten kumulierten Prozentsatz mit 64%.;Newsela (Old) has the highest combined percentage at 64%.;Newsela (Old), 64%;Newsela (Old), 64%;Complex Calculation and Logical Reasoning;'
2020.acl-main.709.pdf-Figure2.png;'Inwieweit spiegeln die 'Not Aligned' und 'Not Simpler'-Segmente der WIKI-AUTO- und Wikipedia (Old)-Diagramme die im Text erwähnte Verbesserung der Datenqualität von 75% weniger fehlerhaften Satzpaaren wider?';'How do the 'Not Aligned' and 'Not Simpler' segments in the WIKI-AUTO and Wikipedia (Old) pie charts reflect the stated improvement of 75% fewer defective sentence pairs mentioned in the text?';'In Wikipedia (Old) stellen 'Not Aligned' und 'Not Simpler' 48% der Daten dar. In WIKI-AUTO machen diese Kategorien 12% aus. Dies ist eine Reduktion um 75% ((48-12)/48 * 100 = 75), was die angegebene Verbesserung bestätigt.';'In Wikipedia (Old), 'Not Aligned' and 'Not Simpler' represent 48% of the data.  In WIKI-AUTO, these categories account for 12%. This is a 75% reduction ((48-12)/48 * 100 = 75), confirming the stated improvement.';75% Reduktion bestätigt;75% reduction confirmed;Caption Question/Complex Calculation and Logical Reasoning;'Figure 2: Manual inspection of 100 random sentence pairs from our corpora (NEWSELA-AUTO and WIKIAUTO) and the existing Newsela (Xu et al., 2015) and Wikipedia (Zhang and Lapata, 2017) corpora. Our corpora contain at least 44% more complex rewrites (Dele_tion + Paraphrase or Splitting + Paraphrase) and 27%_ less defective pairs (Not Aligned or Not Simpler).'
2020.acl-main.711.Dataset.pdf-Figure3.png;Welche Farbe repräsentiert den größten Anteil im Kreisdiagramm?;Which color represents the largest portion in the pie chart?;Blau repräsentiert den größten Anteil (FM).;Blue represents the largest portion (FM).;Blau;Blue;Simple Retrieval;'
2020.acl-main.711.Dataset.pdf-Figure3.png;Um wie viele Prozentpunkte ist der blaue Anteil größer als der orange Anteil?;How many percentage points larger is the blue portion than the orange portion?;Der blaue Anteil (45,6%) ist 43,8 Prozentpunkte größer als der orange Anteil (1,8%).;The blue share (45.6%) is 43.8 percentage points larger than the orange share (1.8%).;43,8;43.8;Simple Calculation;'
2020.acl-main.711.Dataset.pdf-Figure3.png;Was ist das Verhältnis des zweitgrößten zum kleinsten Kreissegment?;What is the ratio of the second largest to the smallest pie segment?;Das zweitgrößte Segment ist grün (29,8%) und das kleinste ist orange (1,8%). Das Verhältnis beträgt 29,8 / 1,8 = 16,56.;The second largest segment is green (29.8%) and the smallest is orange (1.8%). The ratio is 29.8 / 1.8 = 16.56.;16,56;16.56;Simple Calculation;'
2020.acl-main.711.Dataset.pdf-Figure3.png;Ist die Summe der Prozentsätze aller Segmente außer dem größten größer als der Prozentsatz des größten Segments?;Is the sum of the percentages of all segments except the largest greater than the percentage of the largest segment?;Das größte Segment ist blau (45,6%). Die Summe der anderen beträgt 29,8% + 22,8% + 1,8% = 54,4%. Also ja, die Summe ist größer.;The largest segment is blue (45.6%). The sum of the others is 29.8% + 22.8% + 1.8% = 54.4%. So yes, the sum is larger.;Ja;Yes;Complex Calculation and Logical Reasoning;'
2020.acl-main.711.Dataset.pdf-Figure3.png;Basierend auf den im Abschnitt 6.3 des Artikels beschriebenen Ergebnissen, welche Modellvariante schnitt am zweitschlechtesten ab, und welche Farbe repräsentiert diese Variante im Kreisdiagramm?;Based on the results discussed in section 6.3 of the paper, which model variation performed second worst, and which color represents this variation in the pie chart?;Die Modellvariante ohne die Umkehrung der Valenz (NoRV) schnitt am zweitschlechtesten ab. Dies wird durch das orange Segment im Kreisdiagramm dargestellt.;The model variation that excluded Reversal of Valence (NoRV) performed second worst. This is represented by the orange segment in the pie chart.;Orange;Orange;Requires Paper Context;"We focus our ablation study on the metric of sarcasticness, as we consider this as the main criterion

As shown in Figure 3, our best model (FM) outperforms individual ablation modules. We filtered out 60 examples from the 150 with no ties. The ablation component employing just Reversal of Valence is second best for sarcasticness according to Figure 3."
2020.eamt-1.2.pdf-Figure1.png;'Welcher Prozentsatz der Teilnehmer antwortete mit 'Nein'?';'What percentage of participants answered 'No'?';44%;44%;44%;44%;Simple Retrieval;'
2020.eamt-1.2.pdf-Figure1.png;'Wie groß ist die Differenz (in Prozentpunkten) zwischen den Antworten 'Ja' und 'Ich weiß nicht'?';'What is the percentage point difference between the 'Yes' and 'I don't know' answers?';28 Prozentpunkte.;28 percentage points.;28;28;Simple Calculation;'
2020.eamt-1.2.pdf-Figure1.png;'Welcher Prozentsatz der Teilnehmer antwortete entweder mit 'Ja' oder 'Nein'?';'What percentage of participants answered either 'Yes' or 'No'?';86%;86%;86%;86%;Simple Calculation;'
2020.eamt-1.2.pdf-Figure1.png;'Ist der kombinierte Prozentsatz von 'Nein' und 'Ich weiß nicht' größer als der Prozentsatz von 'Ja'?';'Is the combined percentage of 'No' and 'I don't know' greater than the percentage of 'Yes'?';Ja.;Yes.;Ja;Yes;Simple Calculation;'
2020.eamt-1.2.pdf-Figure1.png;Die Studie erwähnt, dass 42% der Teilnehmer, die in einem englischsprachigen Land leben, angaben, dass Überschwemmungen in ihrem Wohngebiet häufig vorkommen. Wie verhält sich dieser Wert im Vergleich zum Gesamtanteil der Teilnehmer, die angaben, dass Überschwemmungen häufig vorkommen (42%)?;The study mentions that 42% of participants living in an English-speaking country reported that flooding was common where they lived. How does this percentage compare to the overall percentage of participants who said flooding was common (42%)?;Die Prozentsätze sind identisch.;The percentages are identical.;Identisch;Identical;Requires Paper Context;'42% of the 48 participants living in an Eng lish-speaking country stated that flooding— namely, the weather-related crisis that is the focus of our study—was common where they lived, with 14% not knowing, as shown in Figure 1.'
2020.figlang-1.23.Dataset.pdf-Figure3.png;Welche Metapher nimmt den größten Teil des Kreisdiagramms ein?;Which metaphor occupies the largest portion of the pie chart?;Forceful Extraction;Forceful Extraction;Forceful Extraction;Forceful Extraction;Simple Retrieval;'
2020.figlang-1.23.Dataset.pdf-Figure3.png;'Ist der Anteil von 'Physical Location' größer oder kleiner als der Anteil von 'War'?';'Is the portion of 'Physical Location' larger or smaller than the portion of 'War'?';Größer;Larger;Größer;Larger;Simple Calculation;'
2020.figlang-1.23.Dataset.pdf-Figure3.png;'Welches Verhältnis besteht zwischen dem Segment 'Forceful Extraction' und der Summe der Segmente 'Medicine' und 'Physical Location'?';'What is the ratio between the 'Forceful Extraction' segment and the sum of the 'Medicine' and 'Physical Location' segments?';'Visuell ist das Segment 'Forceful Extraction' größer als die kombinierten Segmente 'Medicine' und 'Physical Location'. Ein genaues Verhältnis lässt sich aus dem Diagramm allein nicht bestimmen.';'Visually, the segment 'Forceful Extraction' is larger than the combined segments 'Medicine' and 'Physical Location'. A precise ratio cannot be determined from the diagram alone.';'Größer';Larger;Complex Calculation and Logical Reasoning;'
2020.figlang-1.23.Dataset.pdf-Figure3.png;'Wenn die Segmente 'War', 'Medicine' und 'Physical Location' kombiniert würden, wären sie größer oder kleiner als das Segment 'Forceful Extraction'?';'If the segments 'War', 'Medicine', and 'Physical Location' were combined, would they be larger or smaller than the 'Forceful Extraction' segment?';Kleiner;Smaller;Kleiner;Smaller;Complex Calculation and Logical Reasoning;'
2020.figlang-1.23.Dataset.pdf-Figure3.png;'Der Artikel erwähnt die Verwendung von Metaphern, um die Haltung verschiedener Gemeinschaften zum Thema der Gleichstellung in der Ehe zu analysieren. In Abbildung 3, die die progressiven Quellen darstellt, dominiert die Metapher der 'gewaltsamen Extraktion'. Basierend auf dem Artikel und der Abbildung 3, welche anderen Metaphern in den progressiven Quellen deuten ebenfalls auf eine 'gewaltsame' oder restriktive Haltung gegenüber der Gleichstellung in der Ehe hin und warum?';'The paper mentions using metaphors to analyze the stance of different communities on the topic of marriage equality. In Figure 3, which represents progressive sources, the metaphor of 'Forceful Extraction' dominates. Based on the paper and Figure 3, which other metaphors present in the progressive sources also suggest a 'forceful' or restrictive stance towards marriage equality and why?';Barriere, Wettbewerb und Kampf könnten restriktive Haltungen gegen die Gleichstellung in der Ehe darstellen, weil sie Hindernisse und Widerstand bedeuten und die Implikationen gewaltsamer Extraktion widerspiegeln.;Barrier, Competition, and Struggle could represent restrictive stances against marriage equality because they signify obstacles and opposition, mirroring the implications of forceful extraction.;Barriere, Wettbewerb, Kampf;Barrier, Competition, Struggle;Caption Question/Complex Calculation and Logical Reasoning;'
2020.lincr-1.7.pdf-Figure2.png;Welche Emotion macht den zweitgrößten Anteil im Kreisdiagramm aus?;Which emotion represents the second largest portion of the pie chart?;Angst stellt mit 23,2 % den zweitgrößten Anteil dar.;Fear represents the second largest portion at 23.2%. ;Angst;Fear;Simple Retrieval;'
2020.lincr-1.7.pdf-Figure2.png;Wie groß ist der Unterschied zwischen den Anteilen von Angst und Wut?;What is the difference between the percentages of Fear and Anger?;Der Unterschied zwischen Angst (23,2 %) und Wut (9 %) beträgt 14,2 %.;The difference between Fear (23.2%) and Anger (9%) is 14.2%. ;14,2%;14.2%;Simple Calculation;'
2020.lincr-1.7.pdf-Figure2.png;Welcher Anteil wird durch die Emotionen Überraschung, Traurigkeit und Freude zusammengenommen im Kreisdiagramm dargestellt?;What combined percentage of the pie chart is represented by Surprise, Sadness, and Joy?;Der kombinierte Prozentsatz von Überraschung (5,22 %), Traurigkeit (13,4 %) und Freude (22,3 %) beträgt 40,92 %.;The combined percentage of Surprise (5.22%), Sadness (13.4%), and Joy (22.3%) is 40.92%. ;40,92%;40.92%;Simple Calculation;'
2020.lincr-1.7.pdf-Figure2.png;'Der Text erwähnt den Datensatz 'DailyDialog'. Welche Emotionen werden in diesem Datensatz verwendet und welche Emotion aus Plutchik's Modell fehlt in diesem Datensatz?';'The text mentions the 'DailyDialog' dataset.  Which emotions are used in this dataset, and which emotion from Plutchik's model is missing from this dataset?';'Der DailyDialog-Datensatz verwendet Ekmans 'Große Sechs' Emotionen: Wut, Ekel, Angst, Freude, Traurigkeit und Überraschung. Vertrauen (und anfänglich auch Erwartung) fehlt und wird später aus anderen Datensätzen wie WordNet-Affect hinzugefügt.';'The DailyDialog dataset uses Ekman's 'Big Six' emotions: anger, disgust, fear, joy, sadness, and surprise.  Trust (and anticipation initially) is missing and added later from other datasets like WordNet-Affect.';Vertrauen/Erwartung;Trust/Anticipation;Requires Paper Context;'Dailydialog (Li et al., 2017) is annotated with the Big Six emotions of Ekman, [...] Wordnet samples will help us generate the missing labels in other corpora such as Surprise and Anticipation.'
2020.lrec-1.345.pdf-Figure1.png;Wie hoch ist der Prozentsatz der ausgestorbenen Sprachen?;What is the percentage of extinct languages?;3,5%;3.5%;3,5%;3.5%;Caption Question/Simple Retrival;'
2020.lrec-1.345.pdf-Figure1.png;Wie viele Sprachen sind vom Aussterben bedroht (einschließlich ausgestorbener Sprachen)?;How many languages are endangered (including extinct languages)?;2680;2680;2680;2680;Caption Question/Simple Retrival;'
2020.lrec-1.345.pdf-Figure1.png;Wie viele Sprachen sind sicher oder es gibt keine Daten darüber?;How many languages are safe or have no data about them?;4020;4020;4020;4020;Caption Question/Simple Retrival;'
2020.lrec-1.345.pdf-Figure1.png;Wie viele Sprachen sind insgesamt gefährdet (vom Aussterben bedroht, stark gefährdet, definitiv gefährdet, gefährdet und ausgestorben)?;How many languages are in total endangered (critically endangered, severely endangered, definitely endangered, vulnerable and extinct)?;2445;2445;2445;2445;Caption Question/Simple Calculation;'
2020.lrec-1.345.pdf-Figure1.png;Warum ist es wichtig, Gondi zu erhalten, und welche Herausforderungen gibt es speziell für die Bildung von Kindern, die Gondi sprechen, wie im Text erwähnt?;Why is it important to preserve Gondi, and what challenges are there specifically for the education of children who speak Gondi, as mentioned in the text?;Die Erhaltung von Gondi ist wichtig, da Sprache Kultur und Traditionen überträgt.  Der Verlust von Gondi bedeutet einen Verlust des kulturellen Erbes. Da Gondi nicht im 8. Anhang der indischen Verfassung aufgeführt ist, kann es nicht in der Bildung und bei Prüfungen für Regierungsjobs verwendet werden.  Das Fehlen von Gondi als Unterrichtssprache in der Grundschule erhöht die Wahrscheinlichkeit, dass Gondi-sprechende Kinder scheitern oder die Schule abbrechen.;Preserving Gondi is crucial because language transmits culture and tradition.  Its loss signifies a loss of cultural heritage. Gondi's exclusion from the 8th Schedule of the Indian Constitution prevents its use in education and government job exams.  The absence of Gondi as a medium of instruction in primary schools increases the likelihood of Gondi-speaking children failing or dropping out.;Kultureller Verlust, Bildungsbenachteiligung;Cultural loss, Educational disadvantage;Requires Paper Context;'Gondi is also not included in the 8[th] Schedule of the Indian Constitution, with the result that education and exams for government jobs cannot be administered in the language. [...] A 2008 UNESCO study found that children whose mother tongue is not the medium of instruction at primary school are more likely to fail in early grades or drop out'
2020.lrec-1.38.pdf-Figure4.png;Welche Antwortmöglichkeit stellt das kleinste Segment im Kreisdiagramm dar?;Which answer option represents the smallest segment in the pie chart?;''Ja, sehr' stellt das kleinste Segment im Diagramm mit einem Wert von 1 dar.;''Yes, very much' represents the smallest segment in the chart with a value of 1.;'Ja, sehr';'Yes, very much';Simple Retrieval;'
2020.lrec-1.38.pdf-Figure4.png;'Was ist die Summe der Werte der Segmente 'Nein, eher nicht' und 'Nein, definitiv nicht'?';'What is the sum of the values of the segments 'No, rather not' and 'No, definitely not'?';Die Summe der Werte ist 5.;The sum of the values is 5.;5;5;Simple Calculation;'
2020.lrec-1.38.pdf-Figure4.png;'Wie viel Prozent der Befragten gaben an, dass der LingoGameBot ihnen nicht beim Vokabeltraining geholfen hat (einschließlich 'Nein, eher nicht', 'Nein, definitiv nicht' und 'Nicht sicher')?';'What percentage of respondents indicated that the LingoGameBot did not help them improve their vocabulary (including 'No, rather not', 'No, definitely not', and 'Not sure')?';40%;40%;40%;40%;Complex Calculation and Logical Reasoning;'
2020.lrec-1.38.pdf-Figure4.png;'Um wie viel Prozentpunkte ist der Anteil der Befragten, die angaben, dass der LingoGameBot ihnen 'etwas' geholfen hat, größer als der Anteil derjenigen, die angaben, dass er ihnen 'sehr' geholfen hat?';'By how many percentage points is the proportion of respondents who said the LingoGameBot helped them 'somewhat' greater than the proportion of those who said it helped them 'very much'?';54,28 Prozentpunkte;54.28 percentage points;54,28;54.28;Complex Calculation and Logical Reasoning;'
2020.lrec-1.38.pdf-Figure4.png;'In der Studie wird ein leichter positiver Trend bei der Verbesserung des Wortschatzes erwähnt, trotz der kurzen Experimentdauer. Abbildung 4 zeigt die Verteilung der Antworten. Welcher Prozentsatz der Befragten gab an, dass sich ihr Wortschatz zumindest etwas verbessert hat (Kombination der Antworten 'Ja, sehr' und 'Ja, etwas')?';'The study mentions a slight positive trend in vocabulary improvement, despite the short experiment duration. Figure 4 shows the distribution of responses. What percentage of respondents reported at least some improvement in their vocabulary (combining 'Yes, very much' and 'Yes, somewhat' responses)?';60%;60%;60%;60%;Complex Calculation and Logical Reasoning;'
2020.lrec-1.414.pdf-Figure1.png;Welcher Kontinent wird durch den grauen Abschnitt des Kreisdiagramms dargestellt?;Which continent is represented by the grey segment of the pie chart?;Nordamerika;North America;Nordamerika;North America;Simple Retrieval;'
2020.lrec-1.414.pdf-Figure1.png;Wie hoch ist der Prozentsatz der Publikationen aus Europa und Asien zusammen?;What is the combined percentage of publications from Europe and Asia?;61%;61%;61%;61%;Simple Calculation;'
2020.lrec-1.414.pdf-Figure1.png;Wie viele Publikationen wurden in Nordamerika veröffentlicht?;How many publications came from North America?;227;227;227;227;Simple Retrieval;'
2020.lrec-1.414.pdf-Figure1.png;Wenn die Gesamtzahl der Publikationen 600 wäre, wie viele Publikationen kämen dann aus jedem der drei Kontinente?;If the total number of publications were 600, how many publications would come from each of the three continents?;Nordamerika: 234, Europa: 222, Asien: 144;North America: 234, Europe: 222, Asia: 144;234, 222, 144;234, 222, 144;Complex Calculation and Logical Reasoning;'
2020.lrec-1.414.pdf-Figure1.png;In Anbetracht der Verteilung der Publikationen nach Regionen (Abbildung 1) und des zunehmenden Trends der Forschungspublikationen aus Asien in den letzten zwei Jahren, wie könnte sich diese Verteilung in Zukunft verschieben, wenn sich der Trend fortsetzt?  Begründen Sie Ihre Antwort.;Considering the distribution of publications across regions (Figure 1) and the increasing trend of research publications from Asia in the last two years, how might this distribution shift in the future if the trend continues? Explain your reasoning.;Wenn der zunehmende Trend der Veröffentlichungen aus Asien anhält, wird das Asien-Segment des Kreisdiagramms wachsen, während die Segmente Nordamerika und Europa wahrscheinlich schrumpfen werden. Die genaue Verschiebung hängt von der Steigerungsrate der asiatischen Veröffentlichungen im Vergleich zu den Veröffentlichungsraten in Nordamerika und Europa ab.;If the increasing trend of publications from Asia continues, the Asia segment of the pie chart will grow, while the North America and Europe segments will likely shrink. The exact shift will depend on the rate of increase in Asian publications relative to the publication rates in North America and Europe.;Asien wächst, Nordamerika/Europa schrumpfen;Asia grows, North America/Europe shrink;Requires Paper Context;'Number of publications in top conferences and journals is very similar for North America and Europe (Figure 1). However, it should be noted that the trend in the last two years is an increasing amount of research in Asia.'
2020.lrec-1.46.pdf-Figure2.png;Welche Farbe repräsentiert den größten Anteil im Kreisdiagramm?;Which color represents the largest segment in the pie chart?;'Hellblau, das mit 43,64% 'zustimmen' entspricht.';'Light blue, representing 'agree' with 43.64%.';Hellblau;Light blue;Simple Retrieval;'
2020.lrec-1.46.pdf-Figure2.png;'Wie groß ist der prozentuale Unterschied zwischen denjenigen, die 'zustimmen', und denjenigen, die 'stark zustimmen'?';'What is the percentage difference between those who 'agree' and those who 'strongly agree'?';26,69%;26.69%;26,69%;26.69%;Simple Calculation;'
2020.lrec-1.46.pdf-Figure2.png;'Wie viel Prozent der Befragten haben das Tool entweder nicht benutzt oder nicht zugestimmt ('stimme nicht zu' und 'stimme überhaupt nicht zu')?';'What percentage of respondents either did not use the tool or disagreed ('disagree' and 'strongly disagree')?';16,53%;16.53%;16,53%;16.53%;Simple Calculation;'
2020.lrec-1.46.pdf-Figure2.png;'Ist der kombinierte Prozentsatz derjenigen, die 'zustimmen' oder 'stark zustimmen', größer als der kombinierte Prozentsatz aller anderen Antworten?';'Is the combined percentage of those who 'agree' or 'strongly agree' greater than the combined percentage of all other responses?';Ja;Yes;Ja;Yes;Simple Calculation;'
2020.lrec-1.46.pdf-Figure2.png;Abbildung 2 zeigt, dass viele Studenten das Online-Tool zur Fehlererkennung nützlich fanden. Abschnitt 6.1 erwähnt, dass drei Aufgaben aus der Bewertung entfernt wurden. Wie könnte sich die Entfernung dieser Aufgaben angesichts der positiven Rückmeldungen in Abbildung 2 auf die Gesamtwahrnehmung der Nützlichkeit des Tools ausgewirkt haben, und welche möglichen Implikationen könnten sich daraus für zukünftige Bewertungen ergeben?;Figure 2 shows that many students found the online error detection tool useful. Section 6.1 mentions that three assignments were removed from the evaluation. Considering the positive feedback in Figure 2, how might the removal of these assignments have affected the overall perception of the tool's usefulness, and what potential implications could this have for future evaluations?;Das Entfernen der drei Aufgaben, die eine signifikante Verbesserung der Schüler mit dem Tool zeigten, könnte die allgemeine wahrgenommene Nützlichkeit erhöhen. Zukünftige Auswertungen sollten eine repräsentative Stichprobe beibehalten oder die potenzielle Verzerrung durch die Entfernungsmethode berücksichtigen.;Removing the three assignments, which showed significant student improvement with the tool, could inflate the overall perceived usefulness. Future evaluations should maintain a representative sample or account for potential bias introduced by the removal methodology.;Verzerrung der Ergebnisse;Inflated usefulness;Requires Paper Context;'Three assignments were unanimously removed from this sample, because the contents of the assignments differed too much, and were not deemed comparable – all other 105 assignments were deemed comparable, differing only in style or sentence structure, but not in content.'
2020.lrec-1.604.pdf-Figure3.png;Welche Farbe repräsentiert den größten Anteil im Kreisdiagramm?;What color represents the largest portion in the pie chart?;Hellblau.;Light blue.;Hellblau;Light blue;Caption Question/Simple Retrieval;'
2020.lrec-1.604.pdf-Figure3.png;Wenn 100 Vorhersagen gemacht wurden, wie viele davon waren falsch?;If 100 predictions were made, how many of them were wrong?;30;30;30;30;Caption Question/Simple Calculation;'
2020.lrec-1.604.pdf-Figure3.png;Wie viel Prozent aller Vorhersagen sind korrekt?;What percentage of all predictions are correct?;70%;70%;70%;70%;Caption Question/Simple Retrieval;'
2020.lrec-1.604.pdf-Figure3.png;Wie verhält sich die Anzahl der korrekten Vorhersagen zur Anzahl der falschen Vorhersagen?;What is the ratio of correct predictions to incorrect predictions?;70:30 oder 7:3;70:30 or 7:3;70:30;70:30;Caption Question/Simple Calculation;'
2020.lrec-1.604.pdf-Figure3.png;Wie schneidet das Mazajak-Tool bei Sätzen ohne Metaphern im Vergleich zu Sätzen mit Metaphern ab (unter Bezugnahme auf Abbildung 2 und 3 sowie den dazugehörigen Text)? Was lässt dies über die Fähigkeiten des Tools im Umgang mit Metaphern schließen?;How does the Mazajak tool perform on sentences without metaphors compared to sentences with metaphors (referencing Figures 2 and 3, and the surrounding text)? What does this suggest about the tool's ability to handle metaphors?;Das Mazajak-Tool erreichte eine Genauigkeit von 70% bei Sätzen ohne Metaphern und 40% bei Sätzen mit Metaphern. Dies deutet auf einen signifikanten Leistungsabfall im Umgang mit Metaphern hin, was darauf hindeutet, dass das Tool Schwierigkeiten hat, diese korrekt zu interpretieren.;The Mazajak tool achieved 70% accuracy on sentences without metaphors and 40% accuracy on sentences with metaphors. This indicates a significant drop in performance when dealing with metaphors, suggesting that the tool struggles to interpret them correctly.;70% ohne Metaphern, 40% mit Metaphern;70% without metaphors, 40% with metaphors;Requires Paper Context;'As shown in figure 2, the Mazajak tool achieved an impressive result on the sentences that do not contain any metaphors, correctly classifying the sentiment of 70% sentences with only 30% error rate. On the other hand, as shown in figure 3, when dealing with the sentences that contain metaphors, its performance degraded significantly by 10 percent, producing 60% and 40% accuracy and error rates respectively.'
2020.lrec-1.627.pdf-Figure3.png;'Wie hoch ist der Prozentsatz der Tweets mit 'Teilweiser Zustimmung'?';'What is the percentage of tweets rated as 'Partial Agreement'?';43,0%;43.0%;43%;43%;Simple Retrieval;'
2020.lrec-1.627.pdf-Figure3.png;'Was ist die Differenz in Prozentpunkten zwischen den Bewertungen 'Zustimmung' und 'Ablehnung'?';'What is the difference in percentage points between the 'Agreement' and 'Disagreement' ratings?';11,2%;11.2%;11,2%;11.2%;Simple Calculation;'
2020.lrec-1.627.pdf-Figure3.png;'Wie hoch ist der Gesamtprozentsatz der Tweets mit den Bewertungen 'Zustimmung' oder 'Teilweise Zustimmung'?';'What is the total percentage of tweets rated as either 'Agreement' or 'Partial Agreement'?';77,1%;77.1%;77,1%;77.1%;Simple Calculation;'
2020.lrec-1.627.pdf-Figure3.png;'Ist der Anteil der Tweets mit 'Teilweiser Zustimmung' größer oder kleiner als die Summe der Anteile mit 'Zustimmung' und 'Ablehnung'?';'Is the percentage of tweets with 'Partial Agreement' greater or less than the sum of the percentages with 'Agreement' and 'Disagreement'?';Kleiner als. Teilweise Zustimmung (43,0%) < Zustimmung (34,1%) + Ablehnung (22,9%) = 57,0%;Less than. Partial Agreement (43.0%) < Agreement (34.1%) + Disagreement (22.9%) = 57.0%;Kleiner;Less than;Complex Calculation and Logical Reasoning;'
2020.lrec-1.627.pdf-Figure3.png;Welche drei Szenarien für die Inter-Annotator-Übereinstimmung (IAA) werden im Text erwähnt, und wie lauten die jeweiligen Prozentsätze im Diagramm?;What three scenarios for Inter-Annotator Agreement (IAA) are mentioned in the text, and what are their corresponding percentages in the chart?;Zustimmung (34,1%), Teilweise Zustimmung (43,0%) und Ablehnung (22,9%).;Agreement (34.1%), Partial Agreement (43.0%), and Disagreement (22.9%).;34,1%, 43%, 22,9%;34.1%, 43%, 22.9%;Caption Question/Simple Retrieval;'
2020.lrec-1.701.pdf-Figure1.png;Welcher Abschnitt im Kreisdiagramm ist am kleinsten?;Which segment in the pie chart is the smallest?;Das kleinste Segment ist das graue, das Klasse 3 repräsentiert.;The smallest segment is the grey one, representing Class 3.;Klasse 3;Class 3;Simple Retrieval;'
2020.lrec-1.701.pdf-Figure1.png;Wie hoch ist der Prozentsatz des zweitkleinsten Abschnitts im Kreisdiagramm?;What is the percentage of the second smallest segment in the pie chart?;Der zweitkleinste Abschnitt ist der rote, der Klasse 5 entspricht und 1,5 % des Kreisdiagramms ausmacht.;The second smallest segment is the red one representing Class 5 which makes up 1.5% of the pie chart.;1,5%;1.5%;Simple Retrieval;'
2020.lrec-1.701.pdf-Figure1.png;Um wie viel Prozent ist der größte Abschnitt größer als die Summe der Abschnitte der Klassen 3, 4 und 5?;By what percentage is the largest segment larger than the sum of the segments of classes 3, 4, and 5?;Der größte Abschnitt ist 37,7 % größer als die Summe der Abschnitte der Klassen 3, 4 und 5.;The largest segment is 37.7% larger than the sum of the segments of classes 3, 4, and 5.;37,7%;37.7%;Simple Calculation;'
2020.lrec-1.701.pdf-Figure1.png;Ist das Verhältnis des größten Abschnitts zum kleinsten Abschnitt größer als 30?;Is the ratio of the largest segment to the smallest segment greater than 30?;Ja, das Verhältnis beträgt ungefähr 70,7 und ist somit größer als 30.;Yes, the ratio is approximately 70.7, which is greater than 30.;Ja;Yes;Simple Calculation;'
2020.lrec-1.701.pdf-Figure1.png;Abbildung 1 zeigt die Verteilung der Klassen für ironische Weibo-Posts. Laut dem Artikel sind ironische Posts (Klassen 4 und 5) mit ungefähr 11,1 % relativ selten. Stimmt diese Aussage mit den in Abbildung 1 dargestellten Daten überein?;Figure 1 shows the class distribution for ironic Weibo posts. According to the article, ironic posts (classes 4 and 5) are relatively rare, at approximately 11.1%. Does this statement align with the data presented in Figure 1?;Ja, die Aussage stimmt mit Abbildung 1 überein. Die Klassen 4 und 5 machen zusammen 11,1 % des Gesamtanteils aus.;Yes, the statement aligns with Figure 1.  Classes 4 and 5 combined represent 11.1% of the total.;Ja;Yes;Caption Question/Simple Calculation;'
2020.lrec-1.890.pdf-Figure5.png;Welcher Merkmalskategorie ist die größte Anzahl von Merkmalen zugeordnet?;Which feature category has the largest number of features associated with it?;Morpho-syntaktisch, mit 19 Merkmalen.;Morpho-syntactic, with 19 features.;Morpho-syntaktisch;Morpho-syntactic;Simple Retrieval;'
2020.lrec-1.890.pdf-Figure5.png;Wie viel Prozent der ausgewählten Merkmale machen die lexikalischen und syntaktischen Merkmale zusammen aus?;What percentage of the selected features do the Lexical and Syntactic features represent combined?;48,15 % (26/54);48.15% (26/54);48,15%;48.15%;Simple Calculation;'
2020.lrec-1.890.pdf-Figure5.png;Wie viele Merkmale wurden insgesamt ausgewählt, und wie viele davon sind NICHT morpho-syntaktisch, lexikalisch oder syntaktisch?;How many features were selected in total, and how many of these are NOT Morpho-syntactic, Lexical, or Syntactic?;Insgesamt wurden 54 Merkmale ausgewählt, davon sind 9 nicht morpho-syntaktisch, lexikalisch oder syntaktisch (4 diskursiv + 4 Rohtext + 1 morphologisch).;54 features were selected in total, and 9 of these are not Morpho-syntactic, Lexical, or Syntactic (4 Discursive + 4 Raw-text + 1 Morphological).;54/9;54/9;Simple Calculation;'
2020.lrec-1.890.pdf-Figure5.png;Ist die Summe der Merkmale der drei kleinsten Kategorien größer als die Anzahl der lexikalischen Merkmale?;Is the sum of the features in the three smallest categories greater than the number of Lexical features?;Nein. Diskursiv (4) + Rohtext (4) + Morphologisch (1) = 9, was weniger als Lexikalisch (13) ist.;No. Discursive (4) + Raw-text (4) + Morphological (1) = 9, which is less than Lexical (13).;Nein;No;Simple Calculation;'
2020.lrec-1.890.pdf-Figure5.png;Abbildung 5 zeigt, dass die meisten ausgewählten Merkmale morpho-syntaktisch sind. Welche anderen Abbildung im Artikel bezieht sich auf diese Merkmale und welche Schlussfolgerung lässt sich daraus für die Bedeutung dieser Merkmalskategorie ziehen?;Figure 5 shows that the majority of selected features are morpho-syntactic.  Which other figure in the paper relates to these features and what conclusion can be drawn regarding the importance of this feature category?;Abbildung 6 zeigt die durchschnittlichen PFI-Werte für jede Merkmalskategorie. Obwohl morpho-syntaktische Merkmale am zahlreichsten sind, haben sie den dritt niedrigsten durchschnittlichen PFI-Wert, was darauf hindeutet, dass sie für die Klassifizierung der Textverständlichkeit im Vergleich zu anderen Merkmalskategorien wie syntaktischen, Rohtext- oder lexikalischen Merkmalen weniger wichtig sind.;Figure 6 shows the average PFI values for each feature category. Although morpho-syntactic features are the most numerous, they have the third lowest average PFI value, suggesting that they are less important for classifying text comprehensibility compared to other feature categories such as syntactic, raw text, or lexical features.;Abbildung 6: Geringere Wichtigkeit;Figure 6: Less important;Requires Paper Context;'Furthermore, for each selected feature, we computed its _permutation feature importance (PFI) score using the tech-_ nique described in (Fisher et al., 2018), i.e. the PFI of a feature is the mean percentage decrease of F1 score obtained by replacing the considered feature with random noise and cross validating again the model. The graph in Figure 6 shows the distribution of the PFI scores averaged among the different categories of linguistic features in order to see which of them had a higher impact in discriminating the classification of the texts.'
2020.osact-1.5.pdf-Figure2.png;Welche Stimmungskategorie macht den größten Teil des Kreisdiagramms aus?;Which sentiment category represents the largest portion of the pie chart?;Negative Stimmung macht den größten Teil (88%) aus.;Negative sentiment represents the largest portion (88%).;Negativ;Negative;Caption Question/Simple Retrieval;'
2020.osact-1.5.pdf-Figure2.png;How many tweets were classified as positive?;Wie viele Tweets wurden als positiv klassifiziert?;52 Tweets wurden als positiv klassifiziert.;52 tweets were classified as positive.;52;52;Caption Question/Simple Retrieval;'
2020.osact-1.5.pdf-Figure2.png;Wie viele sarkastische Tweets wurden insgesamt analysiert?;How many sarcastic tweets were analyzed in total?;Insgesamt wurden 1682 sarkastische Tweets analysiert.;1682 sarcastic tweets were analyzed in total.;1682;1682;Caption Question/Simple Calculation;'
2020.osact-1.5.pdf-Figure2.png;Wie viel Prozent der sarkastischen Tweets sind nicht negativ?;What percentage of sarcastic tweets are not negative?;12% der sarkastischen Tweets sind nicht negativ (9% neutral und 3% positiv).;12% of the sarcastic tweets are not negative (9% neutral and 3% positive).;12%;12%;Caption Question/Simple Calculation;'
2020.osact-1.5.pdf-Figure2.png;Inwiefern könnte die im Kreisdiagramm dargestellte Verteilung der Sarkasmus-Stimmung die Herausforderungen bei der Entwicklung robusterer Sentimentanalysemodelle verdeutlichen?;How might the distribution of sarcasm sentiment shown in the pie chart highlight the challenges in developing more robust sentiment analysis models?;Die überwältigende Mehrheit (88%) der sarkastischen Tweets ist als negative Stimmung gekennzeichnet. Dieses Ungleichgewicht kann Sentimentanalysemodelle beeinflussen und es schwierig machen, sarkastische Ausdrücke, die eigentlich neutral (9%) oder positiv (3%) sind, korrekt zu klassifizieren. Die begrenzten Beispiele für nicht-negative sarkastische Tweets erschweren es den Modellen, diese feinen Unterschiede zu erlernen und zu erkennen, was eine erhebliche Herausforderung bei der Entwicklung robusterer Sentimentanalysen darstellt.;The overwhelming majority (88%) of sarcastic tweets are labeled as negative sentiment. This imbalance can bias sentiment analysis models, making it difficult to accurately classify sarcastic expressions that are actually neutral (9%) or positive (3%). The limited examples of non-negative sarcastic tweets make it harder for models to learn and recognize these subtle differences, thus posing a significant challenge in developing more robust sentiment analysis.;Ungleichgewicht, Herausforderungen für Modelle;Imbalance, model challenges;Caption Question/Complex Calculation and Logical Reasoning;'
2020.osact-1.5.pdf-Figure3.png;Was ist der Titel des am weitesten links stehenden Kreisdiagramms?;What is the title of the leftmost pie chart?;POSITIV;POSITIVE;POSITIV;POSITIVE;Simple Retrieval;'
2020.osact-1.5.pdf-Figure3.png;'Wie hoch ist der Prozentsatz des negativen Stimmungswerts im Kreisdiagramm mit der Bezeichnung 'NEUTRAL'?';'What is the percentage of the negative sentiment in the pie chart labeled 'NEUTRAL'?';18%;18%;18%;18%;Simple Retrieval;'
2020.osact-1.5.pdf-Figure3.png;'Was ist die Summe der neutralen und positiven Prozentsätze im mit 'POSITIV' beschrifteten Kreisdiagramm?';'What is the sum of the neutral and positive percentages in the pie chart labeled 'POSITIVE'?';96%;96%;96%;96%;Simple Calculation;'
2020.osact-1.5.pdf-Figure3.png;Welche Stimmung hat den kleinsten Prozentsatz in allen drei Kreisdiagrammen zusammen und wie hoch ist dieser Prozentsatz?;Which sentiment has the smallest percentage across all three pie charts, and what is that percentage?;'Positive Stimmung, 2%, im Kreisdiagramm 'NEGATIV'.';'Positive sentiment, 2%, in the 'NEGATIVE' pie chart.';2%;2%;Complex Calculation and Logical Reasoning;'
2020.osact-1.5.pdf-Figure3.png;Die Bildunterschrift erwähnt eine Veränderung der Stimmung zwischen der ursprünglichen und der neuen Annotation.  Welche ursprüngliche Beschriftung zeigt die größte Veränderung der Stimmung und wie verteilt sich die Stimmung in der neuen Annotation?;The caption mentions a change in sentiment between original and new annotation. Which original label shows the largest change in sentiment, and how is the sentiment distributed in the new annotation?;'Das mit 'POSITIV' beschriftete Diagramm zeigt die größte Veränderung. Ursprünglich wäre es mit 100% positiv beschriftet gewesen. Die neue Annotation zeigt 49% positiv, 47% neutral und 4% negativ.';'The 'POSITIVE' labeled chart shows the largest change. Originally, it would be labeled 100% positive. The new annotation shows 49% positive, 47% neutral, and 4% negative.';POSITIV;POSITIVE;Caption Question/Complex Calculation and Logical Reasoning;'
C10-2016.pdf-Figure3.png;Welches Segment des Kreisdiagramms stellt den größten Prozentsatz dar?;Which segment of the pie chart represents the largest percentage?;NN-17 Zustand(e) stellt mit 42% den größten Prozentsatz dar.;NN-17 state(s) represents the largest percentage at 42%. ;NN-17;NN-17;Simple Retrieval;'
C10-2016.pdf-Figure3.png;Was ist der prozentuale Unterschied zwischen VV-3 und AD-3?;What is the percentage difference between VV-3 and AD-3?;Der prozentuale Unterschied zwischen VV-3 (10%) und AD-3 (9%) beträgt 1%.;The percentage difference between VV-3 (10%) and AD-3 (9%) is 1%. ;1%;1%;Simple Calculation;'
C10-2016.pdf-Figure3.png;Ist der Anteil von NN-17 größer als der kombinierte Anteil aller anderen Segmente?;Is NN-17 larger than the combined percentage of all the other segments?;Nein, NN-17 (42%) ist kleiner als der kombinierte Anteil aller anderen Segmente (58%).;No, NN-17 (42%) is smaller than the combined percentage of all other segments (58%).;Nein;No;Complex Calculation and Logical Reasoning;'
C10-2016.pdf-Figure3.png;'Die Bildunterschrift erwähnt einen 'EM-Algorithmus'.  Welche alternative Methode wird im Paper für unüberwachtes POS-Tagging erwähnt, die bessere Ergebnisse als traditionelle EM-, VB- und GS-Methoden liefert?';'The caption mentions an 'EM algorithm'. Which alternative method is mentioned in the paper for unsupervised POS tagging that yields better results than traditional EM, VB, and GS methods?';Das Posterior Regularization Framework, vorgeschlagen von Graça et al. (2009), wird als eine Methode erwähnt, die bessere Ergebnisse liefert.;The Posterior Regularization framework proposed by Graça et al. (2009) is mentioned as yielding better results.;Posterior Regularization Framework;Posterior Regularization framework;Requires Paper Context;'We have only scratched the surface of the research in unsupervised techniques in Chinese NLP. We have established a baseline of EM, VB and GS against the CTB 5.0. The experiment shows that for both Chinese and English, GS(c,w) produces the best result. We have also found that Chinese performs rather poorly in the 1-to-1 accuracy when comparing against English in the same data size. We find that in many-to-1 mapping, we have a disproportionate large number of states mapping to individual POS tags comparing to the gold distribution and also in comparison to English against its gold distribution. Graça et al. (2009) addresses the problem we observe in our resulting tag distributions in our model where EM, VB and GS fails to capture the shape of the true distribution. They propose a Posterior Regularization framework where it poses linear constraints on the posterior expectation.'
C10-2016.pdf-Figure4.png;Welcher POS-Tag repräsentiert den kleinsten Anteil an Wort-Token?;Which POS tag represents the smallest proportion of word tokens?;ADJ;ADJ;ADJ;ADJ;Simple Retrieval;'
C10-2016.pdf-Figure4.png;'Was ist die Summe der Prozentsätze der Wort-Token, die durch die POS-Tags 'ADJ' und 'PREP' repräsentiert werden?';'What is the sum of the percentages of word tokens represented by the POS tags 'ADJ' and 'PREP'?';16%;16%;16%;16%;Simple Calculation;'
C10-2016.pdf-Figure4.png;'Wenn die Gesamtzahl der Wort-Token 1 Million beträgt, wie viele Wort-Token werden dann durch die POS-Tags 'V', 'DET' und 'N' repräsentiert?';'If the total number of word tokens is 1 million, how many word tokens are represented by the POS tags 'V', 'DET', and 'N'?';640.000;640,000;640.000;640,000;Simple Calculation;'
C10-2016.pdf-Figure4.png;Wenn 'N', 'DET', 'V' und 'PREP' zusammen 74% der Wort-Token ausmachen und 'ADJ' 6% ausmacht, wie viel Prozent der Wort-Token werden dann von den restlichen POS-Tags repräsentiert?;If 'N', 'DET', 'V', and 'PREP' together account for 74% of the word tokens, and 'ADJ' accounts for 6%, what percentage of the word tokens are represented by the remaining POS tags?;20%;20%;20%;20%;Simple Calculation;'
C10-2016.pdf-Figure4.png;Abbildung 4 zeigt die Verteilung der Wort-Token auf verschiedene POS-Tags bei der Verwendung des EM-Algorithmus mit einem 500k-Datensatz und 50 States, die auf 17 POS-Tags abgebildet werden. Der Text erwähnt, dass bei der Verwendung von 50 States und 50 Tags eine gleichmäßigere Verteilung beobachtet wurde. Erklären Sie anhand von Abbildung 4 und dem Text, warum die Reduzierung der Anzahl der Tags zu einer ungleichmäßigeren Verteilung führt.;Figure 4 shows the word token distribution across different POS tags when using the EM algorithm with a 500k dataset and 50 states mapping to 17 POS tags. The text mentions that a more uniform distribution was observed when using 50 states and 50 tags. Using Figure 4 and the text, explain why reducing the number of tags leads to a less uniform distribution.;Mit 50 Zuständen und 50 Tags gibt es eine Eins-zu-Eins-Zuordnung, was zu einer gleichmäßigeren Verteilung führt. Wenn 50 Zustände nur 17 Tags zugeordnet sind, werden einigen Tags mehrere Zustände zugewiesen, was zu einer ungleichmäßigeren Verteilung führt, wie z. B. die Überrepräsentation von 'N'.;With 50 states and 50 tags, there is a one-to-one mapping, resulting in a more uniform distribution.  When 50 states map to only 17 tags, some tags are assigned multiple states, resulting in a less uniform distribution, such as the overrepresentation of 'N'.;Ungleichmäßige Verteilung durch mehrere Zustände pro Tag;Uneven distribution due to multiple states per tag;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-demos.18.pdf-Figure5.png;Welche Farbe haben die Punkte, die die Ergebnisse des zh-en Baidu-Systems darstellen?;What color are the dots representing the results of the zh-en Baidu-system?;Rot.;Red.;Rot;Red;Simple Retrieval;'
2020.acl-demos.18.pdf-Figure5.png;Wie hoch ist der höchste NDCG@10-Wert, der von einem blauen Punkt erreicht wird?;What is the highest NDCG@10 value achieved by a blue dot?;Ungefähr 1,0.;Approximately 1.0.;1.0;1.0;Simple Retrieval;'
2020.acl-demos.18.pdf-Figure5.png;Gibt es mehr rote Punkte mit einem NDCG@10-Wert über 0,9 als blaue Punkte mit einem NDCG@10-Wert über 0,9?;Are there more red dots with a NDCG@10 value above 0.9 than blue dots with a NDCG@10 value above 0.9?;Ja;Yes;Ja;Yes;Simple Calculation;'
2020.acl-demos.18.pdf-Figure5.png;Wenn Sie die Punkte in vier Quadranten aufteilen (basierend auf den Mittelwerten der BLEU- und NDCG@10-Achsen), welcher Quadrant enthält die meisten blauen Punkte?;If you divide the dots into four quadrants (based on the mean values of the BLEU and NDCG@10 axes), which quadrant contains the most blue dots?;Der obere linke Quadrant (höherer NDCG@10, niedrigerer BLEU).;The top-left quadrant (higher NDCG@10, lower BLEU).;Oben links;Top-left;Complex Calculation and Logical Reasoning;'
2020.acl-demos.18.pdf-Figure5.png;Der Text erwähnt, dass es keine klare Korrelation zwischen den beiden Metriken gibt. Wie manifestiert sich dieser Mangel an Korrelation visuell in der Verteilung der Punkte im Streudiagramm? Welche Merkmale der Verteilung deuten auf einen schwachen oder nicht vorhandenen Zusammenhang zwischen diesen beiden Metriken hin?;'The text mentions there is 'no clear correlation' between sentence-level NDCG@10 and BLEU.  How does this lack of correlation visually manifest in the distribution of the dots on the scatterplot? Describe the characteristics of the distribution that suggest a weak or non-existent relationship between these two metrics.';Die Punkte sind eher verstreut als entlang einer Linie oder Kurve geclustert. Diese verteilte Verteilung ohne erkennbares Muster deutet auf einen schwachen oder nicht vorhandenen Zusammenhang zwischen BLEU und NDCG@10 hin.;The dots are spread out rather than clustered along a line or curve.  This dispersed distribution, lacking any discernible pattern, suggests a weak or non-existent relationship between BLEU and NDCG@10.;Verstreut;Spread out;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.312.pdf-Figure2.png;Welches Symbol wird verwendet, um neutrale Datenpunkte darzustellen?;Which symbol is used to represent neutral data points?;Kreuze (x).;Crosses (x).;Kreuze;Crosses;Simple Retrieval;'
2020.acl-main.312.pdf-Figure2.png;Was ist das ungefähre Verhältnis zwischen dem höchsten und dem niedrigsten Polaritätswert im SST-Datensatz (Abbildung (a))?;What is the approximate ratio between the highest and lowest polarity scores in the SST dataset (figure (a))?;Ungefähr -1.;Approximately -1.;-1;-1;Simple Calculation;'
2020.acl-main.312.pdf-Figure2.png;Welches der sechs Diagramme weist die größte Varianz in den Werten auf der vertikalen Achse auf?  Begründen Sie Ihre Antwort mit dem ungefähren Wertebereich.;Which of the six plots shows the largest variance in values on the vertical axis? Justify your answer by stating the approximate range of values.;Abbildung (b), IMDB-Polaritätswerte, reicht von etwa -15 bis 20.;Figure (b), IMDB polarity scores, ranges from approximately -15 to 20.;Abbildung (b);Figure (b);Complex Calculation and Logical Reasoning;'
2020.acl-main.312.pdf-Figure2.png;Abschnitt 5 beschreibt den Einfluss des Skalierungsfaktors λ und den Zusammenhang mit Mean Pooling. Vergleichen Sie die Diagramme (d) und (b) in Abbildung 2. Zeigen die Diagramme mit λ = 10 den Mean-Pooling-Effekt? Erklären Sie Ihre Beobachtung anhand der Verteilung der Datenpunkte.;Section 5 discusses the influence of the scaling factor λ and its connection to mean pooling. Considering this information, compare plots (d) and (b) in Figure 2. Do the plots with λ = 10 demonstrate the mean pooling effect? Explain your observation by referring to the distribution of the data points.;Nein, die Diagramme mit λ = 10 zeigen keinen starken Mean-Pooling-Effekt. Die Aufmerksamkeitswerte in (d) sind um Null zentriert und weniger gestreut als die Polaritätswerte in (b). Wenn Mean Pooling dominant wäre, würden wir eine ähnliche Streuung in beiden Diagrammen erwarten.;No, the plots with λ = 10 do not clearly demonstrate a strong mean pooling effect. The attention scores in (d) are centered around zero and less dispersed than the polarity scores in (b).  If mean pooling were dominant, we would expect similar dispersion in both plots.;Nein;No;Requires Paper Context;"Results on using LSTM or the affine transformation layer as the input encoder are similar – setting a proper value for λ appears to be crucial. Figure 2 shows the results for polarity scores and attention scores for the first 3 datasets, when λ _√_ is set to a moderate value of 10 (i.e., _d). These_

results are consistent with our analysis. ... However, setting _λ to a very large value does not seem to have a_ significant impact on the performance – in this case, from Equations 1 and 2 we can see that the attention weights will be close to each other for all input tokens, leading to an effect similar to mean pooling."

2020.acl-main.312.pdf-Figure3.png;Welche Form wird in der mittleren Grafik verwendet, um die neutralen Datenpunkte darzustellen?;What shape is used in the middle graph to represent the neutral data points?;Grüne X.;Green x's.;x;x;Simple Retrieval;'
2020.acl-main.312.pdf-Figure3.png;Wie hoch ist ungefähr der höchste Datenpunkt für positive Polaritätswerte im linken Diagramm?;Approximately what is the highest polarity score for positive data points in the leftmost graph?;Ungefähr 20.;Approximately 20.;20;20;Simple Retrieval;'
2020.acl-main.312.pdf-Figure3.png;Ist im mittleren Diagramm die Bandbreite der Attention Scores für positive Token größer oder kleiner als die Bandbreite der Attention Scores für negative Token?;In the middle graph, is the range of attention scores for positive tokens larger or smaller than the range of attention scores for negative tokens?;Kleiner.;Smaller.;Kleiner;Smaller;Simple Calculation;'
2020.acl-main.312.pdf-Figure3.png;Welcher Datensatz im rechten Diagramm weist die größte Varianz der Attention Scores auf, gemessen an der vertikalen Streuung der Punkte für jede Kategorie?;Which dataset in the rightmost graph has the largest variance in attention scores, judging by the vertical spread of the points for each category?;Guns;Guns;Guns;Guns;Simple Retrieval;'
2020.acl-main.312.pdf-Figure3.png;Der Text erwähnt, dass bei einem großen Skalierungsfaktor λ (z. B. 100) die Attention Scores weniger interpretierbar werden. Wie äußert sich diese verminderte Interpretierbarkeit visuell im entsprechenden Diagramm in Abbildung 3 (und für welchen Datensatz)?;The text mentions that with a large scaling factor λ (e.g., 100), the attention scores become less interpretable. How is this reduced interpretability visually apparent in the corresponding graph in Figure 3 (and for which dataset)?;In Abbildung 3b (SST-Datensatz mit λ = 100) haben die positiven Token (blaues '+') niedrigere Attention Scores als die neutralen Token (grünes 'x'), was dem erwarteten Muster widerspricht. Dies macht die Attention Scores weniger interpretierbar.;In Figure 3b (SST dataset with λ = 100), the positive tokens (blue '+') have lower attention scores than the neutral tokens (green 'x'), which contradicts the expected pattern.  This makes the attention scores less interpretable.;Positive Token niedrigere Attention Scores als neutrale Token;Positive tokens lower attention scores than neutral tokens;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.333.pdf-Figure3.png;Welches Diagramm befindet sich in der unteren linken Ecke der Abbildung?;Which plot is located in the bottom left corner of the figure?;(g) CTG mit 1-Gramm-Entropie;(g) CTG w/ 1-gram Entropy;(g);(g);Simple Retrieval;'
2020.acl-main.333.pdf-Figure3.png;Wie hoch ist in etwa das Verhältnis zwischen dem höchsten und dem niedrigsten Wert auf der y-Achse in Diagramm (a)?;What is the approximate ratio between the highest and lowest value on the y-axis in plot (a)?;Ungefähr 1,67;Approximately 1.67;1,67;1.67;Simple Calculation;'
2020.acl-main.333.pdf-Figure3.png;In wie vielen Diagrammen liegt der niedrigste Entropiewert unter 0,4?;In how many plots is the lowest entropy value below 0.4?;5;5;5;5;Simple Calculation;'
2020.acl-main.333.pdf-Figure3.png;In welchem Diagramm ist die Differenz zwischen dem höchsten und dem niedrigsten Wert auf der y-Achse am größten, und in welchem am kleinsten?;In which plot is the difference between the highest and lowest value on the y-axis greatest, and in which is it smallest?;Größte Differenz: d,e,f. Kleinste Differenz: b;Largest difference: d,e,f. Smallest difference: b;d,e,f/b;d,e,f/b;Complex Calculation and Logical Reasoning;'
2020.acl-main.333.pdf-Figure3.png;In Abbildung 3 werden die Korrelationen zwischen normalisierten menschlichen Bewertungen und der entsprechenden n-Gramm-Entropie für den Basisdatensatz, den WS-Datensatz und den CTG-Datensatz dargestellt.  Welche Augmentierungsmethode (WS oder CTG) scheint visuell die stärkste Korrelation zwischen der 1-Gramm-Entropie und den menschlichen Bewertungen zu erzeugen, und welche die schwächste? Begründen Sie Ihre Antwort anhand der Trendlinien in den entsprechenden Teildiagrammen.;Figure 3 displays the correlations between normalized human ratings and the corresponding n-gram entropy for the baseline dataset, the WS dataset, and the CTG dataset. Which augmentation method (WS or CTG) visually appears to produce the strongest correlation between 1-gram entropy and human ratings, and which the weakest? Explain your reasoning based on the trend lines in the relevant subplots.;WS scheint die stärkste Korrelation zwischen 1-Gramm-Entropie und menschlichen Bewertungen zu haben, was durch die steilste positive Steigung in Diagramm (d) angezeigt wird. Der Basisdatensatz (Diagramm a) scheint aufgrund der geringsten Steigung die schwächste Korrelation zu haben.;WS appears to have the strongest correlation between 1-gram entropy and human ratings, as indicated by the steepest positive slope in plot (d). The baseline dataset (plot a) appears to have the weakest correlation due to the shallowest slope.;WS/Basisdatensatz;WS/Baseline;Caption Question/Complex Calculation and Logical Reasoning;'
2020.acl-main.416.pdf-Figure3.png;Welche Farbe haben die Punkte im Streudiagramm?;What color are the dots in the scatter plot?;Die Punkte sind rot.;The dots are red.;Rot;Red;Simple Retrieval;'
2020.acl-main.416.pdf-Figure3.png;Bei welchem Wert auf der x-Achse erreicht die schwarze Linie den Wert 1 auf der y-Achse?;At what value on the x-axis does the black line reach the value 1 on the y-axis?;Die schwarze Linie erreicht den Wert 1 auf der y-Achse, wenn x gleich 1 ist.;The black line reaches the value 1 on the y-axis when x is equal to 1.;1;1;Simple Retrieval;'
2020.acl-main.416.pdf-Figure3.png;Das Diagramm zeigt visuell eine Korrelation zwischen DSCORER und COUNTER. Charakterisieren Sie diese Korrelation (positiv, negativ, keine) und erklären Sie, wie die visuelle Verteilung der Punkte Ihre Charakterisierung unterstützt. Finden Sie außerdem den Pearson-Korrelationskoeffizienten für 4-Gramme im Paper und erklären Sie, ob dieser Koeffizient Ihre visuelle Analyse unterstützt.;The plot visually demonstrates a correlation between DSCORER and COUNTER. Characterize this correlation (positive, negative, none) and explain how the visual distribution of the dots supports your characterization. Furthermore, locate the Pearson correlation coefficient for 4-grams in the paper and explain whether this coefficient supports your visual analysis.;"Das Diagramm zeigt eine positive Korrelation; mit zunehmenden x-Werten steigen auch die y-Werte tendenziell. Die Punkte sammeln sich um eine Kurve, die sich nach oben und rechts bewegt. Der Artikel gibt einen Pearson-Korrelationskoeffizienten von 0,88 für 4-Gramme an. Dieser positive Koeffizient stützt die visuelle Analyse einer positiven Korrelation.";"The plot shows a positive correlation; as the x-values increase, the y-values also tend to increase. The dots cluster around a curve that moves upward and to the right. The paper states a Pearson correlation coefficient of 0.88 for 4-grams. This positive coefficient supports the visual analysis of a positive correlation.";Positiv;Positive;Requires Paper Context;'across systems and datatasets, Pearson’s correlation coefficient r is 0.93 on 1-grams, 0.94 on 2-grams, 0.91 on 3-grams, and 0.88 on 4-grams'
2020.acl-main.428.pdf-Figure2.png;Ist der Wert des am weitesten rechts liegenden Punktes auf der horizontalen Achse größer als 0,11?;Is the value of the rightmost point on the horizontal axis greater than 0.11?;Ja;Yes;Ja;Yes;Simple Retrieval;'
2020.acl-main.428.pdf-Figure2.png;Wie viele Punkte haben einen Wert auf der horizontalen Achse zwischen 0,04 und 0,06 und einen Wert von mehr als 23 auf der vertikalen Achse?;How many points have a value on the horizontal axis between 0.04 and 0.06 and a value greater than 23 on the vertical axis?;0;0;0;0;Simple Calculation;'
2020.acl-main.428.pdf-Figure2.png;Wie viele Punkte haben einen Wert von weniger als 0,02 auf der horizontalen Achse und gleichzeitig einen Wert von mehr als 28 auf der vertikalen Achse?;How many points have a value of less than 0.02 on the horizontal axis and a value of greater than 28 on the vertical axis?;8;8;8;8;Simple Calculation;'
2020.acl-main.428.pdf-Figure2.png;Laut dem Paper, führt eine Erhöhung des Wertes von α im Allgemeinen zu einer höheren oder niedrigeren Perplexität und Labelwiederholung im ELI5-Datensatz? Beziehen Sie sich dabei auf die Ergebnisse in Tabelle 3 und die Abbildung 2.;According to the paper, does increasing the value of α generally lead to higher or lower perplexity and label repetition in the ELI5 dataset?  Refer to the results discussed in Table 3 and displayed in Figure 2.;Eine Erhöhung von α führt im Allgemeinen zu einer geringeren Labelwiederholung. Nur sehr hohe Werte von α führen zu einer erhöhten Perplexität.;Increasing α generally leads to lower label repetition. Only very high values of α lead to increased perplexity.;Geringere Labelwiederholung;Lower Label Repetition;Requires Paper Context;'Results for ELI5, shown in Table 3, show that it has an especially large problem with label repetition, and that label-unlikelihood is able to reduce the repetitions by 91% (.055 vs .617), while significantly boosting F1 (.130 to .182). Figures 2 and 3 show perplexity as a function of label and context repeats respectively using unlikelihood on ELI5. The parameter α can clearly control repeats smoothly, with only very high values resulting in increased perplexity.'
2020.acl-main.493.pdf-Figure10.png;Welche syntaktische Beziehung wird durch die Farbe Hellgrau/Silber dargestellt?;Which syntactic relation is represented by the light grey/silver color?;Hellgrau/Silber steht für 'nmod'.;Light grey/silver represents 'nmod'.;nmod;nmod;Simple Retrieval;'
2020.acl-main.493.pdf-Figure10.png;Welche Farbe repräsentiert die syntaktische Beziehung 'conj'?;What color represents the syntactic relation 'conj'?;Orange steht für 'conj'.;Orange represents 'conj'.;Orange;Orange;Simple Retrieval;'
2020.acl-main.493.pdf-Figure10.png;Welche zwei Farben, die syntaktische Beziehungen darstellen, sind im Diagramm am stärksten voneinander getrennt?;Which two colors, representing syntactic relations, appear most spatially separated in the diagram?;Dunkelgrau/Grau ('cc') und dunkelblau ('case') erscheinen am weitesten voneinander entfernt.;Dark gray/gray ('cc') and dark blue ('case') appear furthest apart from each other.;Dunkelgrau/Grau & Dunkelblau;Dark gray & Dark blue;Simple Retrieval;'
2020.acl-main.493.pdf-Figure10.png;In Abschnitt B.2 wird erwähnt, dass die Cluster 'nsubj' und 'obj' sich nach der Dimensionsreduktion mit PCA und t-SNE überlappen. Welche im Textauszug genannten Probleme mit der Darstellung könnten zu dieser Überlappung beitragen, und warum könnten diese Probleme speziell bei 'nsubj' und 'obj' auftreten?;Section B.2 mentions that the 'nsubj' and 'obj' clusters overlap after PCA and t-SNE dimensionality reduction.  According to the text excerpt, what representational issues might contribute to this overlap, and why might these issues specifically affect 'nsubj' and 'obj'?;Der Text erklärt, dass einige Cluster nach der PCA-Reduktion weniger durch Syntax als vielmehr durch Semantik oder Sprachidentitäten motiviert sind. Dies könnte zu einer Überlappung zwischen 'nsubj' und 'obj' führen, da sie zwar syntaktisch unterschiedlich sind, aber oft enge semantische Beziehungen haben (z. B. Subjekt und Objekt desselben Verbs). Verschiedene Sprachen könnten ähnliche semantische Rollen auch syntaktisch unterschiedlich behandeln, wodurch die Grenzen in einem mehrsprachigen Einbettungsraum weiter verschwimmen.;The text explains that some clusters are motivated less by syntax and more by semantics or language identities after PCA reduction. This could cause overlap between 'nsubj' and 'obj' because, while syntactically distinct, they often have close semantic relationships (e.g., subject and object of the same verb). Different languages might also treat similar semantic roles differently syntactically, further blurring the lines in a multilingual embedding space.;Semantik/Sprachidentitäten;Semantics/Language identities;Requires Paper Context;"Instead of projecting difference vectors into our syntactic subspace, we first reduce them to a 32 dimensional representation using PCA,[15] then reduce to 2 dimensions using t-SNE as previously. We find that projected under PCA, syntactic difference vectors still cluster into major groups, and major trends are still evident (Figure 10). In addition, many finer-grained distinctions are still apparent (e.g. the division between common nouns and pronouns). However, in some cases, the clusters are motivated less by syntax and more by semantics or language identities. For example:

  - The nsubj and obj clusters overlap, unlike our syntactically-projected visualization, where there is clearer separation.

  - Postnominal adjectives, which form a single coherent cluster under our original visualization scheme, are split into several different clusters, each primarily composed of words from one specific language.

  - There are several small monolingual clusters without any common syntactic meaning, mainly composed of languages parsed more poorly by BERT (i.e. Chinese, Arabic, Farsi, Indonesian)."

2020.acl-main.493.pdf-Figure8.png;Welche Farbe wird in der Legende für 'case' verwendet?;What color is used for 'case' in the legend?;Dunkelblau/Marineblau;Dark blue/Navy blue;Dunkelblau;Dark blue;Caption Question/Simple Retrival;'
2020.acl-main.493.pdf-Figure8.png;Welche Abhängigkeitsbeziehung wird durch die Farbe Orange dargestellt?;Which dependency relation is represented by the color orange?;conj;conj;conj;conj;Caption Question/Simple Retrival;'
2020.acl-main.493.pdf-Figure8.png;Welche Abhängigkeitsbeziehung wird durch die Farbe Grün dargestellt und welche durch die Farbe Lila?;Which dependency relation is represented by green and which by purple?;'Grün steht für 'det' und Lila für 'advmod'.';'Green represents 'det' and purple represents 'advmod'.';det, advmod;det, advmod;Caption Question/Simple Retrival;'
2020.acl-main.493.pdf-Figure8.png;Die Abbildung visualisiert Kopf-Dependent-Abhängigkeitspaare mithilfe von t-SNE. Reif et al. (2019) verwendeten eine andere Methode zur Visualisierung von Syntaxbäumen. Welche Methode war das und wie wurde sie angewendet?;This figure visualizes head-dependent dependency pairs using t-SNE. Reif et al. (2019) used a different method to visualize syntax trees. What was that method, and how was it applied?;Reif et al. (2019) verwendeten PCA (Hauptkomponentenanalyse), um einzelne Syntaxbäume in einer zweidimensionalen Projektion der Struktursondierungsabstände zu visualisieren.;Reif et al. (2019) used PCA (Principal Component Analysis) to visualize individual syntax trees in a 2-dimensional projection of the structural probe distances.;PCA;PCA;Requires Paper Context;'In a monolingual study, Reif et al. (2019) also use the structural probe of Hewitt and Manning (2019) as a tool for understanding the syntax of BERT. They plot the words of individual sentences in a 2dimensional PCA projection of the structural probe distances, for a geometric visualization of individual syntax trees. Further, they find that distances in the mBERT space separate clusters of word senses for the same word type.'
2020.acl-main.673.pdf-Figure4.png;'Welche Farbe wird für die Punkte verwendet, die im rechten Diagramm mit 'pos' beschriftet sind?';'What color is used to represent the points in the right plot labeled 'pos'?';Hellrot/Pink;Light red/Pink;Hellrot/Pink;Light red/pink;Simple Retrieval;'
2020.acl-main.673.pdf-Figure4.png;Gibt es im linken Streudiagramm mehr blaue oder rote Punkte? (Schätzen Sie, eine genaue Zählung ist nicht erforderlich);Are there more blue or red dots in the left scatter plot? (Estimate, precise counting is not required);Ungefähr die gleiche Anzahl blauer und roter Punkte.;Approximately the same amount of blue and red dots.;Gleich;Same;Simple Calculation;'
2020.acl-main.673.pdf-Figure4.png;'Im rechten Diagramm scheinen die Punkte 'pos' und 'neg' eine Beziehung zueinander zu haben. Beschreiben Sie diese Beziehung anhand ihrer relativen Position.';'In the right plot, the 'pos' and 'neg' points seem to have a relationship. Describe that relationship in terms of their relative position.';'Sowohl 'pos'- als auch 'neg'-Punkte zeigen eine positive Korrelation.';'Both 'pos' and 'neg' points show a positive correlation.'.;Positive Korrelation;Positive Correlation;Simple Calculation;'
2020.acl-main.673.pdf-Figure4.png;Vergleichen Sie die beiden Diagramme. Was ist der Hauptunterschied in der Verteilung der Punkte in Bezug auf ihre Position?;Compare the two plots. What is the primary difference in the distribution of the points in terms of their position?;Das linke Diagramm zeigt eine komplexere, nichtlineare Verteilung. Das rechte Diagramm zeigt eine einfachere, lineare Verteilung mit einer positiven Korrelation.;The left plot shows a more complex, non-linear distribution. The right plot shows a simpler, linear distribution with a positive correlation.;Nichtlinear vs. linear;Non-linear vs. linear;Complex Calculation and Logical Reasoning;'
2020.acl-main.673.pdf-Figure4.png;"Der Text erwähnt das Training von IDEL ohne I(s;c), was zu IDEL[-] führt. Abbildung 4 zeigt die Punktverteilung von IDEL[-] im Vergleich zu IDEL (Abbildung 3). Welche Auswirkungen hat das Entfernen von I(s;c) auf die Trennung der 'pos'- und 'neg'-Punkte in den beiden dargestellten Einbettungsräumen (Stil und Inhalt)?";"The text mentions training IDEL without I(s;c), resulting in IDEL[-]. Figure 4 shows the point distribution of IDEL[-] compared to IDEL (Figure 3). What is the effect of removing I(s;c) on the separation of 'pos' and 'neg' points in the two embedding spaces (style and content) shown?";"Das Entfernen von I(s;c) verringert die Trennung zwischen 'pos'- und 'neg'-Punkten im Stil-Einbettungsraum und erhöht die Trennung im Inhalts-Einbettungsraum.";"Removing I(s;c) reduces separation between 'pos' and 'neg' points in the style embedding space and increases separation in the content embedding space.";Reduzierte Stiltrennung, erhöhte Inhaltstrennung;Reduced style separation, increased content separation;Caption Question/Complex Calculation and Logical Reasoning;'
W12-0203.pdf-Figure4.png;'Welche Farbe haben die Punkte, die 'botsing' darstellen?';'What color are the dots representing 'botsing'?';Grünlich-gelb.;Chartreuse or green-yellow.;Grünlich-gelb;Chartreuse;Simple Retrieval;'
W12-0203.pdf-Figure4.png;Wie viele blaue Punkte gibt es im Vergleich zu grünlich-gelben Punkten? Geben Sie Ihr Verhältnis als Bruch an (z. B. 1/2, wenn es halb so viele blaue Punkte gibt).;How many blue dots are there compared to chartreuse dots? Express your answer as a fraction (e.g., 1/2 if there are half as many blue dots).;Ungefähr 1/1. Es ist schwierig, aufgrund von Überlappungen genau zu sein, aber die Mengen erscheinen ungefähr gleich.;Approximately 1/1.  It's difficult to be precise due to overlap, but the quantities appear roughly equal.;1/1;1/1;Simple Calculation;'
W12-0203.pdf-Figure4.png;'Wie viele 'aanrijding'-Punkte befinden sich im positiven Bereich von dim1 (d. h. rechts von der vertikalen Nulllinie) und wie viele 'botsing'-Punkte befinden sich im negativen Bereich von dim2 (d. h. unterhalb der horizontalen Nulllinie)?';'How many 'aanrijding' dots are in the positive range of dim1 (i.e., to the right of the vertical zero line), and how many 'botsing' dots are in the negative range of dim2 (i.e., below the horizontal zero line)?';'Ungefähr 45 'aanrijding'-Punkte befinden sich rechts von der Nulllinie von dim1, und ungefähr 69 'botsing'-Punkte befinden sich unterhalb der Nulllinie von dim2.';'Approximately 45 'aanrijding' points are located to the right of the zero line of dim1, and approximately 69 'botsing' points are located below the zero line of dim2.';45/69;45/69;Complex Calculation and Logical Reasoning;'
W12-0203.pdf-Figure4.png;'Der Text erwähnt, dass 'botsing' sowohl wörtliche als auch metaphorische Kollisionen darstellen kann. Konzentrieren Sie sich auf die 'botsing'-Punkte am äußersten rechten Rand des Diagramms (dim1 > 0,6). Scheinen diese Punkte, basierend auf ihrer Position und der Diskussion im Text, eher wörtliche oder metaphorische Kollisionen darzustellen?';'The text mentions that 'botsing' can represent both literal and metaphorical collisions. Focusing on the 'botsing' dots at the far right of the chart (dim1 > 0.6), do these dots appear to represent mostly literal or metaphorical collisions, based on their position and the discussion in the text?';'Die 'botsing'-Punkte ganz rechts (dim1 > 0,6) stellen wahrscheinlich metaphorische Kollisionen dar. Der Text erklärt, dass die rechte Seite fast ausschließlich von 'botsing'-Token bevölkert ist, und weitere Analysen zeigen, dass diese weitgehend die metaphorische Bedeutung darstellen.';'The 'botsing' dots at the far right (dim1 > 0.6) likely represent metaphorical collisions. The text explains that the right side is almost exclusively populated by 'botsing' tokens, and further analysis reveals these largely represent the metaphorical meaning.';Metaphorisch;Metaphorical;Caption Question/Complex Calculation and Logical Reasoning;'Figure 4 indeed shows that the right side of the chart is almost exclusively populated by botsing tokens. Looking at their contexts reveals that they indeed overwhelmingly instantiate the metaphorical meaning og collision.'
W12-4403.pdf-Figure2.png;'Was ist der Unterschied zwischen dem höchsten und dem niedrigsten Wert auf der 'Joint-Prediction'-Achse?';'What is the difference between the highest and lowest value on the 'Joint-Prediction' axis?';'Der Unterschied zwischen dem höchsten und dem niedrigsten Wert auf der 'Joint-Prediction'-Achse ist 1,0.';'The difference between the highest and lowest value on the 'Joint-Prediction' axis is 1.0.';1;1;Simple Calculation;'
W12-4403.pdf-Figure2.png;'Welche Kategorie von Datenpunkten (tp, fp, fn, tn) ist in dem Bereich am häufigsten vertreten, in dem der Wert für 'String Similarity Estimate' unter 0,5 und der Wert für 'Joint-Prediction' unter 0,1 liegt?';Which category of data points (tp, fp, fn, tn) is most prevalent in the region where the 'String Similarity Estimate' is below 0.5 and the 'Joint-Prediction' is below 0.1?;'Die am häufigsten vertretene Kategorie im angegebenen Bereich ist 'tn' (richtig negativ), dargestellt durch lila Quadrate.';'The most prevalent category in the specified region is 'tn' (true negatives), represented by purple squares.';tn;tn;Simple Retrieval;'
W12-4403.pdf-Figure2.png;In Abschnitt 3 wird die Kombination von Kontext, Wortform und Alignment im gemeinsamen Modell erläutert. Wie verdeutlicht Abbildung 2 die Grenzen der alleinigen Verwendung von String-Ähnlichkeit für die Erkennung benannter Entitäten, insbesondere im Hinblick auf die im Text diskutierte Rolle des Kontextes bei der Reduzierung von falsch-positiven Ergebnissen? Konzentrieren Sie sich auf bestimmte Datenpunktcluster und deren Bedeutung für die Modellleistung.;Section 3 discusses the combination of context, word-shape, and alignment in the joint model. How does Figure 2 illustrate the limitations of using String Similarity alone for named entity recognition, particularly regarding the role of context discussed in the text in reducing false positives? Focus on specific data point clusters and their implications for the model's performance.;Die Gruppe der richtig Negativen (lila Quadrate) mit hoher String-Ähnlichkeit, aber niedriger Joint-Prediction zeigt die Grenzen der alleinigen Verwendung von String-Ähnlichkeit. Diese wären falsch positive Ergebnisse, wenn man sich nur auf die String-Ähnlichkeit verlassen würde. Das gemeinsame Modell, indem es den Kontext berücksichtigt, klassifiziert diese korrekt als Nicht-Entitäten und reduziert so falsch positive Ergebnisse.;The cluster of true negatives (purple squares) with high String Similarity but low Joint-Prediction illustrates the limitations of using String Similarity alone. These would be false positives if only String Similarity was considered. The joint model, by incorporating context, correctly classifies these as non-entities, reducing false positives.;Kontext reduziert falsch Positive;Context reduces false positives;Caption Question/Complex Calculation and Logical Reasoning;'
W14-0301.pdf-Figure1.png;Welche Farbe haben die Punkte im oberen Diagramm?;What color are the points in the top graph?;Rot.;Red.;Rot;Red;Simple Retrieval;'
W14-0301.pdf-Figure1.png;Was ist die Differenz zwischen dem höchsten und niedrigsten Korrelationskoeffizienten in den drei Diagrammen?;What is the difference between the highest and lowest correlation coefficient shown in the three graphs?;Der höchste Korrelationskoeffizient ist 0,7874 und der niedrigste ist -0,8687. Die Differenz beträgt 0,7874 - (-0,8687) = 1,6561.;The highest correlation coefficient is 0.7874 and the lowest is -0.8687. The difference is 0.7874 - (-0.8687) = 1.6561.;1,6561;1.6561;Caption Question/Simple Calculation;'
W14-0301.pdf-Figure1.png;Berechnen Sie die Summe der Korrelationskoeffizienten aller drei Diagramme. Ist das Ergebnis positiv oder negativ?;Calculate the sum of the correlation coefficients shown in all three graphs. Is the result positive or negative?;0,7874 + (-0,8687) + (-0,7968) = -0,8781. Das Ergebnis ist negativ.;0.7874 + (-0.8687) + (-0.7968) = -0.8781. The result is negative.;Negativ;Negative;Caption Question/Simple Calculation;'
W14-0301.pdf-Figure1.png;Welcher der drei Korrelationskoeffizienten liegt am nächsten an 0?;Which of the three correlation coefficients is closest to 0?;Der Korrelationskoeffizient, der am nächsten an 0 liegt, ist 0,7874 (Korrelation zwischen %G und BLEU).;The correlation coefficient closest to 0 is 0.7874 (correlation between %G and BLEU).;0,7874;0.7874;Caption Question/Simple Calculation;'
W14-0301.pdf-Figure1.png;'Der Text erwähnt Ausreißer in Abbildung 1. In welchen der drei Diagramme sind diese Ausreißer am deutlichsten sichtbar und warum könnten diese Ausreißer laut dem Artikel trotz eines hohen 'G'-Prozentsatzes niedrige BLEU-Werte oder hohe TER/TERpA-Werte aufweisen?';'The text mentions outliers in Figure 1. In which of the three graphs are these outliers most apparent, and what reasons does the paper suggest for these outliers having low BLEU scores or high TER/TERpA scores despite a high 'G' percentage?';Die Ausreißer sind am deutlichsten in den TER- und TERpA-Diagrammen (1b und 1c) sichtbar. Der Artikel legt nahe, dass diese Ausreißer auftreten können, wenn viele (unbekannte) Quellwörter nicht übersetzt werden oder wenn die (eindeutige) Referenzübersetzung einfach zu weit von der generierten Hypothese entfernt ist.;The outliers are most apparent in the TER and TERpA graphs (1b and 1c). The paper suggests that these outliers could occur when many (unknown) source words are not translated, or when the (unique) reference translation is simply too far from the generated hypothesis.;1b und 1c;1b and 1c;Caption Question/Complex Calculation and Logical Reasoning;'
W14-1802.pdf-Figure5.png;Welche Farbe haben die Punkte im Streudiagramm?;What color are the dots in the scatter plot?;Rot.;Red.;Rot;Red;Simple Retrieval;'
W14-1802.pdf-Figure5.png;Was ist der Unterschied zwischen dem höchsten und dem niedrigsten Wert auf der horizontalen Achse?;What is the difference between the highest and lowest value on the horizontal axis?;Ungefähr 14.;Approximately 14.;14;14;Simple Calculation;'
W14-1802.pdf-Figure5.png;Wenn Sie eine Linie durch die Punkte zeichnen würden, welche ungefähre Steigung hätte diese Linie?;If you were to draw a line through the dots, what would be the approximate slope of that line?;Ungefähr 1.;Approximately 1.;1;1;Simple Calculation;'
W14-1802.pdf-Figure5.png;Der Artikel erwähnt Herausforderungen bei der Bewertung aufgrund eines niedrigen SNR. Welche zwei Faktoren tragen laut Artikel zu einem niedrigen SNR bei, und wie könnte sich dies visuell im Streudiagramm in Abbildung 5 manifestieren, da es Daten der Stufe V (Klassen 9-12) darstellt?;The paper mentions challenges in scoring due to low SNR. According to the paper, which two factors contribute to low SNR, and how might this visually manifest in the scatter plot in Figure 5, given that it represents Stage V (Grades 9-12) data?;Geringe Signalamplitude (leises Sprechen) und hohes Hintergrundgeräusch tragen zu einem niedrigen SNR bei.  Visuell könnten Punkte, die deutlich unterhalb der Trendlinie liegen, auf Probleme mit niedrigem SNR zurückgeführt werden.  Dies ist in Abbildung 5 möglicherweise weniger ausgeprägt, da sie die Klassenstufen 9-12 darstellt, in denen Schüler im Vergleich zu jüngeren Schülern seltener leise sprechen.;Low signal amplitude (quiet speech) and high background noise contribute to low SNR.  Visually, points significantly deviating downwards from the trend line could be attributed to low SNR issues.  This might be less pronounced in Figure 5 as it represents Grades 9-12, where students are less likely to speak softly compared to younger students.;Leises Sprechen, Hintergrundgeräusche;Quiet speech, background noise;Requires Paper Context;'We identified several participants for whom the difference between human and machine scores is bigger than 4 in Figures 1, 2, 3, 4, 5. Listening to the recordings of these tests, we concluded that the most important factor was low Signal-toNoise Ratio (SNR). Either the background noise was very high (in 6 of 1,362 tests in the validation set), or speech volume was low (in 3 of 1,362 tests in the validation set).'
W14-3112.pdf-Figure1.png;Welche Farbe hat der Cluster oben links?;What is the color of the cluster in the top left corner?;Gelb;Yellow;Gelb;Yellow;Simple Retrieval;'
W14-3112.pdf-Figure1.png;Wie viele Cluster gibt es insgesamt in der Abbildung?;How many clusters are there in total in the figure?;10;10;10;10;Simple Calculation;'
W14-3112.pdf-Figure1.png;Welche zwei Cluster haben die meisten Knoten? (Geben Sie die Farben an);Which two clusters have the most nodes? (Specify by color);Gelb (oben links) und Grün (unten links);Yellow (top left) and Green (bottom left);Gelb, Grün;Yellow, Green;Complex Calculation and Logical Reasoning;'
W14-3112.pdf-Figure1.png;Welcher Cluster scheint am wenigsten verbunden zu sein, gemessen an der Anzahl der sichtbaren Kanten? (Geben Sie die Farbe an);Which cluster appears to be the least connected based on the number of visible edges? (Specify by color);Lila (unten rechts);Purple (bottom right);Lila;Purple;Complex Calculation and Logical Reasoning;'
W14-3112.pdf-Figure1.png;'In der Bildunterschrift wird eine 'Treemap-Struktur' erwähnt. Wie wird diese Treemap-Struktur im GIB-Layout verwendet, um die relative Größe der Cluster widerzuspiegeln, und wie hängt dies mit der im Artikel beschriebenen Themenkovarianz zusammen?';'The caption mentions a 'treemap structure'. How does this treemap structure, as used in the GIB layout, reflect the relative size of the clusters, and how does this relate to the topic covariance discussed in the paper?';Die Treemap-Struktur stellt Cluster visuell mit Größen dar, die proportional zu ihrer Fläche im Layout sind. Die Themenkovarianz, berechnet aus dem LDA-Theta-Vektor (Themenprävalenz in Dokumenten), bestimmt die räumliche Anordnung. Eine höhere Kovarianz zwischen Themen (d. h., sie treten häufig gemeinsam in Dokumenten auf) führt zu einer engeren Platzierung innerhalb des Treemaps.;The treemap structure visually represents clusters with sizes proportional to their area in the layout. The topic covariance, calculated from the LDA theta vector (topic prevalence in documents), determines the spatial arrangement. Higher covariance between topics (meaning they often co-occur in documents) results in closer placement within the treemap.;Clustergröße proportional zur Fläche, Themenkovarianz bestimmt Anordnung;Cluster size proportional to area, topic covariance determines arrangement;Caption Question/Complex Calculation and Logical Reasoning;'
W16-2912.pdf-Figure1.png;'Welche Farbe hat der Kreis mit der Bezeichnung 'UMLS'?';'What is the color of the circle labeled 'UMLS'?';Hellviolett/Lavendel.;Light purple/lavender.;Hellviolett/Lavendel;Light purple/lavender;Simple Retrieval;'
W16-2912.pdf-Figure1.png;'Wie viele Begriffe befinden sich im Schnittbereich der Kreise 'WNLing' und 'word2vec'?';'How many terms are in the intersection of the 'WNLing' and 'word2vec' circles?';64 Begriffe.;64 terms.;64;64;Simple Retrieval;'
W16-2912.pdf-Figure1.png;Wie viele eindeutige Begriffe gibt es insgesamt in den drei dargestellten Vokabularen?;How many unique terms are there in the three vocabularies shown?;3657 eindeutige Begriffe.;3657 unique terms.;3657;3657;Complex Calculation and Logical Reasoning;'
W16-2912.pdf-Figure1.png;Wie viele Begriffe sind ausschließlich in genau zwei der drei dargestellten Vokabulare vorhanden?;How many terms are present in exactly two of the three vocabularies, but not all three?;109 Begriffe.;109 terms.;109;109;Complex Calculation and Logical Reasoning;'
W16-2912.pdf-Figure1.png;'Der Text erwähnt den Begriff 'substance use history' aus dem Basisvokabular, der von keinem der drei Ansätze gefunden wurde. Welcher Bereich im Venn-Diagramm würde sich verändern, wenn dieser Begriff von allen drei Ansätzen gefunden worden wäre, und wie hoch wäre der neue Wert in diesem Bereich?';'The text mentions the term 'substance use history' from the baseline vocabulary, which was not found by any of the three approaches. Which area in the Venn diagram would change if this term had been found by all three approaches, and what would be the new value in this area?';Der zentrale Schnittpunkt aller drei Kreise würde von 54 auf 55 steigen.;The central intersection of all three circles would increase from 54 to 55.;55;55;Caption Question/Complex Calculation and Logical Reasoning;'
W16-2920.pdf-Figure8.png;Welche Zahl steht im hellblauen Kreis?;What number is in the light blue circle?;2;2;2;2;Simple Retrieval;'
W16-2920.pdf-Figure8.png;'Was ist die Summe der Zahlen in den Schnittmengen der Kreise 'Latent' und 'Feature-basiert'?';'What is the sum of the numbers within the overlapping sections of the 'Latent' and 'Feature-based' circles?';47;47;47;47;Simple Retrieval;'
W16-2920.pdf-Figure8.png;Wie viele True Positives wurden von mindestens einem der drei Modelle identifiziert?;How many true positives were identified by at least one of the three models?;126;126;126;126;Complex Calculation and Logical Reasoning;'
W16-2920.pdf-Figure8.png;'Wie viele True Positives wurden ausschließlich vom 'Latent'-Modell und vom 'Rules'-Modell zusammen identifiziert (d.h. ohne Überschneidung mit dem 'Feature-basiert'-Modell)?';'How many true positives were identified by the 'Latent' model and the 'Rules' model combined, without overlap with the 'Feature-based' model?';36;36;36;36;Simple Calculation;'
W16-2920.pdf-Figure8.png;Tabelle 4 zeigt die F1-Werte für die einzelnen Modelle und ein kombiniertes Modell. Erklärt die in Abbildung 8 dargestellte geringe Überschneidung zwischen dem latent-basierten und dem feature-basierten Modell, warum das kombinierte Modell einen besseren F1-Wert erzielt als die Einzelmodelle? Begründen Sie Ihre Argumentation anhand der Abbildung und der entsprechenden Erläuterung im Artikel.;Table 4 shows the F1 scores for individual models and a combined model. Does the low overlap shown in Figure 8 between the latent and feature-based models explain why the combined model achieves a better F1 score than the individual models? Explain your reasoning by referring to the figure and the relevant discussion in the paper.;Ja. Die geringe Überschneidung in Abbildung 8 zeigt, dass die Modelle weitgehend komplementär sind, d.h. sie erfassen unterschiedliche Teile der Daten. Diese Komplementarität ermöglicht es einem kombinierten Modell, das eine siebartige Architektur verwendet, die Stärken jedes Modells zu nutzen und einen höheren F1-Gesamtwert zu erreichen, wie in Tabelle 4 dargestellt und in Abschnitt 5.1 erläutert.;Yes. The low overlap in Figure 8 demonstrates that the models are largely complementary, meaning they capture different parts of the data. This complementarity allows a combined model using a sieve-based architecture to leverage the strengths of each and achieve a higher overall F1 score, as shown in Table 4 and explained in section 5.1.;Ja;Yes;Requires Paper Context;"The table also includes a sieve-based ensemble system, which performs significantly better than the best-performing single model. In this architecture, the sieves are applied in descending order of precision, so that the positive predictions of the higher precision sieves will always be preferred to contradictory predictions made by subsequent, lower-precision sieves. Figure 7 illustrates that as sieves are added, the F1 score remains fairly constant, while recall increases at the cost of precision.

...

However, as our discussion in Section 5.1 will show, our combined model demonstrates that the latent and featurebased models are largely complementary.

5.1 Model overlap

As Chambers et al. (2014), Mirza (2016), and many other algorithms have shown, models can be applied sequentially in “sieves” to produce higherquality output. Ideally, each model in a sievebased system will capture different portions of the data through a mixture of approaches, distinguishing this method from more naive ensembles in which the contributions of a lone component would be washed out. Figure 8 details this observation by showing the coverage difference between the models described here."
